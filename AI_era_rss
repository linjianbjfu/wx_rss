<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>AI_era</id>
    <title>新智元</title>
    <updated>2024-02-22T03:25:46.596Z</updated>
    <generator>awesome</generator>
    <author>
        <name>新智元</name>
    </author>
    <subtitle>智能+中国主平台，致力于推动中国从互联网+迈向智能+新纪元。重点关注人工智能、机器人等前沿领域发展，关注人机融合、人工智能和机器人革命对人类社会与文明进化的影响，领航中国新智能时代。</subtitle>
    <logo>http://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb27w0Aw0CyUGVElB6ibyE1fYyiaNHRpfQ8voAiaRicXDORqaibXnwHx4VJEYeja6zHnF0natYBX86oKmOw/0?wx_fmt=png</logo>
    <icon>http://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb27w0Aw0CyUGVElB6ibyE1fYyiaNHRpfQ8voAiaRicXDORqaibXnwHx4VJEYeja6zHnF0natYBX86oKmOw/0?wx_fmt=png</icon>
    <entry>
        <title type="html"><![CDATA[全球最强开源大模型一夜易主！谷歌Gemma 7B碾压Llama 2 13B，今夜重燃开源之战]]></title>
        <id>2652446680_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652446680&amp;idx=1&amp;sn=7453bcb6b07b3268a1aab06b133ed7df&amp;chksm=f12a6b29c65de23f8768e9847fa95044d54e137af1b4edf55d55b0f19ba4a5b7718d37997e9a#rd"/>
        <updated>2024-02-21T17:16:43.000Z</updated>
        <summary type="html"><![CDATA[<h3 style="margin: 0px;padding: 0px;outline: 0px;font-weight: 400;font-size: 16px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);visibility: visible;" data-mpa-powered-by="yiban.io"><div data-tools="135编辑器" data-id="88402" style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;line-height: 27.2px;widows: 1;visibility: visible;"><div data-style="line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;" style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><div style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><div style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><div data-tools="135编辑器" data-id="88402" style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 0.544px;line-height: 27.2px;visibility: visible;"><div data-style="line-height: 1.8; text-align: justify; font-size: 15px; letter-spacing: 0px; color: rgb(117, 114, 114);white-space: normal;" style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><div style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><p style="text-align: center;margin-bottom: 8px;"><img class="rich_pages wxw-img js_insertlocalimg" data-backh="247" data-backw="578" data-imgfileid="504962985" data-ratio="0.42777777777777776" data-s="300,640" data-type="png" data-w="1080" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u2eww2E1Ptse01S4RUJQYXNblBlkjd0AUSJW1hjia85AboKGCEibBawYw/640?wx_fmt=png&amp;from=appmsg"></p><div style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><hr style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 17px;letter-spacing: 0.544px;visibility: visible;"><p style="margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;line-height: 1.75em;visibility: visible;"><br style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"></p><p style="margin: -1.2em 8px 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;clear: both;min-height: 1em;font-size: 17px;letter-spacing: 0.544px;text-align: center;line-height: 1.75em;visibility: visible;"><span style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;visibility: visible;"><strong style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-family: inherit;font-size: 1em;text-decoration: inherit;visibility: visible;"><span style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;">&nbsp;&nbsp;</span></strong><strong style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 1em;font-family: inherit;text-decoration: inherit;visibility: visible;"><span style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 18px;color: rgb(255, 255, 255);line-height: 1.4;font-family: inherit;font-weight: inherit;text-decoration: inherit;background-color: rgb(127, 127, 127);visibility: visible;">新智元报道&nbsp;&nbsp;</span></strong></span></p></div></div></div></div></div></div></div></div></h3><p style="margin: 0px 8px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;min-height: 1em;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.75em;visibility: visible;"><span style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;font-size: 12px;color: rgb(136, 136, 136);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 1px;visibility: visible;">编辑：编辑部</span></p><div powered-by="xiumi.us" style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(34, 34, 34);font-size: 17px;font-style: normal;font-variant-ligatures: normal;font-variant-caps: normal;font-weight: 400;letter-spacing: 0.544px;orphans: 2;text-align: justify;text-indent: 0px;text-transform: none;white-space: normal;widows: 2;word-spacing: 0px;-webkit-text-stroke-width: 0px;text-decoration-thickness: initial;text-decoration-style: initial;text-decoration-color: initial;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;background-color: rgb(255, 255, 255);visibility: visible;"><div style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><p style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;"><h5 style="margin: 10px 8px 0px;padding: 10px;outline: 0px;font-weight: 400;font-size: 14px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;color: rgb(0, 0, 0);letter-spacing: 0.544px;font-family: Arial, Helvetica, sans-serif;border-radius: 3px;background-color: rgb(248, 248, 248);line-height: 1.75em;word-break: break-all !important;word-spacing: 1px !important;visibility: visible;"><span style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;letter-spacing: 1px;font-size: 15px;visibility: visible;"><strong style="margin: 0px;padding: 0px;outline: 0px;max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible;">【新智元导读】</strong>谷歌发布全球最强开源大模型Gemma，7B性能超越Llama 2 13B！谷歌和OpenAI，已经卷出了新高度。这轮番放深夜炸弹的频率，让人不得不怀疑双方都已经攒了一堆大的。</span></h5></p></div></div><p style="max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: left;line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="letter-spacing: 1px;"><br></span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">一声炸雷深夜炸响，谷歌居然也开源LLM了？！</span></p><p style="margin-left: 8px;margin-right: 8px;"><img class="rich_pages wxw-img" data-backh="92" data-backw="578" data-height="164" data-imgfileid="504963013" data-ratio="0.1533980582524272" data-type="png" data-w="1030" data-width="1030" height="158" style="width: 100%;height: auto;" width="1030" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2ubnCCZR2lCgtMFEEmToWRMrs6SsYZjTT9F6ol4ibCyNwUcfzAVhFdXcg/640?wx_fmt=png"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">这次，重磅开源的Gemma有2B和7B两种规模，并且采用了与Gemini相同的研究和技术构建。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-backh="385" data-backw="562" data-height="802" data-imgfileid="504962902" data-ratio="0.6851851851851852" data-type="png" data-w="1080" data-width="1170" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uPMIE9B47SFWqDX9Odr9sFuOic5dDYoKkfPBhsXbyVW1G7tzkaHuHNYw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">有了Gemini同源技术的加持，Gemma不仅在相同的规模下实现SOTA的性能。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">而且更令人印象深刻的是，还能在关键基准上越级碾压更大的模型，比如Llama 2 13B。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-backh="421" data-backw="562" data-height="749" data-imgfileid="504962900" data-ratio="0.749" data-type="png" data-w="1000" data-width="1000" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u95AMZt9c96icYrM91KkuibdYeUaZl4TyS2RaVIA2SXwnRKibiaWVhY6kvQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">与此同时，谷歌还放出了16页的技术报告。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="110" data-backw="562" data-height="242" data-imgfileid="504962901" data-ratio="0.1962962962962963" data-type="png" data-w="1080" data-width="1230" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uqDv6iaBZ9ryDvRXqSwI2ibLwDm9omdgibvqicw8McALXsic2MtluZRnOUjQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: left;"><span style="letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 14px;">技术报告地址：https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">谷歌表示，Gemma这个名字源自拉丁语「gemma」，也就是「宝石」的意思，似乎是在象征着它的珍贵性。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">历史上，Transformers、TensorFlow、BERT、T5、JAX、AlphaFold和AlphaCode，都是谷歌为开源社区贡献的创新。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-backh="657" data-backw="562" data-height="1200" data-imgfileid="504962904" data-ratio="1.1684518013631937" data-type="png" data-w="1027" data-width="1027" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uWRCnP2gJY5JVNpUhM5YBM2C9vIsQPvj0LgAFzGx2cHr6ygCapQLOMQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><span style="letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 14px;">谷歌：今天我就来给你表演一个什么是Open AI</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">而谷歌今天在全球范围内同步推出的Gemma，必然会再一次掀起构建开源AI的热潮。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">同时也坐实了OpenAI「唯一ClosedAI」的名头。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">OpenAI最近刚因为Sora火到爆，Llame据称也要有大动作，谷歌这就又抢先一步。硅谷大厂，已经卷翻天了！</span></p><p style="margin-left: 8px;margin-right: 8px;line-height: 1.75em;margin-bottom: 0px;text-align: center;"><img class="rich_pages wxw-img" data-backh="349" data-backw="562" data-height="415" data-imgfileid="504963008" data-ratio="0.6203288490284006" data-type="jpeg" data-w="669" data-width="669" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uM4n8ib18em1xXgCl1ZVWawH07Bl2mThUAicGzibn2glEdbtDSr3giag2DA/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;text-align: center;"><span style="letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 14px;">谷歌：开源闭源我全都要</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Hugging Face CEO也跟帖祝贺。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="146" data-imgfileid="504963009" data-ratio="0.15192507804370448" data-type="png" data-w="961" data-width="961" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2unvepxibH9UvUeJ29PEnMlYqexDhwoicxNxZeXsN6RjEPZvtLZdPbFdiaQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">还贴出了Gemma登上Hugging Face热榜的截图。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="1112" data-imgfileid="504963010" data-ratio="0.4583333333333333" data-type="png" data-w="1080" data-width="2424" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2utXdOPgjkQtpCibiag0eIV8k8rjWy2xQ7jmVjUdfLsL4qotqohNNUdZPQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Keras作者François Chollet直言：最强开源大模型，今日易主了。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="582" data-imgfileid="504963007" data-ratio="0.49722222222222223" data-type="png" data-w="1080" data-width="1170" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uan9eAq46cQTqJaSnicY4y5gzqm0Pib72l9icpSpBbx6olGVOK8OMpK6bA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">有网友已经亲自试用过，表示Gemma 7B真是速度飞快。</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">谷歌简直是用Gemini拳打GPT-4，用Gemma脚踢Llama 2！</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="219" data-imgfileid="504963006" data-ratio="0.22884012539184953" data-type="png" data-w="957" data-width="957" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uFd7jNS1pl1ibVTwsCm8XzTLHgxvdqJeVT0ufSXZpP8YxaPNgNK31YKg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">网友们也是看热闹不嫌事大，召唤Mistral AI和OpenAI今晚赶快来点大动作，别让谷歌真的抢了头条。（手动狗头）</span></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="317" data-imgfileid="504963011" data-ratio="0.33124346917450365" data-type="png" data-w="957" data-width="957" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uF94KSKdFVjicqcaruUSsMWqIhyro4D3ibSGGIibVmVicRa9txSKTsl4C4w/640?wx_fmt=png&amp;from=appmsg"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span></p><div autoid="1895" data-style-type="0" style="max-width: 100%;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><div style="padding: 8px;max-width: 100%;box-sizing: border-box;border-left: 6px solid rgb(255, 202, 0);font-size: 18px;line-height: 1.4;font-family: inherit;font-weight: bold;text-decoration: inherit;border-top-color: rgb(255, 202, 0);border-right-color: rgb(255, 202, 0);border-bottom-color: rgb(255, 202, 0);overflow-wrap: break-word !important;"><p style="line-height: 1.75em;margin-bottom: 0px;">同规模刷新SOTA，越级单挑Llama 2 13B</p></div></div><h2 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"></h2><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">可以看到，Gemma-7B模型在涵盖一般语言理解、推理、数学和编码的8项基准测试中，性能已经超越了Llama 2 7B和13B！</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-backh="311" data-backw="562" data-height="842" data-imgfileid="504962909" data-ratio="0.5537037037037037" data-type="png" data-w="1080" data-width="1520" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u3n54ydwM6B2aWmZ0tB6eichLjibTdCccBmB9iaPVvW16GxZhPkdfQnjaA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">并且，它也超越了Mistral 7B模型的性能，尤其是在数学、科学和编码相关任务中。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="556" data-backw="562" data-height="752" data-imgfileid="504962908" data-ratio="0.9894736842105263" data-type="png" data-w="760" data-width="760" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uW5u6GVgqb2vKTuMSZo67ruFtkGq7XefQicSGHFqyrrSIGsNOC2pO8wg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在安全性方面，经过指令微调的Gemma-2B IT和 Gemma-7B IT模型，在人类偏好评估中都超过了Mistal-7B v0.2模型。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">特别是Gemma-7B IT模型，它在理解和执行具体指令方面，表现得更加出色。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="405" data-backw="562" data-height="562" data-imgfileid="504962910" data-ratio="0.7205128205128205" data-type="png" data-w="780" data-width="780" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uKuBjdH0XUBWhslvwggPoPSSlJbH7kDibL9EVyEQhV4sOSjIHvd398vA/640?wx_fmt=png&amp;from=appmsg"></p><div autoid="1895" data-style-type="0" style="max-width: 100%;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><div style="padding: 8px;max-width: 100%;box-sizing: border-box;border-left: 6px solid rgb(255, 202, 0);font-size: 18px;line-height: 1.4;font-family: inherit;font-weight: bold;text-decoration: inherit;border-top-color: rgb(255, 202, 0);border-right-color: rgb(255, 202, 0);border-bottom-color: rgb(255, 202, 0);overflow-wrap: break-word !important;"><p style="line-height: 1.75em;margin-bottom: 0px;">一整套工具：跨框架、工具和硬件进行优化</p></div></div><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"></h3><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">这次，除了模型本身，谷歌还提供了一套工具帮助开发者，确保Gemma模型负责任的使用，帮助开发者用Gemma构建更安全的AI应用程序。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">- 谷歌为JAX、PyTorch和TensorFlow提供了完整的工具链，支持模型推理和监督式微调（SFT），并且完全兼容最新的Keras 3.0。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">- 通过预置的Colab和Kaggle notebooks，以及与Hugging Face、MaxText、NVIDIA NeMo和TensorRT-LLM等流行工具的集成，用户可以轻松开始探索Gemma。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">- Gemma模型既可以在个人笔记本电脑和工作站上运行，也可以在Google Cloud上部署，支持在Vertex AI和Google Kubernetes Engine (GKE) 上的简易部署。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">- 谷歌还对Gemma进行了跨平台优化，确保了它在NVIDIA GPU和Google Cloud TPU等多种AI硬件上的卓越性能。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">并且，使用条款为所有组织提供了负责任的商业使用和分发权限，不受组织规模的限制。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-backh="135" data-backw="562" data-height="672" data-imgfileid="504962911" data-ratio="0.23981481481481481" data-type="png" data-w="1080" data-width="2800" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2unEFldFvtwsoQ1y88LSdYxXH5qST4W4DZNfgXwIUbZcDwJTYUHfEVxQ/640?wx_fmt=png&amp;from=appmsg"></p><div autoid="1895" data-style-type="0" style="max-width: 100%;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><div style="padding: 8px;max-width: 100%;box-sizing: border-box;border-left: 6px solid rgb(255, 202, 0);font-size: 18px;line-height: 1.4;font-family: inherit;font-weight: bold;text-decoration: inherit;border-top-color: rgb(255, 202, 0);border-right-color: rgb(255, 202, 0);border-bottom-color: rgb(255, 202, 0);overflow-wrap: break-word !important;"><p style="line-height: 1.75em;margin-bottom: 0px;">但，没有全胜</p></div></div><h2 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"></h2><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">不过，Gemma并没有能够在所有的榜单中，都拿下SOTA。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在官方放出的评测中，Gemma 7B在MMLU、HellaSwag、SIQA、CQA、ARC-e、HumanEval、MBPP、GSM8K、MATH和AGIEval中，成功击败了Llama 2 7B和13B模型。</span></p><div data-mpa-template="t" mpa-from-tpl="t"><div style="background-color: rgb(255, 255, 255);box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="text-align: right;margin: 10px 0%;box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="padding: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;background-color: rgb(255, 255, 254);padding-top: 5px;padding-bottom: 5px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="margin: 3px 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;overflow-x: auto;overflow-y: hidden;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="width: 1000%;min-width: 100%;box-sizing: border-box;display: flex;justify-content: center;align-items: center;max-width: 1000% !important;" mpa-from-tpl="t" data-mpa-scroll-mark="0"><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 4px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962986" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uI6MABKVdhh2fknRaE9oUAO92alOc9XPdib1DQuCaTRR3HNMuzbUkJxg/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962987" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uEP3fGL4ggV4Osbs89QrE0JicuIcjl4DhuibNPEHbs8GBnmBVhxIZkkrA/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962988" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u2TebIbgNCjVPCLnvjsqhSBvUbsOWx2KSZ576Ew9a7u1Jv6gd4lXrrw/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962989" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uenPiblb22ALgB6o8NRmfeQx2UibYvlmQgHgn1icZTZ8dcQdpsXsGD1JIg/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962990" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uXVwQ4k2quqia4icEcFOoF7FAS8uFgPMzJ4XNmXjbHicUHlFOWmcEYhQSg/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962991" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uD34YBxxFwVXT2icguvnokpOwegqE7lQhzUhAU00R8icdzyuAxPPT0Jkw/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962992" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2udicSic1Sljje2hvlXwicwdyBiajYXKJDaVZPvicScH0eW0sHa3epf3KvOAw/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962993" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uFrfDYpLL4XaMyibnERxEfhfic50wNVyo0fbyl2tzjXma80YjSRmeYb8A/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962994" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u0TNHjkInicJb76P2X8icfMuGCxLfcmEiaSIaDDibgLQL5uI1n3Tr0wfEWQ/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962995" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uKA78mibW4M4kvsdTYeHiboGbMiaxqcibLdFBeSJ1rv5jKQSTWgSMica5iafg/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin: 8px 0% 10px;box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;font-size: 12px;color: rgba(81, 81, 81, 0.54);box-sizing: border-box;" mpa-from-tpl="t"><p style="box-sizing: border-box;text-align: center;line-height: 1.75em;"><span style="letter-spacing: 1px;color: rgb(136, 136, 136);font-size: 14px;">左右滑动查看</span></p></div></div></div></div></div><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">相比之下，Gemma 7B在Boolq测试中，只与Mistral 7B打了个平手。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962921" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uV0XeLcUl2d26gdR0FiaKQM3ZmkFB7zV0NuI5bgIMvoyAALDmxDF4JOQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">而在PIQA、ARC-c、Winogrande和BBH中，则不敌Mistral 7B。</span></p><div data-mpa-template="t" mpa-from-tpl="t"><div style="background-color: rgb(255, 255, 255);box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="text-align: right;margin: 10px 0%;box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="padding: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;background-color: rgb(255, 255, 254);padding-top: 5px;padding-bottom: 5px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;width: 100%;" mpa-from-tpl="t"><div style="margin: 3px 0%;box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;overflow-x: auto;overflow-y: hidden;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="width: 400%;min-width: 100%;box-sizing: border-box;display: flex;justify-content: center;align-items: center;max-width: 400% !important;" mpa-from-tpl="t" data-mpa-scroll-mark="0"><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 4px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962996" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uGiceo7cSNw9P71a80ELGQNxA0VDa3cKJVU16pYdLPlaURfIUzc13LzQ/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962997" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uKqknA68icia2jLqXicBS3mR5NFYDic3lYIgLD4eKZoYcarohCekBMyndXA/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962998" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2ud0vL6juW82jribY4NFBLTo8vqjibgET2bNxKGdETicGsUQSRtibjia1o4Xg/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div><div style="display: inline-block;width: 33.3333%;vertical-align: middle;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="display: inline-block;width: 100%;vertical-align: top;padding-right: 3px;padding-left: 3px;box-sizing: border-box;" mpa-from-tpl="t"><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;margin-right: 0%;margin-left: 0%;box-sizing: border-box;" mpa-from-tpl="t"><p style="max-width: 100%;vertical-align: middle;display: inline-block;overflow: hidden !important;box-sizing: border-box;" mpa-from-tpl="t"><img class="rich_pages wxw-img" data-height="1432" data-imgfileid="504962999" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uxM3VLquiaPq1zojQgCpfGQsJIgPib5fv5StTOibh80iaURyh60iaj8rJt2g/640?wx_fmt=png&amp;from=appmsg"> </p></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div style="box-sizing: border-box;" mpa-from-tpl="t"><div style="margin: 8px 0% 10px;box-sizing: border-box;" mpa-from-tpl="t"><div style="text-align: center;font-size: 12px;color: rgba(81, 81, 81, 0.54);box-sizing: border-box;" mpa-from-tpl="t"><p style="box-sizing: border-box;text-align: center;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 14px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 1px;">左右滑动查看</span></p></div></div></div></div></div><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在OBQA和trivalent QA中，更是同时被7B和13B规模的Llama 2 7B斩于马下。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-backh="342" data-backw="562" data-height="1432" data-imgfileid="504963002" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 254);width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uX3tBYEm9OsVoTViaMTQ3M2QbKp78Xjiaqibv4mKSicNeLl4gjEt9jPQbfA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"><img class="rich_pages wxw-img" data-backh="342" data-backw="562" data-height="1432" data-imgfileid="504963003" data-ratio="0.6092592592592593" data-type="png" data-w="1080" data-width="2350" style="letter-spacing: 0.578px;text-align: center;text-wrap: wrap;background-color: rgb(255, 255, 254);width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uNun6u4JaI92JgdBO5NKZ1nias2iabOsWRSUuO27D5rV5cJRnWxGvOQUw/640?wx_fmt=png&amp;from=appmsg"></span></p><div autoid="1895" data-style-type="0" style="max-width: 100%;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><div style="padding: 8px;max-width: 100%;box-sizing: border-box;border-left: 6px solid rgb(255, 202, 0);font-size: 18px;line-height: 1.4;font-family: inherit;font-weight: bold;text-decoration: inherit;border-top-color: rgb(255, 202, 0);border-right-color: rgb(255, 202, 0);border-bottom-color: rgb(255, 202, 0);overflow-wrap: break-word !important;"><p style="line-height: 1.75em;margin-bottom: 0px;">技术报告</p></div></div><h2 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"></h2><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">谷歌这次发布的两个版本的Gemma模型，70 亿参数的模型用于GPU和TPU上的高效部署和开发，20亿参数的模型用于CPU和端侧应用程序。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在18个基于文本的任务中的11个中，Gemma都优于相似参数规模的开源模型，例如问答、常识推理、数学和科学、编码等任务。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">模型架构方面，Gemma在Transformer的基础上进行了几项改进，从而在处理复杂任务时能够展现出更加出色的性能和效率。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">- 多查询注意力机制</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">其中，7B模型采用了多头注意力机制，而2B模型则使用了多查询注意力机制。结果显示，这些特定的注意力机制能够在不同的模型规模上提升性能。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">- RoPE嵌入</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">与传统的绝对位置嵌入不同，模型在每一层都使用了旋转位置嵌入技术，并且在模型的输入和输出之间共享嵌入，这样做可以有效减少模型的大小。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">- GeGLU激活函数</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">将标准的ReLU激活函数替换成GeGLU激活函数，可以提升模型的表现。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">- 归一化化位置（Normalizer Location）</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">每个Transformer子层的输入和输出都进行了归一化处理。这里采用的是RMSNorm作为归一化层，以确保模型的稳定性和效率。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">架构的核心参数如下：</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="356" data-backw="562" data-height="482" data-imgfileid="504962926" data-ratio="0.6342105263157894" data-type="png" data-w="760" data-width="760" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uqfvwfR7vkJGicfdbhr0DwB0EY7QFVhfzpZM2C6ZPDJ2BC4dO3sunWXA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">两种规模的参数如下：</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-height="342" data-imgfileid="504962931" data-ratio="0.45" data-type="png" data-w="760" data-width="760" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2ulCfGPPvo9ImEVkcnRyicB3L09pAPHVycepPUz6mpdICIeGvZSaHTM9A/640?wx_fmt=png&amp;from=appmsg"></p><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(255, 104, 39);"><strong><span style="font-size: 15px;letter-spacing: 1px;">预训练</span></strong></span></h3><h4 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">训练数据</span></strong></h4><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Gemma 2B和7B分别针对来自网络文档、数学和代码的主要英语数据的2T和6Ttoken，进行了训练。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">与Gemini不同，这些模型不是多模态的，也没有针对多语言任务的SOTA进行训练。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">谷歌使用了Gemini的SentencePiece分词器的子集，来实现兼容性。</span></p><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(255, 104, 39);"><strong><span style="font-size: 15px;letter-spacing: 1px;">指令微调</span></strong></span></h3><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">团队对Gemma 2B和7B模型进行了微调，包括有监督的微调（SFT）和基于人类反馈的强化学习（RLHF）。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在有监督的微调阶段，研究者使用了一个由纯文本、英文、由人工和机器生成的问题-答案对组成的数据集。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在强化学习阶段，则是使用了一个基于英文偏好数据训练出的奖励模型，以及一套精心挑选的高质量提示作为策略。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者发现，这两个阶段对于提升模型在自动评估和人类偏好评估中的表现，至关重要。</span></p><h4 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">监督微调</span></strong></h4><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者根据基于LM的并行评估，选择了数据混合物进行监督微调。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">给定一组保留prompt，研究者会从测试模型中生成响应，从基准模型中生成对相同提示的响应，随机洗牌，然后要求一个更大、能力更强的模型在两种响应之间表达偏好。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者构建了不同的提示集，以突出特定的能力，如遵循指令、实事求是、创造性和安全性。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">我们使用了不同的基于LM的自动评委，采用了一系列技术，如思维链提示、使用评分标准和章程等，以便与人类偏好保持一致。</span></p><h4 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">RLHF</span></strong></h4><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者进一步利用来自人类反馈的强化学习（RLHF），对已经进行过有监督微调的模型进行了优化。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">他们从人类评估者那里收集他们的偏好选择，并在 Bradley-Terry 模型的基础上，训练了一个奖励函数，这与Gemini项目的做法相似。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者采用了一个改进版的REINFORCE算法，加入了 Kullback–Leibler 正则化项，目的是让策略优化这个奖励函数，同时保持与最初调整模型的一致性。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">与之前的有监督微调阶段相似，为了调整超参数并进一步防止奖励机制被滥用，研究者使用了一个高性能模型作为自动评估工具，并将其与基准模型进行了直接对比。</span></p><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(255, 104, 39);"><strong><span style="font-size: 15px;letter-spacing: 1px;">性能评估</span></strong></span></h3><h4 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">自动评估</span></strong></h4><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">谷歌在多个领域对Gemma进行了性能评估，包括物理和社会推理、问答、编程、数学、常识推理、语言建模、阅读理解等。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Gemma2B和7B模型与一系列学术基准测试中的多个外部开源大语言模型进行了比较。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在MMLU基准测试中，Gemma 7B模型不仅超过了所有规模相同或更小的开源模型，还超过了一些更大的模型，包括Llama 2 13B。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><img class="rich_pages wxw-img" data-backh="472" data-backw="562" data-height="907" data-imgfileid="504962934" data-ratio="0.8398148148148148" data-type="png" data-w="1080" data-width="1080" style="width: 100%;height: auto;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uaWxRBcFUfGFT2r8l6BtBhjchbict03rvSUJTXswfkxLc0Xr4aV1l9ow/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">然而，基准测试的制定者评估人类专家的表现为89.8%，而Gemini Ultra是首个超越此标准的模型，这表明Gemma在达到Gemini和人类水平的性能上，还有很大的提升空间。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">并且，Gemma模型在数学和编程的基准测试中表现尤为突出。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在通常用于评估模型分析能力的数学任务中，Gemma 模型在GSM8K和更具挑战性的 MATH基准测试上至少领先其他模型10分。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">同样，在HumanEval上，它们至少领先其他开源模型6分。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Gemma甚至在MBPP上超过了专门进行代码微调的CodeLLaMA 7B模型的性能（CodeLLaMA得分为41.4%，而 Gemma 7B得分为44.4%）。</span></p><h4 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">记忆评估</span></strong></h4><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">近期研究发现，即便是经过精心对齐的人工智能模型，也可能遭受新型对抗攻击，这种攻击能够规避现有的对齐措施。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">这类攻击有可能使模型行为异常，有时甚至会导致模型重复输出它在训练过程中记住的数据。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">因此，研究者专注于研究模型的「可检测记忆」能力，这被认为是评估模型记忆能力的一个上限，并已在多项研究中作为通用定义。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">研究者对Gemma预训练模型进行了记忆测试。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">具体来说，他们从每个数据集中随机选择了10,000篇文档，并使用文档开头的50个词元作为模型的prompt。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">测试重点是精确记忆，即如果模型能够基于输入，精确地生成接下来的50token，与原文完全一致，便认为模型「记住了」这段文本。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">此外，为了探测模型是否能够以改写的形式记忆信息，研究者还测试了模型的「近似记忆」能力，即允许在生成的文本和原文之间存在最多10%的编辑差距。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在图2中，是Gemma的测试结果与体量相近的PaLM和PaLM 2模型的对比。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="348" data-backw="382" data-height="682" data-imgfileid="504962932" data-ratio="0.9093333333333333" data-type="png" data-w="750" data-width="750" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uaaFiaL2SPf49To4pbYfIQt72vqOrwj6KCm85KgUH7wicxzJPhbf4L8bw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">可以发现，Gemma的记忆率明显更低（见图2左侧）。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">不过，通过对整个预训练数据集的「总记忆量」进行估算，可得一个更为准确的评估结果（见图2右侧）：Gemma在记忆训练数据方面的表现与PaLM相当。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">个人信息的记忆化问题尤为关键。如图3所示，研究者并未发现有记忆化的敏感信息。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="451" data-backw="562" data-height="602" data-imgfileid="504962930" data-ratio="0.8026666666666666" data-type="png" data-w="750" data-width="750" style="width: 68%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2unkv6rDRPYxjEtGrOLjUjomAW85V8qFANabDu7wkrwj3iamSmHon4dTA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">虽然确实发现了一些被归类为「个人信息」的数据被记忆，但这种情况发生的频率相对较低。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">而且这些工具往往会产生许多误报（因为它们仅通过匹配模式而不考虑上下文），这意味着研究者发现的个人信息量可能被高估了。</span></p><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="color: rgb(255, 104, 39);"><strong><span style="color: rgb(255, 104, 39);font-size: 15px;letter-spacing: 1px;">总结讨论</span></strong></span></h3><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;"></span></h3><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">总的来说，Gemma模型在对话、逻辑推理、数学和代码生成等多个领域，都有所提升。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">在MMLU（64.3%）和MBPP（44.4%）的测试中，Gemma不仅展现了卓越的性能，还显示了开源大语言模型性能进一步提升的空间。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">除了在标准测试任务上取得的先进性能，谷歌也期待与社区共同推动这一领域的发展。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">Gemma从Gemini模型计划中学到了很多，包括编码、数据处理、架构设计、指令优化、基于人类反馈的强化学习以及评估方法。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">同时，谷歌再次强调使用大语言模型时存在的一系列限制。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">尽管在标准测试任务上表现优异，但要创建出既稳定又安全、能够可靠执行预期任务的模型，还需要进一步的研究，包括确保信息的准确性、模型的目标对齐、处理复杂逻辑推理，以及增强模型对恶意输入的抵抗力。</span></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;">团队表示，正如Gemini所指出的，需要更具挑战性和鲁棒性的测试基准。</span></p><div autoid="1895" data-style-type="0" style="max-width: 100%;white-space: normal;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><div style="padding: 8px;max-width: 100%;box-sizing: border-box;border-left: 6px solid rgb(255, 202, 0);font-size: 18px;line-height: 1.4;font-family: inherit;font-weight: bold;text-decoration: inherit;border-top-color: rgb(255, 202, 0);border-right-color: rgb(255, 202, 0);border-bottom-color: rgb(255, 202, 0);overflow-wrap: break-word !important;"><p style="line-height: 1.75em;margin-bottom: 0px;">团队成员</p></div></div><h3 style="margin-right: 8px;margin-bottom: 24px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"></h3><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">核心贡献者：</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="532" data-backw="330" data-height="532" data-imgfileid="504962933" data-ratio="1.612121212121212" data-type="png" data-w="330" data-width="330" style="width: 35%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uVEhmU1NRyrpmSW8QBtFMmDa8Tiac0gh8zticOrNMT2QndibSgeOibdibxpg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">其他贡献者：</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="1440" data-backw="562" data-height="1947" data-imgfileid="504962899" data-ratio="2.5618421052631577" data-type="png" data-w="760" data-width="760" style="width: 79%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2uLotot5Pn7zfBrLp1sWsbG0zhhxWI6l3S6ib0MhWVbziao62DXdtp9pHQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;">产品经理、项目经理、执行赞助、负责人和技术负责人：</span></strong></p><p style="margin-right: 8px;margin-left: 8px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;text-align: center;"><img class="rich_pages wxw-img" data-backh="1102" data-backw="400" data-height="1102" data-imgfileid="504962898" data-ratio="2.755" data-type="png" data-w="400" data-width="400" style="width: 35%;height: auto !important;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/UicQ7HgWiaUb3ibh1mUYV7Rw86DOmxibMg2u8y4KbcjEMnRug1c9PpljDgzkJc0xTsdLgkWzoicaS2mbzTsVY5UQ1cw/640?wx_fmt=png&amp;from=appmsg"></p><p style="max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: left;line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="letter-spacing: 1px;"><br></span></p><p style="max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: left;line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;">参考资料：</span></p><p style="max-width: 100%;min-height: 1em;white-space: normal;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);text-align: left;line-height: 1.75em;margin-left: 8px;margin-right: 8px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="font-size: 14px;color: rgb(136, 136, 136);letter-spacing: 1px;">https://ai.google.dev/gemma/</span></p><p style="text-align: center;margin-bottom: 0px;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;"><img class="rich_pages wxw-img" data-backh="420" data-backw="562" data-galleryid="" data-imgfileid="504962896" data-ratio="0.7472222222222222" data-s="300,640" data-type="jpeg" data-w="1080" style="outline: 0px;width: 100%;display: initial;box-sizing: border-box !important;overflow-wrap: break-word !important;visibility: visible !important;height: auto;" src="https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb1lKYCMMiaxGxWTbkaPTAxuR84iaPsp8u8Yg0okpLUj3ibsPkwdQXjibPcp8oW1jmJAmZmMEia2sjDKpGA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;box-sizing: border-box !important;overflow-wrap: break-word !important;"><br></p><p style="margin-right: 8px;margin-bottom: 0px;margin-left: 8px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.75em;box-sizing: border-box !important;overflow-wrap: break-word !important;"><img class="rich_pages wxw-img __bg_gif" data-imgfileid="504962897" data-ratio="0.1540880503144654" data-type="gif" data-w="636" style="outline: 0px;display: initial;box-sizing: border-box !important;overflow-wrap: break-word !important;width: 367px !important;visibility: visible !important;" src="https://mmbiz.qpic.cn/mmbiz_gif/UicQ7HgWiaUb10PoMc8QQNrjsp8lOMiaPwVkHbjVicxntJynwdmjiadosl2znIvDTSjWsp4kcqlbqVdFt6TxqpptrkA/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1"></p><p style="margin-left: 8px;margin-right: 8px;margin-bottom: 24px;line-height: 1.75em;"><br></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name>新智元</name>
        </author>
    </entry>
</feed>