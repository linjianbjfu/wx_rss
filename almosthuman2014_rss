<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>almosthuman2014</id>
    <title>机器之心</title>
    <updated>2024-03-05T03:00:22.276Z</updated>
    <generator>awesome</generator>
    <author>
        <name>机器之心</name>
    </author>
    <subtitle>专业的人工智能媒体和产业服务平台</subtitle>
    <logo>http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Hw3m9nYrAsOLx3ZicPxogLrGibnMYybTBN7EGzEhCVulznVbDob2ib3mwdMMQXtOhO6bqCdSz9kX7w/0?wx_fmt=png</logo>
    <icon>http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Hw3m9nYrAsOLx3ZicPxogLrGibnMYybTBN7EGzEhCVulznVbDob2ib3mwdMMQXtOhO6bqCdSz9kX7w/0?wx_fmt=png</icon>
    <entry>
        <title type="html"><![CDATA[生成式 AI 时代，手机正在进行一次全栈革新？]]></title>
        <id>2650909512_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909512&amp;idx=1&amp;sn=fdf171220387e754d383ae66706b2cd4&amp;chksm=84e46f36b393e620f46bc5f78e775216cf9fbf04092e3f1d075a7cbb2c5554eea7f56dcb6d02#rd"/>
        <updated>2024-03-05T02:48:45.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 1.75em;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心发布</span></p><p style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 1.75em;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：泽南</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="16" data-source-title=""><div class="js_blockquote_digest"><p>手机行业的第三次重大变革开始了。</p></div></blockquote><p><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">最近一段时间，AI 与大模型技术突飞猛进。春节刚过，前沿方向上就迎来了新一轮突破。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425719" data-ratio="1.775" data-type="gif" data-w="320" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0NO6jIOSk3n18L4pWY0feJ3WXKvLcsF9riafbuQHsJJ8VxF1tibpsI5yQ/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">OpenAI 的 Sora 一下子把 AI 视频生成的进度条拉快了半年。</span></em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在大模型的应用领域，技术落地应用的速度也在加快。目前各家大厂的新一代旗舰手机已经悉数登场，它们绝大多数都搭载了大模型，能实现很多前所未有的功能。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425718" data-ratio="0.5616" data-type="gif" data-w="625" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0CKibic16xgQH3icT8VIYWjOviaoq0WRMSUb7Lia5H9ObdHSKVo8vn69FkpA/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图片来自高通骁龙 8Gen3 宣传片：https://www.youtube.com/watch?v=0CqtpjlL25w</span></em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为什么大家都选择在 2024 年入局 AI ？</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">答案似乎很明确。随着大模型逐步成熟、芯片端侧算力的增强，手机厂商有了明确的判断：2024 年将是 AI 手机的元年。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">不过面对一致的目标，各家打法不尽相同：很多手机开始引入云端大模型应用，也有一些实现了小尺寸模型的端侧跑通。在这其中，已经落地多个 AI 功能的 OPPO Find X7 系列正在获得越来越多的认可。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">它做到了很多个「第一」：Find X7 是全球首个端侧应用 70 亿参数大语言模型的手机。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">它还是第一个支持 AI 通话摘要的手机，让用户可以在通话结束后让 AI 一键生成摘要，并自动生成待办事项和提醒：</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425720" data-ratio="0.4564814814814815" data-type="gif" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0GtKagz4Zw5bC8wo7WClyl7iboCnJ0rPTXCLvUhibJEZpFLropUdicbY2g/640?wx_fmt=gif&amp;from=appmsg"><span style="font-size: 15px;letter-spacing: 0.034em;text-align: justify;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">有了手机端 AI 大模型的加持，智能助手也不再是个「摆设」，OPPO 的小布助手实现了跨越式的体验提升。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">现在的小布能够更好地理解自然语言，还可以回答各种刁钻的问题。它拥有超过 100 种能力，包括文字生成图片、图片解释、AI 文章摘要等，能在办公效率、生活服务、学习教育等不同维度为用户提供帮助。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">比如你可以问小布为什么饼干上有很多小孔，并要求它以「四岁孩子能理解的方式」回答：</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425711" data-ratio="0.4675925925925926" data-type="gif" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0wcl4TCdlnLofOIL5X6ecyialGU6xUibRdxZiaJpiaWXVicZiauib3k1M2ic5DA/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO 还带来了全新的 AIGC 消除功能。以往需要电脑专业软件复杂操作的改图任务，现在在手机上只需要简单一圈 AI 就能帮你完成主体消除、实景重绘。在这个过程中，大模型还能进行一定程度的「创作」，脑补出背景，得到一张没有人潮的风景照：</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425715" data-ratio="0.4564814814814815" data-type="gif" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0CnprNnkmTLxL6QzmNOLVHkzLw98JWicr9s3xYEicQKd7cbtd4oBz3U1Q/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Find X7 的大模型能力不仅支持超过 120 类主体的识别与分割，还可以实现发丝级的分割、多达 6 个的多主体分离。这就是手机端生成式 AI 时代的拍照新体验。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">手机作为最常见的消费电子产品，一直是各种 AI 技术优先落地的方向，AI 美颜、AI 助手等功能早已是智能手机的标配。而随着大模型的兴起，手机作为人类「外延器官」了解用户的优势，再加上生成式 AI 前所未有的突破，又带来了更智能、个性化的体验和更多样的玩法。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">AI 手机或许将是继功能机、智能机之后，手机行业的第三个重大变革阶段。而在这场变革中，OPPO 提前为我们展示了大模型技术突破后，手机的全新形态。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">端侧 70 亿参数大模型</span></strong></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">为什么 OPPO 做到了？</span></strong></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO Find X7 能够实现的很多新能力，得益于端侧运行的 70 亿参数大模型。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在这代旗舰机上，首次搭载了OPPO 自主训练的 AndesGPT 70 亿参数大模型。通过端云协同的部署，它实现了领先不止一代的 AI 体验。相比 10 亿参数模型，该模型能展现出更高「智商」的理解能力，可以更准确地理解对话内容并生成重点明确、细节丰富的摘要内容。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">相比于同平台的其他模型，AndesGPT 70 亿参数版可以在 2000 字首字生成时带来 20 倍的更快响应，最高对 1.4 万字进行内容摘要，是其他模型的 3.5 倍，对话体验也更接近人类对话的速度与信息量。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425722" data-ratio="0.3333333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0rfp79hicq1QMmjPzPW6FbQTWicQZYO7vfm3A0yac7Jib2RGq463I85SoA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我们知道，当前的大模型军备竞赛中，各家科技公司都在抢购 GPU，毕竟跑大模型很耗费算力。要在算力与内存有限的手机上运行大模型并不是件简单的事，OPPO 是如何做到的？</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这是因为在新一代手机上，OPPO 实现了面向大模型，从软件、硬件到云平台的全面优化。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">首先，OPPO 与平台厂商进行紧密协作，基于对芯片的理解，和一直以来对于用户需求的洞察和理解，根据大模型和算法深度定制了 SoC 芯片，提升了高负载条件下芯片的运行调度，进而优化了大模型的运行效率。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425723" data-ratio="0.3333333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0pKCDwPWtpeU2FdKy34GiafP090cdVyV67kd3IwEtJDGbtBAIPlsXdzQ/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">对于用户需求的洞察和理解是 OPPO 的核心竞争力，通话智能摘要就是个好例子：通话录音是业内早已出现的功能，但将传统的通话录音与端侧大模型结合，就带来了颠覆传统应用的全新 AI 体验。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">大模型部署在端侧，除了需要计算资源的极致优化，另一个瓶颈在于存储。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在正常情况下，70 亿参数的大模型需要占用 28GB 内存。为了真正实现端侧部署，OPPO 用 INT4 量化的方式对模型进行了大幅度压缩，让原本占用 28GB 内存的模型现在只需要 3.9GB，既降低了资源需求，也几乎不影响 AI 模型的输出效果。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">「大模型在端侧性能消耗比较大，要通过并行计算的算子优化、对内存管理的优化等来降低损耗和系统资源占用。续航方面要根据用机情况来看，我们端侧大模型的功耗控制在用户可以接受的范围内」OPPO AI 中心产品总监张峻表示。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO 还是第一家真正意义上把端侧 70 亿参数大模型同时部署在高通和 MTK 两个不同平台的手机厂商，对用户「一视同仁」的同时，也验证了自身对 AI 优化部署的能力。目前，端侧视觉模型的手机端部署也被列在了他们的日程表上。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">对于生成式 AI 能力来说，有时端侧模型无法处理的复杂任务，需要把数据传到云端，利用服务器端 AI 加速器的力量；而很多包含个人信息和偏好的信息，需要在手机端侧预先处理，以保证隐私。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">大模型的端云协同，是目前行业的共识。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在这一方面，OPPO 在发布 AndesGPT 大模型时，提出了通过三级大模型部署策略实现的端云联合部署，满足了多场景高效适配。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425724" data-ratio="0.37222222222222223" data-type="png" data-w="1080" style="font-size: 15px;letter-spacing: 0.034em;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0cG48jFzQ2ibibt2ZqIKT6YVB1GzZ3MXibYCQTXOYxJKWIPM4uwic6epOQg/640?wx_fmt=png&amp;from=appmsg"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在端云协同的架构下，OPPO AI 手机的算力供给不再局限于本地，同时用户信息也能保证不被泄露 —— 用户数据仅在端侧计算，云端更强大的计算能力则面向复杂任务处理，既提高了大模型计算时的整体性能和效率，也保证了安全。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">AI 技术能力之外，OPPO 还有一个大战略。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><span style="font-size: 16px;"><strong>加码 AI 战略</strong></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><span style="font-size: 16px;"><strong>人工智能投入无上限</strong></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">其实，OPPO 已在 AI 领域深耕多年：早在2020年，OPPO就已经开始探索大语言模型的训练、应用与落地，首个自研大模型 OBERT一度跃居中文大规模知识图谱问答KgCLUE排行榜的首位；2023 年，OPPO 自主训练的安第斯大模型（AndesGPT）在 Super CLUE 知识与百科能力排行榜上仅次于 GPT 4，领先于所有竞品。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">此外，Find X7 上在端侧应用的 70 亿大模型，AI 算力跑分也在安卓榜单上名列第一。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO 创始人兼 CEO 陈明永判断，2024 年将是 AI 手机元年，五年内 AI 对手机行业的影响将不可忽视。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">2 月 20 日，OPPO 召开 AI 战略发布会，分享了他们在 AI 战略上详细的规划。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img" data-galleryid="" data-imgfileid="503425712" data-ratio="0.53" data-type="gif" data-w="600" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID06EllvuNMWAlFZSykkTicib8FISHOdicKcQTfTFGhAj2OfNqreIfPArklg/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO 对真正的 AI 手机下了定义，认为其需要具备以下四大特征：</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">能高效利用计算资源，满足生成式 AI 的计算需要；</span></p></li><li><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">能敏锐感知真实世界，了解用户与环境的复杂信息；</span></p></li><li><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">有强大的自我学习能力；</span></p></li><li><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">具备更充沛的创作能力，为用户提供持续的灵感与知识支持。</span></p></li></ul><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为了适应这些能力需求，手机行业需要进行全面的技术革新与生态重构：在硬件架构上，高效能的 AI 算力底座、模型库的管理优化以及智慧仿生感知能力将成为 AI 手机的新的标准。AI 手机的 OS 系统通过内嵌智能体，将能高效地处理复杂任务，并可以主动创作。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">另一方面，未来的 AI 手机将支持更敏锐、更准确的自然语义理解，拥有更强大的自学习能力，可提供更符合直觉的多模态交互。由此看来，传统的应用生态将会在 AI 手机时代转向智能体生态，各类服务应用都会与 AI 能力无缝连接，实现真正的智能化服务。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p><img class="rich_pages wxw-img" data-imgfileid="503425725" data-ratio="0.3333333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0F9iaFNjpMB6f42Ge5IQJSicPhdwoj3ovppicvIl29E0EibIiac9B84KGnlg/640?wx_fmt=png&amp;from=appmsg"><span style="font-size: 15px;letter-spacing: 0.034em;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为此，OPPO 已经做足了准备。在云端算力上，OPPO 拥有能够支持千亿级 AI 模型训练的 OPPO AI 滨海湾数据中心，支持两毫秒的骨干网络链接超低时延，以及 100% 的纯绿色能源。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">未来，OPPO 将在算力上持续投入，部署 AndesGPT Titan、Turbo、Tiny 三个级别的模型以对应不同应用场景。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425726" data-ratio="0.3333333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0foS7SPdtxzrxbTBW5c5ibdLSiaIhndN6H0ZncM3wt8dNz44RibdJtKTPQ/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在 Agent 能力上，OPPO 正式发布了 1+N 智能体生态战略。其中的「1」代表 OPPO AI 超级智能体，它基于知识图谱、文档数据以及搜索引擎，能精准理解用户意图，给出准确结果，充分调用其他多种工具；「N」则代表基于 OPPO AI Pro 智能体开发平台所赋能的全新智能体生态。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">相比大模型智能助手，智能体是更加快捷和主动的 AI 助手，可以根据你的设定，以最有效的方式完成各种目标，满足情感陪伴、求知探索、娱乐闲聊等多样的场景需求。同时，构建智能体的方法非常简便，无需编程代码基础，人们只需和大模型进行自然语言对话，提供必要的说明和知识即可。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">智能体也可以与大模型以外的其他服务相连接，访问更多信息和手机功能，以通用化的能力满足用户的各类需求。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">更重要的是，OPPO 的 1+N 也意味着联合更多合作伙伴与开发者。随着智能体布局的展开，人们就能共同打造出面向 AI 手机生态的服务体系。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">就像智能手机上的 APP 应用市场。不过这次，由 AI 连接的服务能力更强，与你的连接更紧密。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">OPPO 还在继续加码 AI。战略发布会上，OPPO 正式宣布成立 AI 中心，旨在整合研发资源，针对 AI 进行能力建设与研发。刘作虎表示，AI 中心的成立将汇聚整个公司的力量，已把 AI 作为手机下一个时代最重要的战略，对于投入不设上限。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">大模型加持的手机</span></strong></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">还会如何进化？</span></strong></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这还只是个开始。毕竟大模型是一个「改变世界」的技术，所有领域的应用都要用 AI 重做一遍。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">最近，在人工智能上，很多人都有大动作：苹果停止了自己持续多年的造车项目，并将探索重点也转向生成式 AI；谷歌在发布原生多模态大模型 Gemini 时宣布，未来大模型会整合至安卓系统中；而高通在 MWC 大会上推出的新一代 AI Hub，已支持超过 75 种主流 AI 模型在端侧的加速。现在，从手机厂商到科技公司，再到芯片公司，英雄所见略同。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我们可以预见，随着技术的进步与行业生态的构建，未来我们还会看到更加智能化的拍照、更快捷的人机交互、更加个性化的内容生成和更高效的任务处理。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">使用生成式 AI，过去复杂的工作将会变得更简单。人们可以无需打开专业软件，仅发出口头指令就能让 AI 自动完成复杂的工作，大幅提升工作效率。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">部署在端侧的生成式 AI，也可以让智能手机更加了解用户的习惯和所处位置。利用情境信息，数字助手将会更加个性化，带来更令人满意的答案，提供更主动的服务。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">更进一步，随着 AI 生成能力逐步进入多模态领域，下一代 AI 渲染工具将能利用文本、语音、图像或视频等各种类型的提示生成 3D 物体和场景，最终创造出全新的沉浸式内容体验。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">一句话，AI 手机将会为我们带来一场革命。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425727" data-ratio="0.5775" data-s="300,640" data-type="gif" data-w="400" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0IYzzGMGzeEWLIXrbUcEPBC4x56zn0u1NM7Lz8uzvMbYNALQ0JvPfhQ/640?wx_fmt=gif&amp;from=appmsg"></p><p style="text-align: center;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">随着 OPPO 等手机厂商对 AI 技术的不断推动，我们与想象之间的距离已经近了。</span></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>关注大模型的</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[全面超越GPT-4，Claude 3终于来了，有大学生智商，支持百万token]]></title>
        <id>2650909461_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909461&amp;idx=1&amp;sn=b68ab649d8c55f94c5a9d4fd7ea9b010&amp;chksm=84e46f6bb393e67d59c7a527d9fa90ace7e5c4b0216208fed218c05e9ab8d73a747087dd6eee#rd"/>
        <updated>2024-03-04T16:54:40.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 1.75em;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span></p><p style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 1.75em;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="12" data-source-title=""><div class="js_blockquote_digest"><p><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">性能比 GPT-4 强很多。</span></p></div></blockquote><p><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">大模型的纯文本方向，已经卷到头了？</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">刚刚，OpenAI 最大的竞争对手 Anthropic 发布了新一代 AI 大模型系列 ——Claude 3。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">该系列包含三个模型，按能力由弱到强排列分别是 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus。其中，能力最强的 Opus 在多项基准测试中得分都超过了 GPT-4 和 Gemini 1.0 Ultra，在数学、编程、多语言理解、视觉等多个维度树立了新的行业基准。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Anthropic 表示，Claude 3 Opus 拥有人类本科生水平的知识。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425784" data-ratio="1.4709110867178925" data-type="png" data-w="911" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID09J8Jd4UZyNaictjy28po8AlqmQ7sjmcTHQ0I9koIPtwEXojJXYF6Fqw/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">在新模型发布后，Claude 首次带来了对多模态能力的支持（Opus 版本的 MMMU 得分为 59.4%，超过 GPT-4V，与 Gemini &nbsp;1.0 Ultra 持平）。用户现在可以上传照片、图表、文档和其他类型的非结构化数据，让 AI 进行分析和解答。</span></p><p style="line-height: 1.75em;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3355015436458770433" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWicJl5G6IHORtWvwpmicdIID0NvibRLkwlhTATy9GOTYlTVYEkRt3Ef8aiaMPj38nyaEXlBq7R6qpaRJg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3355015436458770433"></iframe></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">此外，这三个模型也延续了 Claude 系列模型的传统强项 —— 长上下文窗口。其初始阶段支持 200K token 上下文窗口，不过，Anthropic 表示，三者都支持 100 万 token 的上下文输入（向特定客户开放），这大约是英文版《白鲸》或《哈利・波特与死亡圣器》的长度。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">不过，在定价上，能力最强的 Claude 3 也比 GPT-4 Turbo 要贵得多：GPT-4 Turbo 每百万 token 输入 / 输出收费为 10/30 美元 ；而 Claude 3 Opus 为 15/75 美元。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425785" data-ratio="0.38055555555555554" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0Y4YVicklmqyR3ddNKnozD631QBtIBvG3asACAK4h6WUwhxXbWaBnuicw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Opus 和 Sonnet 现可在 claude.ai 和 Claude API 中使用，Haiku 也将于不久后推出。亚马逊也第一时间宣布新模型登陆了 Amazon Bedrock。以下是 Anthropic 发布的官方 demo：</span></p><p style="line-height: 1.75em;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3355023918750744581" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWicJl5G6IHORtWvwpmicdIID0iaKkgb1Liawfto9OOWUcE4qJm8agVhNZSl2kiafellF1bLoOgqmvtfCwg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3355023918750744581"></iframe></p><p style="line-height: 1.75em;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3355025180179283970" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gWicJl5G6IHORtWvwpmicdIID085ytEkZo72LIHuVKtOGTAN15lbe7SQlS52NSx3sdMIcx7hA2hYMUJQ%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3355025180179283970"></iframe></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">在 Anthropic 官宣之后，不少得到试用机会的研究者也晒出了自己的体验。有人说，Claude 3 Sonnet 解出了一道此前只有 GPT-4 才能解开的谜题。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425786" data-ratio="1.1333333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0mJlUibs13m24xXpVwia7HG5X87XNicVpYDekViag3myxfkvHZjiaCCB7mMw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">不过，也有人表示，在实际体验方面，Claude 3 并没有彻底击败 GPT-4。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425787" data-ratio="0.5690515806988353" data-type="png" data-w="601" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0B6gITWnlEwQXoWXaLDVgk0M9TgMS1YnukUFtF56MubY6poiaMduWcAw/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">Claude 3 系列模型</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 系列模型的三个版本分别是 Claude 3 Opus、Claude 3 Sonnet 和 Claude 3 Haiku。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425788" data-ratio="0.5743380855397149" data-type="png" data-w="982" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0WyIbJPLOXMlG8GibVSyYWlcBUxRP7ic1ic6vicpKMiazk5KbdibNjN6fDhKw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">其中 Claude 3 Opus 是智能程度最高的模型，支持 200k tokens 上下文窗口，在高度复杂的任务上实现了当前 SOTA 的性能。该模型能够以绝佳的流畅度和人类水平的理解能力来处理开放式 prompt 和未见过的场景。Claude 3 Opus 向我们展示了生成式 AI 可能达到的极限。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425789" data-ratio="0.881619937694704" data-type="png" data-w="963" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0JEGzKkY1iafHWQLcQQc8XD9cRPz8epbzo6iabzUvWsNWXoUEUmlRA5iaQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 Sonnet 在智能程度与运行速度之间实现了理想的平衡，尤其是对于企业工作负载而言。与同类模型相比，它以更低的成本提供了强大的性能，并专为大规模 AI 部署中的高耐用性而设计。Claude 3 Sonnet 支持的上下文窗口为 200k tokens。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425790" data-ratio="0.7477110885045778" data-type="png" data-w="983" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0uT8af1q1AJaxzUSIKrybkhn8atU1lEx7e5ibzXU8S8icJgS2IRVF5gRQ/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 Haiku 是速度最快、最紧凑的模型，具有近乎实时的响应能力。有趣的是，它支持的上下文窗口同样是 200k。该模型能够以无与伦比的速度回答简单的查询和请求，用户通过它可以构建模仿人类交互的无缝 AI 体验。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425791" data-ratio="0.7903391572456321" data-type="png" data-w="973" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0pib5icZaVVdO3499HLXO9iaPpF2pibgIXqpE2k5NVNHFnwbUa0yj7jaRdA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 0.034em;">接下来我们详看一下 Claude 3 系列模型的特性和性能表现。</span><br></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">全面超越 GPT-4，实现智能水平新 SOTA</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">作为 Claude 3 系列中智能水平最高的模型，Opus 在 AI 系统的大多数评估基准上都优于竞品，包括本科水平专家知识（MMLU）、研究生水平专家推理（GPQA） 、基础数学（GSM8K）等基准。并且，Opus 在复杂任务上表现出接近人类水平的理解力和流畅度，引领通用智能的前沿。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">此外，包括 Opus 在内，所有 Claude 3 系列模型都在分析和预测、细致内容创建、代码生成以及西班牙语、日语和法语等非英语语言对话方面实现了能力增强。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">下图为 Claude 3 模型与竞品模型在多个性能基准上的比较，可以看到，最强的 Opus 全面优于 OpenAI 的 GPT-4。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425792" data-ratio="0.887962962962963" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0ML0NAia3skn6yQXeeHJ3Mg0hRhticLSfsnATvNJIMEgzdDImhadSc2bA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;">近乎实时响应</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 模型可以支持实时客户聊天、自动补充和数据提取等响应必须立即且实时的任务。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Haiku 是智能类别市场上速度最快且最具成本效益的型号。它可以在不到三秒的时间内读完一篇包含密集图表和图形信息的 arXiv 平台论文（约 10k tokens）。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">对于绝大多数工作，Sonnet 的速度比 Claude 2 和 Claude 2.1 快 2 倍，且智能水平更高。它擅长执行需要快速响应的任务，例如知识检索或销售自动化。Opus 的速度与 Claude 2 和 2.1 相似，但智能水平更高。</span></p><p style="line-height: 1.75em;text-align: left;"><br></p><p style="line-height: 1.75em;"><strong><span style="font-size: 15px;">强大的视觉能力</span></strong><span style="font-size: 15px;">&nbsp;</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 具有与其他头部模型相当的复杂视觉功能。它们可以处理各种视觉格式数据，包括照片、图表、图形和技术图表。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Anthropic 表示，它们的一些客户 50% 以上的知识库以各种数据格式进行编程，例如 PDF、流程图或演示幻灯片。因此，新模型强大的视觉能力非常有帮助。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425793" data-ratio="0.4361111111111111" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0yE27gX2eEDwcsMwu2djfwD1G8QcPJBYQWXeD3EYqMwohWxV2iatf96Q/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;">更少拒绝回复</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">以前的 Claude 模型经常做出不必要的拒绝，这表明模型缺乏语境理解。Anthropic 在这一领域取得了有意义的进展：与前几代模型相比，即使用户 prompt 接近系统底线，Opus、Sonnet 和 Haiku 拒绝回答的可能性明显降低。如下所示，Claude 3 模型对请求表现出更细致的理解，能够识别真正的有害 prompt，并且拒绝回答无害 prompt 的频率要少得多。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425794" data-ratio="0.41944444444444445" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0duAQxVcrSIwtibEcuK59DfAKn2F15TdpMhJiciapab8vY5GBaebNz4dRQ/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;">准确率提高</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">为了评估模型的准确率，Anthropic 使用了大量复杂的、事实性问题来解决当前模型中的已知弱点。Anthropic 将答案分为正确答案、错误答案（或幻觉）和不确定性回答，也就是模型不知道答案，而不是提供不正确的信息。与 Claude 2.1 相比，Opus 在这些具有挑战性的开放式问题上的准确性（或正确答案）提高了一倍，同时也减少了错误回答。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">除了产生更值得信赖的回复之外，Anthropic 还将在 Claude 3 模型中启用引用，以便模型可以指向参考材料中的精确句子来证实回答。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425795" data-ratio="0.4074074074074074" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0bKbUnEiaL56NNUofzpWziaFVO9szLfziak5VCqibdmOqwRRruL51SjZlNg/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: left;"><strong><span style="font-size: 15px;">长上下文和近乎完美的召回能力</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 系列型号在发布时最初将提供 200K 上下文窗口。然而，官方表示所有三种模型都能够接收超过 100 万 token 的输入，此能力会被提供给需要增强处理能力的特定用户。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">为了有效地处理长上下文提示，模型需要强大的召回能力。Needle In A Haystack（NIAH）评估衡量模型可以从大量数据中准确回忆信息的能力。Anthropic 通过在每个提示中使用 30 个随机 Needle/question 对在不同的众包文档库上进行测试，增强了该基准的稳健性。Claude 3 Opus 不仅实现了近乎完美的召回率，超过 99% 的准确率。而且在某些情况下，它甚至识别出了评估本身的局限性，意识到「针」句子似乎是人为插入到原始文本中的。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425796" data-ratio="0.49444444444444446" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0JfibyicY67FnAM1eTtkQVpWbkIXRxMcFiazGMZn36k8hzxKEvqicqwJqqA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><strong style="text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 15px;">安全易用</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Anthropic 表示，其已建立专门团队来跟踪和减少安全风险。该公司也在开发 Constitutional AI 等方法来提高模型的安全性和透明度，并减轻新模式可能引发的隐私问题。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">虽然与之前的模型相比，Claude 3 模型系列在生物知识、网络相关知识和自主性的关键指标方面取得了进步，但根据研究，新模型处于 AI 安全级别 2（ASL-2）以内。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">在使用体验上，Claude 3 比以往模型更加擅长遵循复杂的多步骤指令，更加可以遵守品牌和响应准则，从而可以更好地开发可信赖的应用。此外，Anthropic 表示 Claude 3 模型现在更擅长以 JSON 等格式生成流行的结构化输出，从而可以更轻松地指导 Claude 进行自然语言分类和情感分析等用例。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">技术报告里写了什么</span></strong></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">目前，Anthropic 已经放出了 42 页的技术报告《The Claude 3 Model Family: Opus, Sonnet, Haiku》。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425797" data-ratio="0.7267441860465116" data-type="png" data-w="860" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0Aic30peeBMpJffFvGn1bDFa7iaVXfDUBLiaoJ1dTictGdWalOyZ3tcyzUA/640?wx_fmt=png&amp;from=appmsg"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(123, 12, 0);">报告地址：https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">我们看到了 Claude 3 系列模型的训练数据、评估标准以及更详细的实验结果。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">在训练数据方面，Claude 3 系列模型接受了截至 2023 年 8 月互联网公开可用的专用混合数据的训练，以及来自第三方的非公开数据、数据标签服务商和付费承包商提供的数据、Claude 内部的数据。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 系列模型在以下多个指标上接受了广泛的评估，包括：</span></p><p style="line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="line-height: 1.75em;"><span style="font-size: 15px;">推理能力</span></p></li><li><p style="line-height: 1.75em;"><span style="font-size: 15px;">多语言能力</span></p></li><li><p style="line-height: 1.75em;"><span style="font-size: 15px;">长上下文</span></p></li><li><p style="line-height: 1.75em;"><span style="font-size: 15px;">可靠性 / 事实性</span></p></li><li><p style="line-height: 1.75em;"><span style="font-size: 15px;">多模态能力</span></p></li></ul><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">首先是推理、编程和问答任务上的评估结果，Claude 3 系列模型在一系列推理、阅读理解、数学、科学和编程的行业标准基准上与竞品模型展开了比较，结果显示不仅超越了自家以往模型，还在大多数情况下实现了新 SOTA。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425798" data-ratio="1.1398148148148148" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0CHsAXftRhEnw0uy1Z7uYLFOt8bmIwvriccL82SZvZjaicNFq4ibuF2YZg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Anthropic 在法学院入学考试 (LSAT) 、多州律师考试 (MBE)、美国数学竞赛 2023 年数学竞赛和研究生入学考试 (GRE) 普通考试中评估了 Claude 3 系列模型，具体结果如下表 2 所示。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><img class="rich_pages wxw-img" data-imgfileid="503425799" data-ratio="0.5351851851851852" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0cmJPoNHLy7T1wRzsmZJunEfibHWpiagyeYGz8liaM4smldbRDGVVXRYNg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 系列模型具备多模态（图像和视频帧输入）能力，并且在解决超越简单文本理解的复杂多模态推理挑战方面取得了重大进展。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">一个典型的例子是 Claude 3 模型在 AI2D 科学图表基准上的表现，这是一种视觉问答评估，涉及图表解析并以多项选择格式回答相应的问题。&nbsp;</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">Claude 3 Sonnet 在 0-shot 设置中达到了 SOTA 水平 —— 89.2%，其次是 Claude 3 Opus（88.3%）和 Claude 3 Haiku（80.6%），具体结果如下表 3 所示。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425800" data-ratio="0.6592592592592592" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0toAgtO6UNh02J9Bh9TafDyMMUgnTPYRSEXKAd6ecTSHjGRZteOOr4A/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">针对这份技术报告，爱丁堡大学博士生符尧在第一时间给出了自己的分析。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">首先，在他看来，被评估的几个模型在 MMLU / GSM8K / HumanEval 等几项指标上基本没有区分度，真正需要关心的是为什么最好的模型在 GSM8K 上依然有 5% 的错误。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425801" data-ratio="0.8194444444444444" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0UcrGJvaB4kXIQObaMuhuH3vgPSosZ8o9zaLlNcT44xdUMtBQ7GbOlw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">他认为，真正能够把模型区分开的是 MATH 和 GPQA，这些超级棘手的问题是 AI 模型下一步应该瞄准的目标。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425802" data-ratio="0.8074074074074075" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0P9AUpj1k9GtArXylhOE8MhIQ2uq2nps44taHbcKzn2qmh3wTicC0pUw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">与 Claude 之前的模型相比，改进比较大的领域是金融和医学。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425803" data-ratio="0.9203703703703704" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0o2pWib9ibxbTI0Hqich9ibYsItQd9sNptVU7V04VK3AicXFh3ER6hZfTEpw/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">视觉方面，Claude 3 表现出的视觉 OCR 能力让人看到了它在数据收集方面的巨大潜力。</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425804" data-ratio="1.0833333333333333" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0zVUiaTtalvZtdgbQVVsncA1ichSDB8KaKpy0OnLnrLlNJhiagm1NFwL1w/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">此外，他还发现了其他一些趋势：</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425805" data-ratio="0.8546296296296296" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0xYaSuoU56HibTqqRoEIeeeDIfQ8yyfjXMa8wPrbh0RsDj1yLKtwcTUQ/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425806" data-ratio="0.7824074074074074" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0aHtCtbvpdlj4MoI6frBPMK1ncibeW9uV99H7bJzNgicFVBRc5DzKibldA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">从目前的评测基准和体验看来，Claude 3 在智能水平、多模态能力和速度上都取得了长足的进步。随着新系列模型的进一步优化和应用，我们或许将看到更加多元化的大模型生态。</span></p><p style="line-height: 1.75em;"><br></p><p style="line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(123, 12, 0);">博客地址：https://www.anthropic.com/news/claude-3-family</span></p><p style="line-height: 1.75em;text-align: left;"><em><span style="color: rgb(123, 12, 0);font-size: 12px;"><br></span></em></p><p style="line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考内容：https://www.cnbc.com/2024/03/04/google-backed-anthropic-debuts-claude-3-its-most-powerful-chatbot-yet.html</span></em></span></p><p style="line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.aboutamazon.com/news/aws/amazon-bedrock-anthropic-ai-claude-3</span></em></span><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></p><p style="line-height: 1.75em;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425807" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>关注大模型的</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[精彩程度堪比电视剧，马斯克与奥特曼、OpenAI的「爱恨纠缠史」]]></title>
        <id>2650909335_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909335&amp;idx=1&amp;sn=39748ece77059f08e95b56f0f0f08434&amp;chksm=84e46ee9b393e7fff40e5c573b3680544aa7881480861353aac362a2ad6d0d30a5bdc5b8f82a#rd"/>
        <updated>2024-03-04T04:27:18.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心编译</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="46" data-source-title="" style="letter-spacing: 0.578px;text-wrap: wrap;"><div class="js_blockquote_digest"><p style="line-height: 1.75em;">马斯克与 OpenAI 及奥特曼之间是理念不合，还是利益之争，我们只能从过往经历中寻得蛛丝马迹。</p></div></blockquote><p style="letter-spacing: 0.578px;text-wrap: wrap;margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这几天，<a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909259&amp;idx=1&amp;sn=bfda3ce888d99208aa7cc6aa33844889&amp;chksm=84e46e35b393e723e624968bfc2e1e728ce738c5429e0b24cd6aa580b9fc45d5ad0379763b3b&amp;scene=21#wechat_redirect" textvalue="马斯克起诉 OpenAI" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">马斯克起诉 OpenAI</a> 的消息再次引爆了科技圈。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这位前 OpenAI 联合创始人在一份长达 46 页、总字数超过 1.4 万字的诉讼文件中，指控 OpenAI 不计后果地开发人类级别的人工智能，并将其移交给微软。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425663" data-ratio="0.7342592592592593" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID06ic1Z0uK9HrkicCxVjpubLFDN1YAGiarRNowDc36bpYTTxyQBSPBPW4XQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">马斯克的诉讼直指 OpenAI 首席执行官 Sam Altman 和总裁 Greg Brockman，他们两人与马斯克合作，于 2015 年创立了这家公司。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">诉讼称，这两人违反了与马斯克最初达成的「创始协议」，该协议承诺公司将公开开发 AGI（通用人工智能），并「造福人类」。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">事后，奥特曼连发了两条意味深长的推文，似乎是对马斯克指控的回应，「这一切都曾经发生过，也将在未来再次发生」、「风暴愈演愈烈，但风暴中心岿然不同」。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425664" data-ratio="0.3851851851851852" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0khqib1gbXZH47KK6MuGWKL1t25lnxRQkkhWtF3gUia1e7fJ19KImjUiaA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从 2015 年共同创立 OpenAI，到后来的分道扬镳，再到如今的对簿公堂，令人唏嘘不已。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">今日，外媒 Business Insider 梳理了马斯克与 OpenAI 及 CEO 奥特曼之间多年的复杂历程，两人之间的纠葛可以写成一部电视剧了。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="text-align: justify;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425665" data-ratio="0.75" data-s="300,640" data-type="png" data-w="1000" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0ydW0p3iaWQjhocIYkTic2sK7E4RialvTQ6wL5xU705VnPadCKtAIic4keg/640?wx_fmt=png&amp;from=appmsg"><span style="color: rgb(136, 136, 136);"><em><span style="letter-spacing: 0.034em;text-align: justify;font-size: 12px;">奥特曼（左）、马斯克（右）。</span></em></span></p><p style="text-align: center;"><strong><span style="letter-spacing: 0.034em;font-size: 16px;">从同为创始人到独自离开，马斯克三年出局</span></strong></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">2015 年，马斯克与奥特曼、著名投资界大佬 Peter Thiel、LinkedIn 联合创始人 Reid Hoffman、Stripe 首位首席技术官 Greg Brockman、计算机科学家 Ilya Sutskever 等其他人共同创立了 OpenAI。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">作为一个非营利性组织，OpenAI 从创立之初就专注于「创建造福全人类的安全通用人工智能（AGI）」。自此以后，OpenAI 构建了 GPT 系列大语言模型，以及最近火爆的文生视频大模型 Sora，不断地向 AGI 迈进。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425666" data-ratio="0.30092592592592593" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0OlwqqoneAqibvUWSyExVdiaN04znl9x5e6ibWkk8I8wLIeQMiarjwk8Akw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">彼时，马斯克认为 AI 是人类最大的威胁。在宣布 OpenAI 成立的声明中写道，「很难想象人类水平的 AI 能够给社会带来多大好处，同样如果构建或使用不当，也很难想象会给社会造成多大的危害。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: left;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425667" data-ratio="0.21296296296296297" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0bqSZO5f4hyictgDJqt2Pnbjte6M3HHia1N68AsjtfwaYvfic0shGDejpQ/640?wx_fmt=png&amp;from=appmsg"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;letter-spacing: 0.034em;text-align: justify;">图源：https://openai.com/blog/introducing-openai</span></em></span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在 OpenAI 成立近三年后，2018 年 2 月，马斯克被 OpenAI 董事会「踢出局」，但会继续提供资金资助和指导。OpenAI 在当时的一篇博客中表示，随着特斯拉（马斯克任职 CEO）继续更加地关注 AI，马斯克的离开将消除特斯拉与 OpenAI 之间潜在的冲突。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="text-align: left;"><span style="color: rgb(136, 136, 136);"><em><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425668" data-ratio="0.3212962962962963" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0ZRZQkJMXx7UibGqZT71eQEbq7QxToswfDtYJwQgic77qbGjTmHq8OmNw/640?wx_fmt=png&amp;from=appmsg"><span style="font-size: 12px;letter-spacing: 0.034em;text-align: justify;">图源：https://openai.com/blog/openai-supporters</span></em></span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">不过后来，随着马斯克的离开，他被曝放弃了向 OpenAI 提供额外资助的承诺，这对于 OpenAI 而言情况变得很艰难。奥特曼曾向《纽约客》杂志称，他必须重新调整自己的生活和时间，以确保 OpenAI 有足够的资金。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">至于马斯克离开 OpenAI 是否有深层原因呢？根据 Semafor 的一篇报道，在 2018 年，奥特曼和其他公司联合创始人拒绝了马斯克运营 OpenAI 的建议。当时，马斯克希望独立运营 OpenAI，并试图击败谷歌。当然，马斯克的建议被拒绝了，因此他撤回了资金并离开了 OpenAI 董事会。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">不过，在 2019 年，马斯克在谈到他离开 OpenAI 的决定时，表示其中一个原因是他不同意 OpenAI 的发展方向。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">他在推特上写道，「我必须集中精力解决（尤其是）特斯拉和 SpaceX 的大量麻烦的工程和制造问题。当然，特斯拉与 OpenAI 在人才方面存在着竞争，我也不同意 OpenAI 团队想做的一些事情。所以，还是分道扬镳的好。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425669" data-ratio="0.25277777777777777" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0z9HTDdtdpmtMlgRpBLFIY483C15xhGs1LwhsGPE7PDEx4eQWficI0Iw/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425670" data-ratio="0.22314814814814815" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0g7HWhL4odH4yF1A7wCgv06Ns5Lx0Jbl7j03VEcSj4BSFf984XdMFwg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">马斯克「怼」人之路开启</span></strong></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在离开 OpenAI 后，马斯克曾多次抨击 OpenAI。他曾多次表示，OpenAI 应该更加开放。尤其是在 ChatGPT 发布之后。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425671" data-ratio="0.6638888888888889" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0CwdNiaKf6YlYrUEzCgHRcyCLcrIibYSdpf50xePEYqJuRFj0wwB6C9hw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">2022 年 12 月，即 OpenAI 发布 ChatGPT 几天后，马斯克表示：OpenAI 事先已访问 Twitter（现由马斯克拥有）的数据库来训练人工智能聊天机器人。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">当时，马斯克在推特上写道：「需要更多地了解（OpenAI）未来的治理结构和收入计划。OpenAI 最初是作为开源和非营利组织开始的。现在这两者都不是事实。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425672" data-ratio="0.4704641350210971" data-s="300,640" data-type="png" data-w="948" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0c3Z12AZCaPW0pqicGVZBvyG5qnUWwQ6RYSsYLqvyaMmyZUkCgPcOucA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">时间转眼来到 2023 年，这一年，OpenAI 凭借 ChatGPT 收获了极大的成功。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">据外媒 Semafor 2023 年报道，马斯克对 ChatGPT 的成功感到愤怒。2023 年 2 月，马斯克再次强调，目前存在的 OpenAI「根本不是我的初衷」。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425673" data-ratio="0.7494481236203091" data-s="300,640" data-type="png" data-w="906" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0UicoKGjca0cNWAKh1AlMY6TWseUSmo2W0aiboV8qAr152icG08oTtmG3g/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">「OpenAI 是作为一家开源（这就是我将其命名为『OpenAI』的原因）、非营利的公司而创建的，目的是制衡谷歌，但现在它已经成为一家闭源、利润最大化的公司，由微软有效控制。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425674" data-ratio="0.43037974683544306" data-s="300,640" data-type="png" data-w="948" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0zxBApYIaRDCibA3evgEF13KsPXvEQ1LTBqmicq518UbLG9bXvDahQnLQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">一个月后，马斯克重申了这一观点：「我仍然很困惑，我捐赠了约 1 亿美元的非营利组织居然成为了市值 30B 美元的营利组织。如果这是合法的，为什么不每个人都这样做？」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425675" data-ratio="0.2857142857142857" data-s="300,640" data-type="png" data-w="938" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID0fhou78SUQZn0UK6pURbm3n6CUpEVPoBxK43Grd14XszBWqwwapGrZQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">如今，马斯克已将他的投诉转变为诉讼。他正在起诉 OpenAI、奥特曼和联合创始人 Greg Brockman，指控该公司近年来的发展方向违反了其创立原则。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">马斯克的律师声称，OpenAI「已经转变为世界上最大科技公司实质上的闭源子公司」，并且正在「完善通用人工智能，以实现微软的利润最大化，而不是为了人类的利益」。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">根据 OpenAI 发给公司员工的内部备忘录，该公司「断然不同意」马斯克对该公司提起的诉讼。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但是，OpenAI CEO 奥特曼的一些观点可以回应马斯克的抱怨。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">据播客 On With Kara Swisher 报道，奥特曼认为马斯克值得肯定的一点是「他确实关心 AGI 的美好未来」，并且奥特曼认为马斯克对人类的未来感到非常有压力。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">至于「OpenAI 已变成一家由微软有效控制的闭源、利润最大化的公司」的说法，奥特曼在播客中表示：「大部分内容都不是真的，并且我认为马斯克知道这一点。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">奥特曼表示，尽管马斯克在 X 上存在明显攻击 OpenAI 的行为，但他仍然将马斯克视为他的偶像之一。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在一场播客中，奥特曼直言不讳的表示，虽然马斯克不断的在公开场合攻击我们。但马斯克仍然是我的偶像之一，我相信他确实对 AGI 安全感到压力，这是可以理解的。他还透露从马斯克身上学到了一些非常有价值的教训。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">不过，马斯克和奥特曼在很多事情上都存在分歧，马斯克曾经签署过公开信，呼吁暂停训练先进人工智能系统六个月的倡议，主要针对 OpenAI。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">去年 3 月，在 GPT-4 诞生后不久，有公开信指出人类对人工智能的实验已经陷入失控，类社会对其可能造成的影响也没有做好准备。因此，公开信呼吁，所有 AI 实验室应立即暂停训练比 GPT-4 更强大的 AI 模型，为期至少 6 个月。这封信还得到了几位人工智能专家的签名。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">信中说：「只有当我们确信其效果是积极的并且风险可控时，才应该开发强大的人工智能系统。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但在公开呼吁暂停的同时，马斯克也在打造自己的大模型竞品。不久之后在推特上，Grok 就上线了。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在马斯克和奥特曼极限拉扯的过程中，还出现了一个戏剧性的事情，不知是有意还是无意，有段时间马斯克在 X 上取消了对奥特曼的关注，不过后来又关注回来了。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">还有一个有意思的事情是，不知大家是否还记得去年 6 月，马斯克在社交媒体上向马克・扎克伯格发起铁笼格斗挑战的故事。作为拥有世界上众多财富的这两位明星级大佬，约架方式堪称是世界奇观，不过最后大家想看到的也没有发生。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">对于此事，奥特曼曾经开玩笑的说，他会去围观马斯克和扎克伯格的笼子大战。不过奥特曼也开玩笑的说即使去观战，也不会和马斯克动手。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">奥特曼不止一次的在采访中提到马斯克，去年 6 月彭博社举办的科技峰会上，作为嘉宾的奥特曼重申了他之前关于马斯克在人工智能问题立场上的一些言论：「马斯克真的非常关心人工智能的安全，我们虽然在某些方面意见不同，但也有共同目标，即希望确保我们 —— 整个世界，有最大的机会获得好的结果。」</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425676" data-ratio="0.9083333333333333" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicJl5G6IHORtWvwpmicdIID07TzW65qGS3SxJ95POxCRnlKvArxiaCskOWGhha75qwG9hND7uibxpbpQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在接受《纽约客》采访时，奥特曼表示，马斯克非常渴望拯救世界，但前提是他必须是那个拯救世界的人。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从一开始的合作伙伴，到现在的斗争不休，两人的恩恩怨怨还在继续。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">最后，为大家推荐自 OpenAI 创立到 Sam 接任 CEO，机器之心的相关报道，背后包含了许多有关 OpenAI、马斯克、Sam Altman 的精彩故事。</span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=401181797&amp;idx=4&amp;sn=32850f66223a4b184c1f0d2bfa84b111&amp;chksm=0d0c481b3a7bc10d27b16b6c0573b4532032dbb8897e3986cb130a852caf6f8525796fe155a6&amp;scene=21#wechat_redirect" textvalue="业界 | OpenAI：马斯克发起 10 亿美元非营利 AI 研究项目" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">业界 | OpenAI：马斯克发起 10 亿美元非营利 AI 研究项目</span></a><span style="font-size: 15px;"></span></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650715043&amp;idx=3&amp;sn=4e3a8c60b412c7703fe00e558baff359&amp;chksm=871b77ddb06cfecb56cd663b11ed2e96e3fe9a428167de6967e2968aedd52f1e3ad1cee7f94c&amp;scene=21#wechat_redirect" textvalue="深度 | 深入解读 OpenAI，Elon Musk 解放人工智能的狂野计划" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">深度 | 深入解读 OpenAI，Elon Musk 解放人工智能的狂野计划</span></a><span style="font-size: 15px;"></span></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719713&amp;idx=1&amp;sn=721ff94713b21148895253b543e2bc24&amp;chksm=871b019fb06c8889e5a4df61cbfdfd421a52d683b0a457173069b28e5b48f0f7afb51ade7ffd&amp;scene=21#wechat_redirect" textvalue="特写 | 从 Y Combinator 到 OpenAI，纽约客万字讲述 Sam Altman 的天定命运（上篇）" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">特写 | 从 Y Combinator 到 OpenAI，纽约客万字讲述 Sam Altman 的天定命运（上篇）</span></a><span style="font-size: 15px;"></span></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650719713&amp;idx=2&amp;sn=df4ff7e49a5512e3dc31be1e2090d6bf&amp;chksm=871b019fb06c8889f1b5531959e0a119f48b921ee9e4786623aa05d8a78ee4cc6ab12af2232b&amp;scene=21#wechat_redirect" textvalue="特写 | 从 Y Combinator 到 OpenAI，纽约客万字讲述 Sam Altman 的天定命运（下篇）" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">特写 | 从 Y Combinator 到 OpenAI，纽约客万字讲述 Sam Altman 的天定命运（下篇）</a></span></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650749563&amp;idx=3&amp;sn=c6790dfa1754d030ec3fb4dda322bb17&amp;chksm=871afe05b06d771379a22d38c7fbffc3bf1dd77208e783ec1061f0ed683512d8eb980c3ba0c1&amp;scene=21#wechat_redirect" textvalue="人物 | OpenAI 背后的领袖 Ilya Sutskever：一个计算机视觉、机器翻译、游戏和机器人的变革者" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">人物 | OpenAI 背后的领袖 Ilya Sutskever：一个计算机视觉、机器翻译、游戏和机器人的变革者</span></a><span style="font-size: 15px;"></span></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650758310&amp;idx=2&amp;sn=adf150d5831db301bcfadfa1c7be285f&amp;chksm=871a98d8b06d11ce51d532bc259cfd9c207988fb181fbebb9f99fd56723d45120156161c499f&amp;scene=21#wechat_redirect" textvalue="YC 掌门人 Sam Altman 宣布离职，将专注于 OpenAI" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2" style="font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 15px;">YC 掌门人 Sam Altman 宣布离职，将专注于 OpenAI</span></a></p></li><li><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650758447&amp;idx=2&amp;sn=8e43c2672cc68677f900b7cd3c24709e&amp;chksm=871a9951b06d10474a12627b5e1ffe635a8ed024044fa32d8d8d8614a4f78a220014ca8c49c0&amp;scene=21#wechat_redirect" textvalue="百倍利润封顶：OpenAI 宣布转型为营利公司，Sam Altman 任 CEO" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">百倍利润封顶：OpenAI 宣布转型为营利公司，Sam Altman 任 CEO</span></a></p></li></ul><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考链接：</span></em></span></p><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://www.businessinsider.com/history-of-elon-musk-and-sam-altman-relationship-feuds-2023-3#altman-joked-that-hed-watch-musk-and-mark-zuckerbergs-rumored-cage-fight-17</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425677" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[十年内出现AGI？下一代Gemini能感知环境？DeepMind CEO哈萨比斯畅谈AI]]></title>
        <id>2650909283_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909283&amp;idx=1&amp;sn=f3d4b8a421b98f46bc8d13583dd6cbdc&amp;chksm=84e46e1db393e70b96c2fb267d437999cc1968fdf43bc0d5fbedd1ea5f48f72eb64ce8476f82#rd"/>
        <updated>2024-03-03T04:33:54.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：Panda</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="69" data-source-title=""><div class="js_blockquote_digest"><div><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">智能本质、对齐、Gemini、超人类AI和多模态、AGI……在这场干货满满的访谈中，Demis Hassabis可谓「知无不言、言无不尽」。</span></p></div></div></blockquote><p><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">「如果我们在未来十年内拥有类似 AGI 的系统，我不会感到惊讶。」Google DeepMind 联合创始人和 CEO Demis Hassabis 近日在人工智能播客节目 Dwarkesh Podcast 上如是说。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在长达一个小时的节目中，Hassabis 分享了自己对智能本质、强化学习、规模扩展和对齐、AGI、多模态等主题的看法。机器之心选择性地整理了其中的主要内容并进行了适当编辑以便阅读。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="318" data-imgfileid="503425612" data-ratio="0.5497076023391813" data-s="300,640" data-type="jpeg" data-w="684" style="width: 578px;height: 318px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9prHyicKeAPCJpddplfLTH4W4VEvBFLvuSKibjAKZDSAoPJiakLrTQrUX8LOhfXKTkfMWYZiaaX9CPicw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">智能的本质</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：第一个问题：您有神经科学背景，那么您是怎么看待智能的？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这个问题很有趣。智能非常宽泛，可普遍用于各种用途。我认为这说明对于大脑处理我们周围世界的方式，必然存在某种高层级的共同之处，算法层面的共同之处。当然，大脑中有做特定事情的特定部分，但我认为所有这些事情下面可能有一些基本原则作为支撑。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您怎么看待这一事实：对于现在的 LLM，当你向其提供大量特定领域的数据时，它们往往会在那个领域变得格外地好？难道不能在所有不同领域上实现普遍提升吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，我认为当在某个领域内获得提升时，有时候也会在其它领域获得出人意料的提升。举个例子，当这些大模型的编程能力提升时，它们的一般推理能力实际上也能得到提升。所以现在是有一定的迁移学习的证据。而且这也是人脑学习的方式。如果我们大量经历或练习象棋或写作等事项，我们就会越来越擅长对应的事情，即便我们是使用某种通用学习技术和通用学习系统来学习某个特定的领域。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：以语言和编程为例，在神经网络中，是否存在某种地方存在某种机制让模型的语言和编程能力一起提升？&nbsp;</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们目前的分析技术还不足以确定这一点。实际上，对于这些系统构建的表征的机制分析，还有待大量研究。我有时候把这称为虚拟脑分析（virtual brain analytics）。从某个方面看，这有点像是 fMRI，或者记录真实大脑中单个细胞的活动。对于这类分析技术，可以怎样将其类比到人造心智呢？这方面有很多出色的研究成果。比如 Chris Olah 就在研究这个，我很喜欢他的研究。有很多计算神经科学的技术可以引入过来分析我们目前正在构建的这些系统。事实上，我也在努力鼓励我在计算神经科学领域的朋友思考这个方向，应用他们的所学来理解大型模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：由于您有神经科学背景，您多半了解一些其他 AI 研究者不太了解的有关人类智能的知识。这方面的知识有哪些？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：神经科学的助益很大。看看过去一二十年的研究就能知道。事实上我已经思考这些三十多年了。在这新的一轮 AI 浪潮早期，神经科学提供了大量有趣的引导性线索。于是出现了强化学习以及深度学习等技术。我们在这方面也有一些开创性的研究成果，比如经历重放（experience replay）以及已经变得非常重要的注意力（attention）概念。很多这些成果的初始灵感都是来自对大脑工作方式的理解，当然它们并不完全一样。一种是工程开发出的系统，另一种是自然的系统。它们并不是某种算法的一对一映射，而更像是某种指示方向的灵感——或许是某种架构思想，或者算法思想或表征思想。毕竟大脑本身就是通用智能存在的证据。人类就是这样的，一旦知道某件事是可能的，就更容易朝那个方向努力，因为你知道这就是一个努力进取直到某时取得成功的问题，而不是能否成功的问题。这能让人更快地取得进展。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为在如今成功的背后，神经科学启迪了很多人的思考，至少是间接的。至于未来，我认为在规划方面还有很多有趣的问题有待解决。还有大脑是以何种方式构建出了正确的世界模型？举个例子，我研究过大脑是如何进行想象的，你也可以将这看作是心智模拟。我们就会问：为了执行更好的规划，我们是以怎样的方式创建了对于世界的非常丰富的视觉空间模拟？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">LLM 之上的强化学习</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：LLM 能否具备这种类似树搜索的能力？您对此怎么看？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是一个非常有潜力的研究方向。我们在持续不断地提升大型模型，让它们成为越来越准确的世界预测器。在效果上，就是让它们成为越来越可靠的世界模型。这明显是必要的，但我认为这可能并不是 AGI 系统的充分条件。在这之外，我们还在研究 AlphaZero 这样的规划机制——其可使用模型执行明确的规划，从而在世界中实现特定的目标。另外可能还会搭配某种链式思维或推理路径，也可能使用搜索来探索巨大的可能性空间。我认为这是我们当前的大模型所缺少的能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：对于这些方法所需的巨量算力，您会怎么获得？您认为这方面的效率会怎么得到提升？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，摩尔定律会帮助我们。每一年，计算能力都在提升；但我们更关注样本高效型的方法以及复用已有的数据，比如经历重放。世界模型越好，搜索效率就越高。举个例子，AlphaGo 的搜索效率就远高于使用暴力搜索的深蓝（Deep Blue）。深蓝的每一次决策可能需要查看数百万种可能下法。AlphaGo 则只需要大约数万次就能决定下一步。但人类的大师级棋手可能只需检查几百种下法就能得到一个非常好的下一步决策结果。这明显说明，暴力搜索系统对这些棋并没有真正的模型。AlphaGo 有相当不错的模型，而顶级人类棋手拥有更丰富、更准确的围棋或国际象棋模型。这让他们只需少量搜索就能做出世界级的决策。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：但是 AlphaGo 胜过了人类冠军。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：当然，所以我们做出了开创性的成果，DeepMind 也因此出名。我们使用游戏作为验证平台，因为很显然在游戏中的搜索效率更高。另外，在游戏中也更容易设定奖励函数——不管是获胜还是赢取分数。这些是大多数游戏内置的奖励机制。但对于真实世界系统，这却非常困难——该如何定义正确的目标函数、正确的奖励函数和正确的目标？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：人类智能有很高的样本效率，它与 AlphaGo 这些系统得到解答的方式有何不同？比如爱因斯坦如何想出了相对论？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：它们大不相同，因为我们的大脑并不会执行蒙特卡洛树搜索。这不是我们的有机大脑的工作方式。为了弥补这一点，人类的大脑会用到直觉。人类会使用自己的知识和经历来构建非常准确的模型，比如爱因斯坦构建了非常准确的物理模型。如果你阅读一下爱因斯坦的经历，看看他是如何想出那些理论的，你会发现他习惯视觉化地思考那些物理系统，而不只是通过数学公式。这让他有了对这些物理系统的非常直觉化的感知。这让他产生了在当时显得非常离奇的想法。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为这就是我们构建的世界模型的复杂精妙之处。想象一下，如果你的世界模型能让你抵达你正在搜索的某个树的某个节点，然后你就只需要在这个节点附近搜索即可。这样一来，你的搜索量就少多了。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在还有一个问题有待解决：强化学习能否让模型使用自我博弈合成数据来克服数据瓶颈问题？您似乎对此很乐观。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我对此非常乐观。首先，仍然还有大量数据可以使用，尤其是多模态和视频等数据。而且显然，社会也在一直不断增加更多数据。但我认为创造合成数据方面也有很大的发展空间。这方面有一些不同的方法，比如模拟和自我博弈，模拟方法包括使用非常仿真的游戏环境来生成接近真实的数据。而自我博弈则是让模型互相交互或交谈。这种方法在我们开发 AlphaGo 和 AlphaZero 时效果非常好。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：那么该如何确保合成的数据不是来自模型的数据集，而是新数据？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这需要一门完整的学科来进行研究。在这方面，我们仍处于数据管理和数据分析的初级阶段。比如通过分析数据分布，能找到分布中的漏洞，这对于公平与偏见等议题来说非常重要。要将其移出系统，就需要确保数据集能够代表你想要学习的分布。对此人们有一些可以使用的技巧，比如增大数据中特定部分的权重或重放这部分数据。也可以想象，如果你发现你的数据集中有如此漏洞，你可以使用生成的数据来进行填补。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在人们很关注强化学习，但其实 DeepMind 很多年前就研究过了。是否还有类似这样的研究方向——早已经出现了，但还没有引起人们重视？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：事实上，过去几十年来这种事情一直在发生。新旧思想结合起来就有巨大潜力，比如过去的一些想法与更大规模模型和大型多模态模型结合起来也许就能得到激动人心的结果。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：强化学习、LLM、树搜索，哪种方法有潜力催生出 AGI？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：从理论上看，我认为纯 AlphaZero 式的方法没理由不成功。Google DeepMind 和社区一些人正在研究在假设完全没有先验知识、没有数据的前提下，从头开始构建所有知识。我认为这是有价值的，因为这些想法和算法在有一定知识时也能使用。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">话虽如此，但目前来说我认为最可能最快实现 AGI 的方法是使用目前世界上已有的知识，比如网络上的和我们收集的知识。而且我们还有 Transformer 等有能力消化这些信息的可大规模扩展的算法。你可以将一个模型用作某种形式的先验，基于其上进行构建并执行预测，以此启动 AGI 学习。没理由不这样做。我猜想，在最终的 AGI 系统中，大型多模态模型会成为整体解决方案的一部分，但它们本身并不足以成为 AGI。它们还需要额外的规划搜索能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">扩展与对齐</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在有个规模扩展假设（scaling hypothesis）。有人猜想，只要扩大模型和数据分布的规模，智能终会出现，您认同吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是一个需要实验检验的问题。几乎所有人（包括那些最早开始研究规模扩展假设的人）都很惊讶规模扩展所带来的成就。看看现如今的大模型，它们的效果好得简直不合理！大模型涌现出的一些性质相当出人意料；在我看来，大模型是有某种形式的概念和抽象能力。要是回到五年以前，我会说要做到这一点，我们可能还需要另一种算法方面的突破。也许更类似大脑的工作方式。我认为，如果我们想要明确的、简洁的抽象概念，我们依然需要更加理解大脑，但这些系统似乎可以隐式地学习它们。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">另一个出人意料的有趣结果是这些系统获得了某种形式的现实基础知识（grounding/定基），即便它们并未体验过世界的多模态——至少在近期的多模态模型出现之前没有。只是靠语言就能构建起如此大量的信息和模型，着实让人惊讶。对此的原因，我有一些假设。我认为大型语言模型能通过 RLHF 反馈系统获得一些现实基础知识，因为人类反馈者本身就是生活在现实中的人。我们就立足于现实世界中。所以我们的反馈也是立足于现实的。因此这能让模型获得一些现实基础。另外，也许语言中就包含了更多的现实基础，如果你能完全洞悉语言，也许能发现我们之前可能没考虑到的东西，甚至可能已经有语言学家研究过这些方面。这实际上是一个非常有趣的哲学问题。人们甚至可能都尚未触及其表面。看看过去的进展，畅想未来是非常有趣的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">对于你说的规模扩展问题，我认为我们应当尽可能地扩大规模，我们也正在这么做。至于最后会趋近一条渐近线还是撞上铁墙，这是个实验问题，不同的人会有不同的意见。但我认为我们应该直接去测试。没人能想出答案。但与此同时，我们也应该加倍投资创新和发明。这是谷歌研究院、DeepMind 和谷歌大脑的做法，我们在过去十年中开创性地取得了许多成果。这就是我们的生存之道，</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">可以说，我们一半的努力是在扩展规模，另一半则是在研发未来的架构和算法——它们或许是在模型变得越来越大之后所需的。我大概猜想，未来这两方面都需要。所以我们要两方面都尽可能地发力。我们很幸运，因为我们确实能做到这一点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Dwarkesh Patel：再多聊聊定基（grounding）。可以想象，有两件事会让定基变得更加困难。一是随着模型变得更加聪明，它们就能在我们无法生成足够人类标签的领域工作——因为我们不够聪明。而是关于计算。目前我们做的都是下一 token 预测。这就像是一个护轨，限制模型让其像人类一样谈话，像人类一样思考。现在，如果额外的计算是以强化学习形式出现的呢——我们只知道达成了目标但无法追踪是如何达成的？如果这两者组合起来，定基会出现什么问题？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为如果系统没有适当地定基，系统就无法适当地实现这些目标。我认为在某种程度上系统应该有定基，至少要有一些，这样才能在真实世界中真正实现目标。随着 Gemini 这样的系统变得更加多模态，可以在文本数据之外处理视频、音频和视觉数据，这些系统就会开始将这些东西融合到一起。我认为这其实就是一种形式的定基。这样系统就会开始更好地理解真实世界的物理机制。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：为了对齐比人类更聪明的系统，应该怎么做？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我和 Shane（注：Shane Legg，DeepMind 联合创始人，现担任该公司首席 AGI 科学家）还有其他许多人在我们创立 DeepMind 之前就已经在考虑这个问题了，因为我们计划着取得成功。2010 年时，还没什么人研究 AI，更别说 AGI 了。但我们那时就知道，如果我们能通过这些系统和思想取得成功，创造出的技术将会具有让人难以置信的变革力量。所以我们 20 年前就在思考了，这样会有什么正面和负面的后果。正面的后果就是惊人的科学成果，比如 AlphaFold、科学和数学领域的科学发现。同时我们也需要确保这些系统是可理解的和可控的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为了得到经过更为严格评估的系统，人们提出了很多想法。但我们目前还没有足够好的评估方法和基准可以确定系统是否欺骗了你、系统是否会泄漏自己的代码等不良行为。还有些人提出可以使用 AI 来辅助分析，就是使用应用范围窄的 AI（narrow AI）。它们不具备通用学习能力，而是专门为某个特定领域专门设计的；它们可以帮助人类科学家分析更通用的系统的行为。我认为一个有很大潜力的方向是创造强化型沙盒或模拟环境——它们的网络安全经过增强，可以把 AI 困在其中，也能保证外部攻击者无法进入。这样一来，我们就可以在这个沙盒中自由地做实验了。另外也有些人在研究让人类能够理解这些系统构建的概念和表征。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">时间线和智能爆炸</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您认为 AGI 会在什么时候出现？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我没有具体的时间预测，因为我感觉还有很多未知和不确定，而且人类的聪明才智和努力总是会带来惊喜。这些都可能导致时间线变化。但我要说，在我们 2010 年创立 DeepMind 时，我们认为这个项目需要 20 年时间。实际上，我觉得我们正按预期向目标靠近。这很了不起，因为通常的 20 年计划总是还要另外 20 年。如果我们在未来十年内拥有类似 AGI 的系统，我不会感到惊讶。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：如果有了 AGI，您会使用吗？您可以将其用来进一步加速 AI 研究。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是有可能的。这要看我们做出什么决定。我们需要作为一个社会来决定如何使用第一个新生的 AGI 系统或甚至 AGI 原型系统。即便是我们现有的系统，我们也需要考虑其安全方面的影响。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">Gemini 的训练</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：目前 Gemini 的开发遇到了什么瓶颈？既然规模扩展法效果很好，为什么不直接把它增大一个数量级？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，有实践方面的限制。一个数据中心究竟能有多少算力呢？实际上，这会遇到非常有趣的分布式计算难题。幸运的是，我们有最好的研究者在研究这些难题以及如何实现跨数据中心训练等等。还有硬件方面的难题，我们有自己构建和设计的 TPU 等硬件，也会使用 GPU。至于规模扩展的效果，也不是总如魔法般有效。扩大规模时也还需要扩展超参数，每一种规模都需要各种不同的创新。不是每一种规模都能重复一样的配方。我们必须调整配方，而且这在某种程度上就像是搞艺术。另外还需要获得新的数据点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：在 Gemini 的开发过程中，您觉得最出人意料的是什么？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我得说没什么非常出人意料，但是能在那种规模上进行训练并从一种组织化的角度去研究它，是非常有趣的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：很多人认为其它实验室的模型的计算效率可能比 DeepMind 的 Gemini 高。您怎么看？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为情况并非如此。实际上，Gemini 使用的算力差不多，也许就比传闻中 GPT-4 使用的算力稍多一点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：对于 2010 年刚创立 DeepMind 的您来说，现在的 AI 进展中哪一点最让您感到意外？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：你也采访过我的同事 Shane。他总是从计算曲线方面进行思考，也常常将 AI 与大脑进行比较——有多少神经元或突触。但现在我们已经差不多到大脑中神经突触数量的数量级和那样的计算量了。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但我认为，更根本的问题在于，我们关注的重心始终是通用性和学习。这始终是我们使用任何技术的核心。因此我们把强化学习、搜索和深度学习看作是三种可以扩展并且可以非常通用的算法，无需大量人工设计的人类先验知识。这不同于 MIT 等在当时构建的 AI——它们是基于逻辑的专家系统，需要大量人工编码。事实证明这种做法是错误的。我们在早期看出了发展趋势。我们使用游戏作为验证平台，发现结果还不错。最后也取得了巨大的成功。AlphaGo 等成功给其他许多人带去了启发。当然，还有我们谷歌研究院和谷歌大脑的同事发明的 Transformer，这种深度学习方法让模型可以处理海量数据。这些技术就是如今成果的基础。这些都是一以贯之的传承。我们当然不可能预测出每一次技术转变，但我认为我们前进的总体方向是正确的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">治理超人类 AI</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您怎么看待超人类智能的前景？它仍然受私有企业控制吗？具体应该如何治理它？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这种技术将会带来重大影响。大于任何一家公司，甚至大于任何一个行业。我认为这必需来自民间社会、学术界、政府的许多利益相关者的大规模合作。好消息是，随着近期聊天机器人等技术的广泛使用，社会中其它一些部分被唤醒了，他们开始认识到这种系统正在到来并且他们也将与这些系统互动。这很不错。这为良好的对话打开了很多大门。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">其中一个例子是几个月前在英国举办的 AI Safety Summit。我认为这是一次巨大成功。我们需要进行国际间的对话，要让整个社会一起来决定我们要使用这些模型做什么、我们希望怎样使用它们、我们希望它们不被用于什么目的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在的 AI 系统已经非常强大，为什么它们的影响没有更大呢？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这说明我们依然还处在这个新时代的起点。目前的这些系统已经有一些有趣的用例，比如使用聊天机器人系统来为你做总结、完成一些简单的写作任务、进行样板式写作；但这些只是我们日常生活的一小部分。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为，对于更一般化的用例，我们仍然需要新的能力，比如规划和搜索，另外还需要个性化、记忆、情境记忆等。因此长上下文窗口是不够的，还要记住 100 轮对话之前我们说了什么。一旦这些技术成熟了，我们就会看到新的用例，比如能帮助我们找到更好更丰富材料（书、电影、音乐等）的新推荐系统。那样我就会每天使用这类系统。我认为我们目前只是触及了这些 AI 助理的表面，其实未来它们能为我们的一般日常生活和工作做更多事情。另外用它们做科研也不足够可靠。但我相信未来当我们决定了事实性和定基等问题之后，这些 AI 系统就能变成世界上最好的研究助理。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：说到记忆，您在 2007 年有一篇论文谈到记忆和想象（imagination）有某种程度的相似之处。现在也有人说目前的 AI 就只是记住了些东西。您对此怎么看？只靠记忆就足够了吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：在有限的情况下，也许记住一切就够了，但这样无法泛化到原有的分布之外。但很明显 Gemini 和 GPT-4 等模型确实能够泛化到新的情况。至于我的那篇论文，我实际上表达的是：记忆（至少是人类记忆）是一种重建的过程。记忆不是磁带式的精确记录。我们的大脑是把看起来熟悉的东西组合到一起。这让我思考想象可能也是这么回事。只不过这时候我们组合的是语义组件（semantic component）——你的大脑将它们组合起来并且认为结果是全新的。我认为我们目前的系统依然缺少这种能力——即把世界模型的不同部分拿出来组合到一起来模拟新东西，从而帮助用来执行规划。这就是我所说的想象。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">安全、开源和权重安全</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：你们有计划和其它两家主要的 AI 实验室一样从某种程度上放出 Gemini 的框架吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我们内部已经做了大量的检查和平衡，我们也会开始发布一些东西。未来几个月，我们有很多博客文章和技术论文发出来。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：如何保护模型的权重，使其不被恶意盗用？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这涉及到两个方面。一是安全，二是开源。安全非常关键，尤其是网络安全。我们 Google DeepMind 非常幸运。因为我们在谷歌的防火墙和云的保护之下，这可以说是世界上最好的安全防护。除此之外，我们 DeepMind 还有特定的措施来保护我们的代码库。所以我们有双重保护。而且我们还在不断提升和改进，比如使用强化沙盒。我们也在考虑特定的安全数据中心或硬件解决方案。所有的前沿实验室都应该这么做。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">开源也很重要。我们是开源和开放科学的大力支持者。我们已经发布了数千篇论文，包括 AlphaFold、Transformer 和 AlphaGo。但对于核心的基础技术，我们会考虑如何阻止恶意组织、个人或流氓国家，防止他们使用这些开源系统去实现他们的有害目的。这是我们必须回答的问题。我不知道这个问题的答案，但我也没能从支持开源一切的人那里听到让人信服的答案。我认为这其中必须要有些平衡。但很显然这是个很复杂的问题。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：在安全方面，其它一些实验室有自己的专攻领域，比如 Anthropic 在研究可解释性。现在你们有了最前沿的模型，你们也会在安全方面做前沿研究吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们已经开创了 RLHF 等技术，这不仅能用于提升性能，也能用于安全。我认为很多自我博弈想法也有潜力用于自动测试新系统的边界条件。部分问题在于，对于这些非常通用的系统，它们的适用范围非常广。我认为我们将需要一些自动测试技术以及之前提到的模拟和游戏、非常拟真的虚拟环境。在这方面我们有很长的研究历史。另外，很幸运谷歌有大量网络安全专家和硬件设计师。这也是我们可以获得的安全保障。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">多模态和进一步的进展</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：对于 Gemini 这样的系统，目前与它们默认的交互方式是通过聊天。随着多模态和新能力的加入，这种情况会如何改变？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：在理解完整的多模态系统方面，我们还处于起步阶段。与其的交互方式将与我们现在的聊天机器人大不相同。我想明年的下一代版本可能会具有一定的环境理解能力，比如通过相机或手机。然后我可以想象下一步。模型在理解方面会变得越来越顺畅。我们可以使用视频、声音甚至触碰。如果再考虑到使用传感器的机器人，世界将会开始变得激动人心。我想未来几年，我们就能看到多模态对机器人学科意味着什么。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：Ilya 曾在播客上跟我说过 OpenAI 放弃研究机器人的原因：在该领域的数据不够，至少在那时候是如此。您认为这对机器人的发展而言依然还是一个瓶颈吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们的 Gato 和 RT-2 Transformer 取得了激动人心的进展。我们一直以来都很喜欢机器人。我们在这一领域也有出色的研究成果。我们仍然在进行机器人研究，因为我们其实喜欢这一事实：这是一个数据稀少的领域。我们认为这会是一个非常有用的研究方向，其中涉及到的课题包括采样效率和数据效率、从模拟环境迁移到现实的迁移学习。我们一直在努力研究。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">实际上 Ilya 说得对，机器人很有挑战性就是因为数据问题。但我想我们会开始看到大模型可以迁移到机器人领域、在非常普适的领域学习，并且可以将 Gato 这样的 token 当作是任意类型的 token 进行处理。这些 token 可以是动作，也可以是词、图块、像素等等。我心中的多模态就是这样。但一开始，训练这样的系统比简单直接的文本语言系统更困难。我们之前聊迁移学习时也谈到了，对于一个真正的多模态系统，一个模态是可以从其它模态获益的。比如如果模型更加理解视频，其语言能力也会有所提升。我们最后会有一个这样的更加通用、更有能力的系统。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：DeepMind 发表了许多有趣的研究成果来加速不同领域的科学研究。为什么要构建这样的特定领域的方案呢？为什么不等到一二十年后让 AGI 来做？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我想我们并不知道 AGI 将在何时到来。而且我们过去也常常说，我们不必等到 AGI，也能做出些出色的成果来造福这个世界。我个人也对 AI 在科学和医疗领域的应用充满热情。而且你可以看到我们的多篇 Nature 论文关注了多个不同的领域。有很多激动人心的研究方向能影响这个世界。作为拥有数十亿用户的谷歌的一分子，我们很荣幸有这样的巨大机会，可以将我们取得的进步快速提供给数十亿人，帮助改善、丰富和助力他们的日常生活。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从 AGI 的角度看，我们也需要检验我们的想法。我们不能指望闭门造 AI 就能推动发展，因为这样只会让内部指标偏离人们真正会关心的真实事物。真实世界应用能提供大量直接的反馈，可以让我们知道系统是否在进步或者我们是不是需要提高数据或样本效率。因为大多数真实世界难题都需要这样。这能不断推动和引导你的研究方向，以确保它们走在正确的道路上。当然，另一方面是，即便是在 AGI 诞生之前很多年，世界也能从中获益。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">Google DeepMind 内部</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：Gemini 的开发工作涉及到谷歌大脑和 DeepMind 等不同机构的合作。这其中遇到了哪些挑战？产生了哪些协同效应？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：过去的一年是很棒的一年。当然，挑战是有的，和任何大型整合工作一样。但我们是两个世界级的组织，各自都发明了许多重要技术，从深度强化学习到 Transformer。因此，我们的很多工作就是将这些汇集起来，实现更加紧密的合作。其实我们过去常常合作，只不过之前是针对具体项目的合作，现在则是更加深度和广泛的合作。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Gemini 是这一合作的首个成果，其实 Gemini 这个名字就暗含了孪生兄弟姐妹的意思。当然，也有很多事情的效率更高了，像是把计算资源、想法和工程开发工作汇集到一起。我们目前就处于这个阶段，基于世界级的工程开发来构建前沿系统。我认为进一步的合作是有意义的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您和 Shane 创立 DeepMind 的部分原因是你们担忧 AI 的安全问题。您认为 AGI 的到来有现实的可能性。您感觉来自谷歌大脑的研究者也有类似看法吗？这个问题方面是否存在文化差异？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：没有。总体而言，这就是我们在 2014 年与谷歌携手的原因之一。我认为，谷歌和 Alphabet 整体（不只是谷歌大脑和 DeepMind）都以负责任的态度认真对待这些问题。差不多我们的座右铭就是大胆尝试这些系统，同时要负起责任。我显然是一个技术乐观主义者，但我希望我们对技术保持谨慎，毕竟我们共同为这个世界带来的东西具有变革性的力量。我认为这很重要。我认为这将成为人类发明的最重要的技术。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：最后一个问题。2010 年时，当其他人还觉得 AGI 很荒谬时，您就在思考这个终极目标了。现在随着这类技术的慢慢起飞，您是怎么想的呢？您是否已经在您的世界模型中预想到过？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我确实已经在我的世界模型中预想到过这些，至少是从技术角度。但很显然，我们不一定预料到了公众会在如此早期阶段参与进来。像是 ChatGPT 等一些应用在某些方面还有所欠缺，但人们已经有浓烈的兴趣去使用它们了。这一点挺让人意外的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">另外还有更加专业化的系统，比如 AlphaFold 和 AlphaGo 以及一些科学方面的成果，但它们在公众关注的主线发展之外，也许几年后公众会关注到它们，那时候我们可能就有了更加普遍适用的助理类型的系统。这会创造出一个和现在不一样的环境。而且情况可能看起来会更混乱，因为会有很多事情发生，也会有很多风险投资，好像所有人都失去理智一样。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我唯一担忧的是我们能否负责任地、深思熟虑地、科学地对待这种情况，使用科学方法来应对。也就是我说的乐观但谨慎的方式。我一直都相信这是我们应对 AI 这类事物的方式。我希望我们不会迷失在这场快速袭来的巨大热潮中。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考链接：</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.dwarkeshpatel.com/p/demis-hassabis</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://twitter.com/dwarkesh_sp/status/1762872471479529522</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425614" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[马斯克起诉OpenAI：他们做出了AGI还授权给微软，这是对创始协议赤裸裸的背叛]]></title>
        <id>2650909259_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909259&amp;idx=1&amp;sn=bfda3ce888d99208aa7cc6aa33844889&amp;chksm=84e46e35b393e723e624968bfc2e1e728ce738c5429e0b24cd6aa580b9fc45d5ad0379763b3b#rd"/>
        <updated>2024-03-02T02:23:10.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="38" data-source-title="" style="outline: 0px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 0.578px;visibility: visible;"><div class="js_blockquote_digest" style="outline: 0px;visibility: visible;"><p style="outline: 0px;visibility: visible;"><span style="outline: 0px;letter-spacing: 0.578px;visibility: visible;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">AGI 做出来了吗？</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">创始协议在哪儿？</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">马斯克起诉 OpenAI 的诉讼文件疑点满满。</span></span></p></div></blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="letter-spacing: 0.034em;font-size: 15px;"></span><span style="font-size: 15px;letter-spacing: 0.034em;">在刚刚过去的一天，「沉湎于戏剧性冲突」的马斯克又做了一件新鲜事：</span><span style="font-size: 15px;letter-spacing: 0.034em;">他起诉了自己参与创立的 OpenAI。</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425587" data-ratio="0.615909090909091" data-type="png" data-w="880" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8aqicvLCbzniasMYPTzWDlLCwPdiaLxyuOt4gLDS8VMQrYYSSd454276tQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在诉讼文件中，他指控 OpenAI 不计后果地开发人类级别的人工智能，并将其移交给微软。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克的诉讼针对的是 OpenAI 及其两名高管 —— 首席执行官 Sam Altman 和总裁 Greg Brockman，他们两人与马斯克合作，于 2015 年创立了这家公司。诉讼称，这两人违反了与马斯克最初达成的「创始协议」，该协议承诺公司将公开开发 AGI（通用人工智能），「造福人类」。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425588" data-ratio="0.7342592592592593" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l85FDR9X2oqibjBYdnhU5o8lr2TvUVC6S40xIrVUjYlpO00EicKhALKCjA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">诉讼文件：https://www.courthousenews.com/wp-content/uploads/2024/02/musk-v-altman-openai-complaint-sf.pdf</span><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克在诉讼中称，该公司的营利性部门是在他与 OpenAI 分道扬镳后于 2019 年成立的，它在没有适当透明度的情况下创建了 AGI，并将其授权给微软，而微软向该公司投资了数十亿美元。诉讼补充道。「这是对创始协议赤裸裸的背叛。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425589" data-ratio="0.6546296296296297" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8w29CsiaqXCQdkkNhyLCE6lps3Z5zsU6sib9wibibl0LR14C3cczILa8Wgw/640?wx_fmt=png&amp;from=appmsg"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼援引微软 CEO Satya Nadella 最近的一次采访，指控微软与 OpenAI 关系密切。针对去年 OpenAI 发生的「宫斗」事件，Nadella 表示，如果「OpenAI 明天就消失了...... 我们拥有所有的知识产权和能力。我们有人，我们有计算，我们有数据，我们拥有一切。We are below them, above them, around them」。该诉讼将此作为 OpenAI 为微软利益服务的有力证据。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于此，该诉讼要求强迫 OpenAI 公开发布其技术，并禁止 OpenAI 利用该技术为微软、Altman 或 Brockman 谋取经济利益。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该诉讼还要求法院裁定，GPT-4 等人工智能系统和其他正在开发的先进模型构成通用人工智能，超越了微软与 OpenAI 许可协议的范围。除了强制 OpenAI 执行禁令之外，马斯克还要求法院在发现 OpenAI 现在是为了私人利益而运营时，对其用于资助公益研究的捐款进行核算和可能的归还。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">根据法律诉状，马斯克在 2016 年至 2020 年 9 月期间向 OpenAI 捐赠了超过 4400 万美元。诉讼补充道，在最初几年，他是 OpenAI 最大的捐款人。马斯克在 2018 年离开了 OpenAI 的董事会，他早些时候表示，有人向他提供了这家初创公司营利部门的股份，但他出于原则立场拒绝接受。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">不过，马斯克想打赢这场官司可能没有那么容易，因为他所给出的诉讼文件涉及一些尚未理清的事实，比如 OpenAI 真的开发出 AGI 了吗？所谓的「创始协议」到底是否存在？这些问题给诉讼带来了不小的难度。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>OpenAI 开发出 AGI 了吗？</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此案的很大一部分内容都围绕着一个大胆而又令人质疑的技术主张：OpenAI 开发出了所谓的通用人工智能。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼称，「依据所了解的信息和据此形成的推断（on information and belief），GPT-4 是一种 AGI 算法」。诉讼文件引用了一些研究，发现 GPT-4 可以在律师资格统一考试和其他标准测试中获得及格分数，以此证明它已经超越了人类的某些基本能力。「GPT-4 不仅具有推理能力，而且比普通人更善于推理，」该诉讼称。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">微软去年 4 月发布的论文 ——「Sparks of Artificial General Intelligence: Early experiments with GPT-4」就在被引用的研究之列。在这篇论文，微软提出了一个断言 ——「鉴于 GPT-4 能力的广度和深度，我们相信它应该被合理视作一个通用人工智能（AGI）系统的早期（但仍不完整）版本。」如今，这句话被马斯克作为证据写进了诉讼文件。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425590" data-ratio="0.862037037037037" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8xpnj24V0t2TCnAT0U5pOeqRNubkp3elx0cdm6x6e1w5iaudoh19EZ4Q/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">同样被列为证据的还有传闻中提到的 OpenAI 神秘模型 ——Q*（Q star），诉讼文件称，该模型更接近 AGI。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此外，文件还提到，微软只对 OpenAI 某些达到 AGI 之前的技术拥有权利。不过，就微软的许可而言，OpenAI 是否达到 AGI 由 OpenAI 公司的董事会决定，而 OpenAI 现在的董事会没有能力判断 OpenAI 开发的算法是否达到了 AGI。</span></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="190" data-source-title=""><div class="js_blockquote_digest"><div><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">2023 年 11 月 17 日，OpenAI 公司董事会解雇了 Altman 先生，因为『他没有始终如一地对董事会坦诚相待』，董事会对他继续领导 OpenAI 的能力失去了信心。在接下来几天的一系列令人震惊的事态发展中，Altman 先生和 Brockman 先生与微软联手，利用微软对 OpenAI 公司的巨大影响力，迫使 OpenAI 公司董事会大多数成员辞职，其中包括首席科学家 Ilya Sutskever。</span></p></div></div></blockquote><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="128" data-source-title=""><div class="js_blockquote_digest"><p>据了解，新的董事会成员是由 Altman 先生亲自挑选的，并得到了微软的支持。新的董事会成员缺乏大量的人工智能专业知识，据了解，他们没有能力独立判断 OpenAI 是否以及何时达到了 AGI，也就无法判断 OpenAI 开发的算法是否超出了微软的许可范围。</p></div></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对于诉讼中提到的这些信息和推论，人工智能领域的很多专家都表示没有办法认可。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">华盛顿大学名誉教授、人工智能专家 Oren Etzioni 说：「GPT-4 是通用的，但它显然不是人们通常所指的 AGI」。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">斯坦福大学专门研究人工智能和语言的教授 Christopher Manning 在谈到马斯克诉讼中的 AGI 断言时说：「这将被视为一种夸大的说法」。Manning 说，人工智能界对什么是 AGI 存在不同看法。一些专家可能会降低标准，认为 GPT-4 能够执行多种功能，因此有理由将其称为 AGI，而另一些专家则倾向于将这一术语保留给能够在任何事情上胜过大多数或所有人类的算法。他说：「根据这个定义，我认为我们显然还没有 AGI，而且离它还很远。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">加州大学伯克利分校教授 Michael Jordan 说：「我感觉我们中的大多数研究人员都认为，大型语言模型（如 GPT-4）是一个非常重要的工具，可以让人类做更多的事情，但它们的局限性使得它们远非独立的智能体。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Jordan 倾向于完全避免使用 AGI 这个词，因为它太模糊了。他说：「我从未发现马斯克有任何关于人工智能的言论是经过校准或基于研究现实的。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克的诉讼面临的另一个困难是，OpenAI 长期以来一直使用自己对 AGI 的定义，将其描述为「在大多数有经济价值的工作中胜过人类的高度自主系统」。如今看来，GPT-4 与这一标准相去甚远。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">有趣的是，就连马斯克自己提出的 AGI 定义都能将 GPT-4 移出 AGI 之列。2022 年 12 月，在他宣布 OpenAI 新推出的 ChatGPT「好得吓人」之后不久，这位企业家提出，算法需要「发明惊人的东西或发现更深层次的物理学」，才能配得上这一称号。马斯克写道：「我还没有看到这种潜力。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425591" data-ratio="0.7731481481481481" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8pbADuQmOFIDJfn4rEOSKlCDsvaXpweUh2Czibkndg0e5ic05xPUsQic2g/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">斯坦福大学法学院教授 Mark Lemley 对 AGI 的主张和该诉讼更广泛的法律依据表示怀疑。虽然 OpenAI 看起来确实不那么开放了，而且变得更加以利润为中心，但这给马斯克带来了什么权利还远不清楚。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Lemley 说：「值得注意的是，诉状中并没有包含马斯克与该公司之间的任何合同，也没有包含他执行这些原则或拿回钱的任何权利的文本。」如果存在这些文件，我希望它们能在诉状中占据显著位置。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>「创始协议」在哪里？</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">另一项颇具争议的内容是马斯克在诉状里提到的「创始协议」，而这份协议并没有出现在证据附件里。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">The Verge 网站主编 Nilay Patel 认为，马斯克是在指控 OpenAI 违反了一份并不存在的合同。而且违约索赔中也承认，「创始协议」基本上就是大家在一些电子邮件中捕捉到的蛛丝马迹。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼文件中写道，「OpenAI, Inc. 的创始公司章程以及原告与被告之间多年来的多次书面沟通等文件中均有关于该创始协议的记载（memorialize）。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Nilay Patel 认为，马斯克的律师故意用了「memorialize」一词来替代「written down」，这是因为难懂的内容更容易赚律师费。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">接着，它又引用了「公司章程」，但这不是合同，马斯克也没有签署，只是简单地写了以下内容：</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="86" data-source-title=""><div class="js_blockquote_digest"><p>该公司的具体目的是为人工智能相关技术的研究、开发和传播提供资金。由此产生的技术将造福于公众，公司将在适用的情况下寻求开源技术，以造福于公众。本公司的成立不为任何人谋取私利。</p></div></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这里没有任何协议 —— 也许 OpenAI 复杂的公司结构（包括非营利性公司拥有营利性公司）确实颠覆了这份文件中阐述的理想，但马斯克不能因此起诉，因为这不是一份合同。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">违约索赔还提到了 Sam Altman 写给 Elon Musk 的一封电子邮件，其中提到 OpenAI 开发的技术将用于「造福世界」，马斯克回复说：「完全同意。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425592" data-ratio="1.1522222222222223" data-type="png" data-w="900" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8PYgvztIfduAQ0AM0icBSGiaDYC15jo8sozDM4f1NFHyicV6bvicEXjk9sA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Nilay Patel 表示，他问了几个律师朋友这些看起来像不像合同，他们大多一脸茫然。这与马斯克对合同运作方式越来越模糊的理解如出一辙。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">综合来看，Nilay Patel 认为，马斯克对 OpenAI 的批评是有道理的，但他请的律师让人感觉一言难尽。「他的律师们已经发现，让这位世界首富在无厘头的诉讼中耗费大量的计费时间，比让『事实』符合『法律』或其他普通律师所做的事情更有利可图。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">自 OpenAI 走向闭源以来，马斯克一直在各个平台上抨击这家公司，并表示自己担心 AGI 可能逃离人类控制，采取危害地球的行动。Altman 过去也曾谈到马斯克的一些担忧，他评价马斯克说，「我喜欢这家伙。我认为他完全错了，」「他可以说任何他想说的话，但我为我们正在做的事情感到自豪，我认为我们将为世界做出积极贡献，我试图超越这一切。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考链接：</span></em></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.wired.com/story/wild-claim-at-the-heart-of-elon-musks-openai-lawsuit/</span></em></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://www.theverge.com/2024/3/1/24087937/elon-musk-suing-openai-nightmare-1l-contracts-exam</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425604" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="margin-bottom: 0px;"><br></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“国家队”入局，多模态大模型企业联汇科技宣布完成新一轮数亿元战略融资]]></title>
        <id>2650909083_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909083&amp;idx=1&amp;sn=56b3946f9d97404f5181fab8694f2438&amp;chksm=84e46de5b393e4f3ffcd16b79bd937a36d02272e39332f5bed48cb5b06725e5e16371a1d3c72#rd"/>
        <updated>2024-03-01T03:54:36.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心发布<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;color: rgb(9, 67, 162);">近日，杭州联汇科技股份有限公司（以下简称 “联汇科技”）宣布完成新一轮数亿元战略融资，投资方由中国移动产业链发展基金中移和创投资、前海方舟（前海母基金管理机构）旗下中原前海基金和齐鲁前海基金等多家头部国资与市场化机构组成。领投方中国移动产业链发展基金中移和创投资是贯彻落实中央企业现代产业链链长工作要求，由中国移动与北京市政府、上海市政府发起成立，服务于数字经济、移动信息现代产业链发展、战略新兴产业等国家战略。</span></strong></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">据悉，本轮融资将主要用于多模态大模型及自主智能体的技术研发、产品创新及市场拓展，扩大其在运营商、能源电力、媒体等国家基础行业与重点细分市场的领先优势。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425390" data-ratio="0.6675925925925926" data-type="jpeg" data-w="1080" style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsE8UeiaWJZsA7IoIrE9HiaX3FNJyXgwia9HQk3ibpCNjg4f43bApKN55y2gQ/640?wx_fmt=jpeg&amp;from=appmsg"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">历经千模大战，为何唯有联汇科技能赢得 “国家队” 青睐？这家坐落在杭州钱塘江畔的 AI 大模型准独角兽企业有哪些过人之处？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong><span style="color: rgb(61, 170, 214);">潮起之江・与 OpenAI 同出一门的黑马技术团队</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">脱颖而出，不是偶然，更非一日之功。2019 年，看准智能化大潮拍岸的联汇科技乘势而上，开启了在多模态大模型、向量数据库等技术领域的研究与沉淀，成为了<strong><span style="color: rgb(9, 67, 162);">国内最早自主研发大规模预训练算法模型的公司之一</span></strong>。放眼全球组建核心技术团队，吸引了卡耐基梅隆大学、微软研究院、加州大学、纽约大学等全球顶尖高校与机构的博士、博士后等技术大牛加盟，以极强的技术研发实力成为全球预训练大模型研究的一颗闪亮明星，连续多年在 ACL、ECCV、CVPR、AAAI 等人工智能国际顶会中取得各项竞赛单元的多个冠军。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">一个优秀的公司，背后必定有一个优秀的理念和团队。联汇科技 CEO 兼首席科学家赵天成博士，博士毕业于卡耐基梅隆大学（CMU）计算机系语言技术所（LTI），仅用 4 年半时间拿下了 CMU 六年起步的博士学位，早在 2017 年就提出了学术界最早的生成式对话模型，深耕多模态机器学习与人机交互技术领域的理论与技术研究，主持多项国家、省、市重大科研项目，带领团队在攻克非结构化数据直接使用、跨模态数据融合分析等行业难题上率先取得突破，是国际多模态交互 AI 领域的领军人物。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在谈及多模态大模型技术的价值时，他说：<strong><span style="color: rgb(9, 67, 162);">“在回国之前，我们很早就已经认识到用小模型的方式去服务中长尾场景，投入产出根本不合理，从而更加坚定了走大模型技术方向的决心，我们要做的事情不是 follow 谁，而是 lead 新的技术革新。”</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425391" data-ratio="0.7416666666666667" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6Qb8AKzFIBxiabY5C0v1d98nQvqr99FvMAZicnIaA8icQFf2NLlN6V86X2w/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><em style="outline: 0px;color: rgb(136, 136, 136);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);"><span style="outline: 0px;font-size: 12px;">联汇科技 CEO 兼首席科学家赵天成</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>何以联汇・聚焦多模态大模型</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>率先实现规模化商用</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">眼耳鼻舌身意，色声香味触法，人类用不同的感官来感知物理世界的美妙。相较于单一模态，赵天成博士团队认为多模态大模型在应用上的价值优势更加显著，融合处理文本、图像等跨模态数据，可以使得大模型在复杂情境理解和多样化内容生成方面的表现更为出色，在多模态协作生成、跨领域检索等实际应用场景中的适应性更强。不同模态的数据组成更广泛、多元的数据集，反向促进预训练效率提升，更有助于增强模型泛化能力和整体性能。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;color: rgb(9, 67, 162);">自 2020 年起，联汇科技陆续推出多个版本的自研多模态大模型</span></strong><span style="font-size: 15px;">，其中 1.0 版本是业界最早的视觉语言大模型，具备视频、图片、文本等跨模态数据的融合分析、认知理解能力；2.0 版本一路过关斩将，不负众望成为全国第一个高分通过工信部信通院评测认证的预训练大模型；3.0 版本<strong><span style="color: rgb(9, 67, 162);">在开放识别、视觉问答、认知推理和高效微调四大核心能力实现质变飞跃</span></strong>，同期发布了 OmBot 大模型驱动的自主智能体与视频小欧、文档小欧和创作小欧等首批典型场景应用，为不同行业提供定制化的智能助手。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在产品研发和市场服务方面，客户覆盖中国移动、中国电信、全国人大、国家电网、央广总台等头部企业，通过提供以多模态大模型为核心的产品与服务，赋能各行各业智能化转型，助力国家 AI 普惠加速实现。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在核心技术创新方面，联汇科技发表多篇国际顶会论文，发明专利丰硕，坚持 “以用促研、研用结合”，结合行业用户服务经验获中国电力科学技术进步奖、中国电力科技创新奖、中国广播电视科技进步奖、国家科技部颠覆性科技成果创新等科技奖项。入选 IDC 等国际咨询机构 “中国多模态 AI 大模型领域代表厂商”、“全球向量数据库代表企业”、“2023 年度最佳大模型” 等。一路艰辛跋涉、一路鲜花掌声，如今的联汇科技以不俗的业绩表现成长为人工智能领军企业、中国 AI 基础大模型创新企业。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>联动未来・携手 “国家队”</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>锚定大 B 赛道服务科技强国战略</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">加快推动人工智能发展、培育新质生产力，不仅是国家高质量发展的必然要求，也是联汇科技矢志不渝的追求。对于多模态大模型技术服务的市场坐标，赵天成博士的目标非常清晰：“<strong><span style="font-size: 15px;color: rgb(9, 67, 162);">我们希望 AI 技术是能够真正服务国家、社会，创造出真正的价值，这是我们团队中的很多人结束留洋、归国扎根的初心和目标。</span></strong>我们的客户有很多是服务国家战略的央企、国企和头部企业，他们代表着国家经济发展的大方向。帮助不同行业的企业与客户降本增效，带去看得见、摸得着的收益，是我们专注大模型技术商业落地的动力所在。”</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">本次中国移动产业链发展基金中移和创投资领投联汇科技，双方携手共同推进行业级人工智能技术发展、支撑壮大 “战新” 产业，主动把握 “AI+” 时代潮流。中移和创投资表示：“联汇科技在视觉领域具备海量高质量图文对和独有数据积累，在行业级多模态大模型和自主智能体技术的研究和创新方面取得了令人瞩目的成绩单，多领域快速实现了商业化落地，相信未来联汇科技持续攻坚多模态大模型技术在视觉领域的应用，赋能千行百业加速提质增效。”</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">联汇科技与 “国家队” 的强强联合，将推动自身从智能平台服务向提供全套解决方案服务的大模型产业生态转型，降低多模态大模型技术的落地赋能的技术门槛与成本，进一步加速产业焕新、夯实基础底座、加快重点行业赋能，与千行百业一道迎接 AI 技术红利真正爆发。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong><span style="font-size: 16px;color: rgb(61, 170, 214);">同风起 共潮生・欢迎志同道合之士加入！</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">联汇科技本轮融资主要用于扩充人才队伍、组织架构升级，更好的提供多模态大模型相关的产品与服务，推动更多的行业规模化应用。欢迎有识之士选择联汇、加入联汇，一起携手共创、加快 AI 普惠，让所有人都能享受到一流的大模型应用服务，让美好发生。招聘通道持续开放中！</span></p><p style="text-align: center;margin-bottom: 24px;"><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于神经网络的偏微分方程求解器新突破：北大&字节研究成果入选Nature子刊]]></title>
        <id>2650908962_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908962&amp;idx=1&amp;sn=a3d84a59bf5cbfb0ddaf1b4fd6f40213&amp;chksm=84e46d5cb393e44a158cef28845bcba5f26f746c912779e4caab7864cbf1d82dfb45631cc590#rd"/>
        <updated>2024-02-29T03:50:08.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心发布</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span><span style="letter-spacing: 0.578px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;text-align: justify;"></span></p></div></div></div></div></div><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">近年来，基于神经网络的偏微分方程求解器在各领域均得到了广泛关注。其中，量子变分蒙特卡洛方法（NNVMC）在量子化学领域异军突起，对于一系列问题的解决展现出超越传统方法的精确度 [1, 2, 3, 4]。北京大学与字节跳动研究部门 ByteDance Research 联合开发的计算框架 Forward Laplacian 创新地利用 Laplace 算子前向传播计算，为 NNVMC 领域提供了十倍的加速，从而大幅降低计算成本，达成该领域多项 State of the Art，同时也助力该领域向更多的科学难题发起冲击。该工作以《A computational framework for neural network-based variational Monte Carlo with Forward Laplacian》为题的论文已发表于国际顶级期刊《Nature Machine Intelligence》，相关代码已开源。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425260" data-ratio="0.9300411522633745" data-s="300,640" data-type="png" data-w="729" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5KQnIibq2gV2dZOHFmev9O2QhYA7U8DdCS1uzaic46iaicOBdugfrUNNKdA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文链接：https://www.nature.com/articles/s42256-024-00794-x</span></p></li><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">代码地址：</span></p></li></ul><ul class="list-paddingleft-1" style="list-style-type: circle;"><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">https://github.com/bytedance/LapNet</span></p></li><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">https://github.com/YWolfeee/lapjax</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;letter-spacing: 0.034em;">该项工作一提出即受到相关研究人员的密切关注，围绕该工作已有多个开源项目实现，编程框架 JAX 也计划将该项工作吸收其中。</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该项工作由北京大学智能学院王立威课题组、物理学院陈基课题组联合字节跳动研究部门 ByteDance Research 一同开发完成，作者中有多位北京大学博士生在 ByteDance Research 实习。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>背景简介</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于神经网络的量子变分蒙特卡洛方法（NNVMC）已成为量子化学 - 从头计算领域中一项前沿技术。它具备精度高、适用范围广等优点。但它的阿克琉斯之踵在于过高的计算成本，这也限制了该方法在实际化学问题中的应用。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">作者提出了一套全新的计算框架 "Forward Laplacian"，利用 Laplace 算子的前向传播，显著提升了 NNVMC 方法的计算效率，为人工智能在微观量子问题中的应用打开了新的大门。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>方法介绍</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">Forward Laplacian 框架</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在 NNVMC 方法中，神经网络的目标函数是微观体系的能量，包括动能与势能两项。其中动能项涉及对神经网络的拉普拉斯算子的计算，这也是 NNVMC 中耗时最长的计算瓶颈。现有的自动微分框架在计算拉普拉斯算子时，需要先计算黑塞矩阵，再求得拉普拉斯项（即黑塞矩阵的迹）。而作者所提出的计算框架 "Forward Laplacian" 则通过一次前向传播直接求得拉普拉斯项，避免了黑塞矩阵的计算，从而削减了整体计算的规模，实现了显著加速。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425261" data-ratio="0.4675925925925926" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5ib4Dk6zZYzsopmDnjnsYqsArBPj5zSzfYxCzZXicEiaPcVZsqPxRzH7tw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">LapNet 网络</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">除了有效削减计算图规模之外，Forward Laplacian 框架的另一大特点是能有效利用神经网络梯度计算中的稀疏性，提出神经网络结构 LapNet。LapNet 通过增加神经网络中的稀疏性，在精度无损的同时，显著提升了网络计算的效率。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425262" data-ratio="0.6018518518518519" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W59qOzkOJbsibXYMNL3XZM3Ow0HicSc61ajsDyh5eYAVppZHC5Iaq35a3A/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>计算结果</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">绝对能量</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">作者首先就方法的效率及精度同当前 NNVMC 领域有代表性的几项工作进行了比较。从绝对能量的计算结果而言，作者提出的 LapNet 在 Forward Laplacian 框架下的效率高于参考工作数倍，精度上也与 SOTA 保持一致。此外，如果在相同计算资源（即相同 GPU hour）的情况下比较，LapNet 的计算结果可以显著优于之前的 SOTA。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425263" data-ratio="0.9972222222222222" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5y92D6oGiblKPDSKUV0PlM7iaxqqbsAltwEVTiaMSibPJXAaxveeFNa4hMg/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">加速标度</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">为了更明确地研究作者所提出方法相比于之前 SOTA 的加速标度，作者在不同大小的链式聚乙烯体系上进行了测试，结果可以很明显地看到 Forward Laplacian 工作带来的 O (n) 加速。此处 n 为目标分子中的电子数目。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425264" data-ratio="0.5583333333333333" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5PZLRU6AfveAtN4qyErucmicUjwP4fqpLr4pJDj4kicPibMpYJMjgx9jow/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">相对能量</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在物理、化学研究中，相对能量相较于绝对能量具有更明确的物理意义。作者也在一系列的体系上进行了测试，均取得了理想结果。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425265" data-ratio="1" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5J4ne2g6zxIe3zXibC1a7fliaYr4D6mYSa9YC45ibtvPicdkkaCUrvBUD9Q/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>总结</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">为降低基于神经网络的量子变分蒙特卡洛方法（NNVMC）的使用门槛，北京大学与字节跳动研究部门 ByteDance Research 联合开发了计算框架 Forward Laplacian，实现了十倍的加速。该工作已受到相关研究人员的广泛关注，期望能够推动 NNVMC 方法在更多科学问题中发挥重要作用。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">参考文献</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[1] Han, J., Zhang, L., &amp; Weinan, E. (2019). Solving many-electron Schrödinger equation using deep neural networks. Journal of Computational Physics, 399, 108929.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[2] Hermann, J., Schätzle, Z., &amp; Noé, F. (2020). Deep-neural-network solution of the electronic Schrödinger equation. Nature Chemistry, 12 (10), 891-897.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[3] Pfau, D., Spencer, J. S., Matthews, A. G., &amp; Foulkes, W. M. C. (2020). Ab initio solution of the many-electron Schrödinger equation with deep neural networks. Physical Review Research, 2 (3), 033429.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[4] Li, X., Li, Z., &amp; Chen, J. (2022). Ab initio calculation of real solids via neural network ansatz. Nature Communications, 13 (1), 7895.</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[能看会说的人形机器人，对话的样子吓到我了]]></title>
        <id>2650908860_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908860&amp;idx=1&amp;sn=0ac695768808930827f1ed277654df70&amp;chksm=84e46cc2b393e5d48933bea59bdcbe5efaf9590bc8042a0a30f978b8d2cd31cdda48f5b02c9e#rd"/>
        <updated>2024-02-28T09:21:18.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><p style="margin-bottom: 0px;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">还记得这个表情宛如真人的人形机器人吗？</span></p><p style="margin-bottom: 0px;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425149" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEuy0iajornSyKE4MLqaYOWVQkcsia6Iw3BKLtLlaicEWNjTKuDTX5TSNWA/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">ta被取名Ameca，由一家名为「Engineered Arts」的英国公司制造。最近，这个机器人又迎来了新的升级：&nbsp;&nbsp;</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p class="channels_iframe_wrp wxw_wechannel_card_not_horizontal"><mp-common-videosnap class="js_uneditable custom_select_card channels_iframe videosnap_video_iframe" data-pluginname="mpvideosnap" data-url="https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzGiaDia5pfLg7z8wGy668qkwibL18VC2UD9uzcuNdicuL9iavYiau5XWMQuEAYLyGBgsq8aTdFbEoup82qLn3xZY1pp8A&amp;bizid=1023&amp;dotrans=0&amp;hy=SH&amp;idx=1&amp;m=&amp;scene=0&amp;token=AxricY7RBHdUIpNuHuBpHMQUg0etqyNCD2X5HtjcFyoXuCaVBOjrmPj7TxHlbbOHyxdLDjZyHJWI" data-headimgurl="http://wx.qlogo.cn/finderhead/PiajxSqBRaEKs6XzYjCzlSsfrOck5ZdKLHuqicYEiaI62Ty9EQxZmibuCQ/0" data-username="v2_060000231003b20faec8c7e5811fcbd2cc05eb34b077bf43ae33648ee0ea039da9063a594944@finder" data-nickname="机器之心机动组" data-desc="能看会说的人形机器人，对话的样子吓到我了！模仿人类说话，观察描述世界！英国公司Engineered Arts宣布人形机器人「Ameca」拥有了视觉能力。#机器人#人形机器人#科技#前沿科技#AI#具身智能#人工智能" data-nonceid="5764530620137363735" data-type="video" data-mediatype="undefined" data-authiconurl="https://dldir1v6.qq.com/weixin/checkresupdate/icons_filled_channels_authentication_enterprise_a2658032368245639e666fb11533a600.png" data-from="new" data-width="1080" data-height="1920" data-id="export/UzFfAgtgekIEAQAAAAAAMXkHIt1TSQAAAAstQy6ubaLX4KHWvLEZgBPE5oJMFzxpc5-FzNPgMIstAxNl4XvKasvz3AKLRPr3" data-isdisabled="0" data-errortips=""></mp-common-videosnap></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从视频中可以看到，现在Ameca不仅表情丰富，还拥有了观察周围环境并与人交流的能力，而且音色、语言风格都可以定制。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Ameca说话的能力是通过接入大型语言模型（早先是GPT-3）来实现的，所以交流起来和语音版ChatGPT体验非常接近。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">观察世界的能力则来自安装在眼睛、胸部等处的各个摄像头。这些摄像头可以识别人脸、物品和周围环境，并判断在谈话中谁在注意倾听或是在做眼神交流。有时 ，Ameca 也需要多试一次才能准确看到目标（比如，视频里看到第三个人体头部的解剖模型）。在最近举办的2024年世界移动通信大会（MWC 2024）上，Ameca接受了很多媒体的「采访」。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3347068431761653760" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEeSBKFWW9rrlCrvWEdTBvff2pUQJWKgicOAsrSJOs1X5q9ogwU4jotjQ%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1920" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3347068431761653760"></iframe></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">之前的视频显示，如果给Ameca安上手臂，ta也可以做一些简单的事情，比如画画（在接入文生图AI模型Stable Diffusion之后）以及尬舞。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;"><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3347048282291683332" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEa79d3BMOUNHyaVFjBE0mU4mmOjWYr6qLgB8mFeHgg7UxfsdGv4ocFg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1920" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3347048282291683332"></iframe></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425150" data-ratio="1.775" data-s="300,640" data-type="gif" data-w="320" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEbicr5gudLHdQ8LBIvWMosFE4fVbeqcKZamtyuporNOZTCqx5YWO1MEg/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">当然，Ameca 目前还走不了路，只能固定在地板上。不过，实验室已经在测试实验用腿。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">值得注意的是，Ameca 价格不菲。据媒体报道，特斯拉 Optimus 价格（马斯克估计量产后价格不到２万美元）甚至不及 Ameca 基本款的十分之一。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">研发 Ameca 的英国机器人公司 Engeneered Arts 规模不大，位于英国的法尔茅斯。负责人 Will Jackson 出生在一个艺术家庭，父母都参与过机器人制造，他也耳濡目染地倾向于为一些主题公园、电影娱乐公司、博物馆等机构制作机器人。有的提供向导服务，有的被大学作为研究平台。近几年，他们将所有的资源都投入到了 Ameca 的研发上，它也是该公司迄今为止最先进的机器人。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Will Jackson 坚持认为，建造人形机器人是为了让他们完成与人类互动的任务（而不是为了进工厂和仓库）。例如，经过这几年的研发，Ameca 也许可以成为老人的陪护（提醒＋关注）。为此，他们还教机器人下棋，但下棋水平不能太高。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为了成功与人类互动，机器人需要有一张脸——Jackson 认为，人脸是我们所拥有的宽带最高的通信工具。面部能表达的东西要比你能说出来的要多。因此，Ameca 的脸是由一张受电子系统控制表情动态的乳胶制皮肤构成，非常富有表现力。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425152" data-ratio="0.56125" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsENGJicvR1hficSupKd1TaxQLvibKcmFhYEJP60kn1OO0THHmCTKTYJQhKg/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">视频前半段，除了一口英式英语，你是否也注意到了 Ameca 的微表情。调侃时会带点笑意；思考时会闭眼，有时也会转动眼珠？</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425151" data-ratio="0.5633333333333334" data-s="300,640" data-type="gif" data-w="600" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEGCtib246vNpc5br0rX6D9jYUZUiafMyZVpykN7u32zGlGnIaPxz7ZRuw/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Engeneered Arts 最初也为娱乐业制作过动画人物，也有能力构建出极为逼真的面孔，但后来还是刻意按照人们从科幻小说获得的印象设计了 Ameca 的脸，皮肤呈灰色，有明显的接缝，还没有头发。据说，这样设计是为了避免恐怖谷效应。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425154" data-ratio="0.56125" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsE38EIS4Gyj0yQr7clLPHyad5s3Gn4JfhPkjiaE7hWHOafQ7wYyabBUyw/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">至于人形机器人与人类互动中的安全问题，公司也在通过工程方法加以解决。Jackson 注意到人类的四肢之所以能避免伤害他人，原因之一是他们既结实又松软。不过，现在还没有那种既小巧又强大的执行器能在机器人身上实现这一点。不过，他们也在努力克服这个难题，毕竟，如果 Ameca 会失控撞到人，以社交为生的它们也就失去了意义。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>参考链接：</em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>https://www.youtube.com/watch?time_continue=1&amp;v=VXlpF3DrVP0&amp;embeds_referring_euri=https%3A%2F%2Ftwitter.com%2F&amp;source_ve_path=Mjg2NjY&amp;feature=emb_logo</em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>https://www.economist.com/science-and-technology/2022/11/07/humanoid-robots-are-getting-close-to-reality?utm_medium=cpc.adword.pd&amp;utm_source=google&amp;ppccampaignID=17210591673&amp;ppcadID=&amp;utm_campaign=a.22brand_pmax&amp;utm_content=conversion.direct-response.anonymous&amp;gad_source=1&amp;gclid=CjwKCAiAivGuBhBEEiwAWiFmYU9-IIvzfA2H0haQ-9meiKTYeebsVZlOgpxwmkxtTMSL80_37JK3QxoChkkQAvD_BwE&amp;gclsrc=aw.ds</em></span><span style="font-size: 15px;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425153" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><div style="line-height: 1.75em;"><p style="display: none;margin-bottom: 0px;"><br></p></div><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name>关注生成式AI用例</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mistral AI新模型对标GPT-4，不开源且与微软合作，网友：忘了初心]]></title>
        <id>2650908731_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908731&amp;idx=1&amp;sn=ede59d27d5992ca5c5274a76b837da2e&amp;chksm=84e46c45b393e553b2dca187f7e11752b476677101894f7c1feed7ac23908432d8afd9790fcb#rd"/>
        <updated>2024-02-27T03:41:25.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: auto;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="29" data-source-title="" mp-original-font-size="15" mp-original-line-height="24" style="color: var(--weui-FG-1);line-height: 24px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-size-adjust: auto;visibility: visible;"><div class="js_blockquote_digest" mp-original-font-size="15" mp-original-line-height="24" style="outline: 0px;visibility: visible;line-height: 24px;"><p style="outline: 0px;visibility: visible;line-height: 1.75em;"><span mp-original-font-size="15" mp-original-line-height="26.25" style="outline: 0px;visibility: visible;line-height: 26.25px;letter-spacing: 0.578px;">「欧洲版 OpenAI」的「最强开源大模型」，被微软收编了。</span></p></div></blockquote><p style="letter-spacing: 0.578px;text-wrap: wrap;margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">生成式 AI 领域，又有重量级产品出现。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">周一晚间，Mistral AI 正式发布了「旗舰级」大模型 Mistral Large。与此前的一系列模型不同，这次 Mistral AI 发布的版本性能更强，体量更大，直接对标 OpenAI 的 GPT-4。而新模型的出现，也伴随着公司大方向的一次转型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">随着 Mistral Large 上线，Mistral AI 推出了名为 Le Chat 的聊天助手（对标 ChatGPT），任何人都可以试试效果。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425047" data-ratio="0.5636623748211731" data-s="300,640" data-type="png" data-w="699" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffgbqZBNggCH8pM3WMUW6XBSu6x3TGP1HXdbpawrlbge5JAWatIxVkBg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(123, 12, 0);">试用链接：https://chat.mistral.ai/</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">此前，Mistral AI 提出的 Mistral-Medium 因为强大的性能、「意外」的开源而名噪一时，目前很多大模型初创企业都已不再对标 Llama 2，而是将 Mistral AI 旗下模型作为直接竞争对手。此次 Mistral Large 的出现，自然迅速吸引了众人关注。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人们首先关注的是性能，尽管在参数数量上不及 GPT-4，Mistral-Large 在关键性能方面却能与 GPT-4 媲美，可以说是当前业内的前三：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425048" data-ratio="0.9593417231364957" data-s="300,640" data-type="jpeg" data-w="1033" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffKNNhZUCQiaToREJicwWnLpdiaFLBoaRw54PA39ZUHn6icV5eXUVdyDtyNw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的推理准确性优于 Claude 2、Gemini 1.0 Pro、GPT-3.5，支持 32k token 的上下文窗口，支持精确指令，自带函数调用能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人们也发现 Mistral Large 的推理速度超过了 GPT-4 和 Gemini Pro。然而优点到此为止。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">模型除了增加体量，也需要有相应的数据。在模型发布后，人们发现它生成的文本有一种 ChatGPT 的既视感。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425049" data-ratio="0.6564814814814814" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffGib82Q5OvjdXPicYF0duUh6qBlf6waf8b129Ld3SfDNicw323n9Q6IJYQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">如果说为了能赶上业内最先进的 GPT-4，使用 AI 生成的内容进行训练或许并不是什么大问题。但 Mistral Large 的出现也给 AI 社区的人们带来了危机感：它并不是一个开源大模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425050" data-ratio="0.48318924111431316" data-s="300,640" data-type="jpeg" data-w="1041" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffaxgVD5Suqdr7tfjugalJvH0LrJHXTpeUjhfLurQq6aOGO1UPKO7Kiaw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这次发布的大模型有跑分，有 API 和应用，就是不像往常一样有 GitHub 或是下载链接。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">有网友发现，新模型发布后，Mistral AI 官网还悄悄把所有有关开源社区义务的内容全部撤掉了：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425051" data-ratio="1.183495145631068" data-s="300,640" data-type="jpeg" data-w="1030" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffbNHZB6HYRlX6ibXozXu6VviafRd33OQQYfdPwteS3gYwspf2p8AFkafA/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">难道以开源起家的 Mistral AI，成立才不足一年，这就要转向了吗？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 目前已经能在 Mistral AI 自有平台 La Plateforme 和微软 Azure 上使用。除了 Mistral Large 之外，Mistral AI 还发布了新模型 Mistral Small，针对延迟和成本进行了优化。Mistral Small 的性能优于 Mixtral 8x7B，并且推理延迟得到了降低，提供了一种开放权重模型和旗舰模型之间的中间方案。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但模型的定价也引发了一些质疑。比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425052" data-ratio="0.3787037037037037" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffy48AuaWgsje5qB3PSzKtsCl1T0sia2M1fwjEoD76dia31icB3dy4cQ9pg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">如果以商业大模型的标准来看待，Mistral Large 的定价和 GPT-4 相比并不具备优势，这又该如何吸引客户呢？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425053" data-ratio="0.7333333333333333" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffNtbGFYbLmu1Q3Ub1c2ktgGXfB9f2IANt41By9aRf5svHPLMGAYqTtw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这位业内人士表示：「如果它的价格是 GPT-4 Turbo 的一半，我会更理解。」</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425054" data-ratio="0.6027777777777777" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffMGf758vmqdKNsvmTXvUN07EHTKXAjSH1mfQUNBKB4zGryfJRxJBGAg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">新的 Mistral AI「大杯」模型，表现如何？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在官方博客中，Mistral AI 详细介绍了 Mistral Large 的功能和优势：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 在多个常用基准测试中取得了优异的成绩，使其成为世界上排名第二的可通过 API 普遍使用的模型（仅次于 GPT-4）：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425055" data-ratio="0.5067920585161965" data-s="300,640" data-type="png" data-w="957" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaff8aArzEMWN8DqrgfZ9rsPMXsvdV42h9anquNXAeaoAkonc3I3rc3Qmg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;letter-spacing: 0.034em;">GPT-4、Mistral Large（预训练）、Claude 2、Gemini Pro 1.0、GPT 3.5 和 LLaMA 2 70B 在 MMLU 上的比较（测量大规模多任务语言理解）。<br></span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的优势如下：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的母语是流利的英语、法语、西班牙语、德语和意大利语，对语法和文化背景有细致入微的理解；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的 32K Token 上下文窗口允许从大型文档中精确调用信息；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">其精确的指令跟随能力使开发人员能够设计自己的审核策略 ——Mistral AI 以此来设置 le Chat 的系统级审核；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 本身就能够进行函数调用。这与在 la Plateforme 上实施的受限输出模式一起，实现了大规模应用程序开发和技术堆栈现代化。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">关于基准测试结果对比，可以参考以下：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">推理和知识</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 展现出了强大的推理能力。下图报告了预训练模型在标准基准上的性能：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425056" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiafficaVQMtjxp9BV9dankUjx6MAiaZib3PibGLaTtvPib5v7Eria6CCbyqwNNnQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">与多个领先 LLM 模型在广泛常识、推理和知识基准上的表现对比，基准包括 MMLU（测量理解中的大规模多任务语言）、HellaSwag（10-shot）、Wino Grande（5-shot）、Arc Challenge（5-shot）、Arc Challenge（25-shot）、TriviaQA（5-shot）和 TruthfulQA。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">多语言能力</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 具有原生的多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425057" data-ratio="0.23333333333333334" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffibM5bCJzDe8ZPwhmTL6EgK28fKaTTxUQeibVxAMR2YFNVnEnkKbITflA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Mistral Large、Mixtral 8x7B 和 LLaMA 2 70B 在 HellaSwag、Arc Challenge 和 MMLU 上法语、德语、西班牙语和意大利语的比较。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">数学和编码</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 在编码和数学任务中表现出顶尖的性能。下表报告了一系列流行基准的性能，以评估一些顶级 LLM 模型的编码和数学性能。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425058" data-ratio="0.46794871794871795" data-s="300,640" data-type="png" data-w="936" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffcNe6qHicDukX0ribGib99nS6kOH6MWLOibiadKx3EnsSE8A17QJzetTm8dg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">领先 LLM 模型在流行编码和数学基准上的性能：HumanEval pass@1、MBPP pass@1、Math maj@4、GSM8K maj@8（8-shot）和 GSM8K maj@1（5-shot）。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">与微软合作，行 OpenAI 故事</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在发布 Mistral Large 等模型的同时，Mistral AI 还宣布了一个消息：将与微软合作，在 Azure 上提供自己的模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">此次合作使 Mistral AI 成为第二家在微软 Azure 云计算平台上提供商业语言模型的公司。这有助于 Mistral AI 将自己的模型推向市场，也让 Mistral AI 有机会使用 Azure 的尖端 AI 基础设施，以加速其下一代大型语言模型的开发和部署。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425059" data-ratio="0.32407407407407407" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffrOaXib6q1Jkicfw00FIFN7kI283JtyMu8ZJ1Lr10HNKBicP0BiasNV74wQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这家公司表示，「在 Mistral AI，我们的使命是让前沿人工智能无处不在。这就是我们今天宣布将自己的开放和商业模型引入 Azure 的原因。微软对我们模型的信任让我们前进了一步！」</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这项为期多年的协议标志着微软正在其最大的赌注 OpenAI 之外，努力提供各种人工智能模型，为其 Azure 云服务吸引更多客户。去年 11 月，OpenAI 经历了 CEO Altman 被解雇（后又重返）的风波。而作为最大的股东，微软在消息公布前 5 到 10 分钟才从 OpenAI 那里得到消息。在这次动荡后，微软设法在控制 OpenAI 的非营利性董事会中获得了一个无投票权的观察员席位。这让他们对 OpenAI 的内部运作有了更多了解，但在重大决策上，微软依然没有投票权。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 对路透社表示，作为交易的一部分，微软将持有该公司少数股权，但未透露细节。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">微软证实了对 Mistral AI 的投资，但表示不持有该公司的股权。这家科技巨头因向 OpenAI 提供巨额资金而受到欧洲和美国监管机构的审查。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">根据公告，微软与 Mistral AI 的合作主要集中在三个核心领域：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">超算基础设施：微软将通过 Azure AI 超级计算基础设施支持 Mistral AI ，为 Mistral AI 旗舰模型的 AI 训练和推理工作负载提供一流的性能和规模；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">市场推广：微软和 Mistral AI 将通过 Azure AI Studio 和 Azure 机器学习模型目录中的模型即服务（MaaS）向客户提供 Mistral AI 的高级模型。除 OpenAI 模型外，模型目录还提供了多种开源和商业模型。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人工智能研发：微软和 Mistral AI 将探索为特定客户训练特定目的模型的合作。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">除了微软，MistralAI 还一直在与亚马逊和谷歌合作，分销自己的模型。一位发言人表示，该公司计划在未来几个月内将 Mistral Large 应用于其他云平台。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 成立于 2023 年 5 月，由来自 Meta Platforms 和 Alphabet 的几位前研究人员 ——Arthur Mensch（现任 CEO）、Guillaume Lample 和 Timothee Lacroix 共同创立。成立不到四周，Mistral AI 就获得了 1.13 亿美元 的种子轮融资，估值约为 2.6 亿美元。成立半年后，他们在 A 轮融资中筹集了 4.15 亿美元，估值飙升至 20 亿美元，涨了七倍多。而此时，他们仅有 22 名员工。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425060" data-ratio="0.3175925925925926" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffMCNSfTnABSfgSqibicDmOlNp0Na4pKqiaibZFjgz16mH78jjicyUJZdJjSw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">总体来说，Mistral AI 的模型现在有以下几种获取方式：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 自己的 API：该接入点安全地托管在 Mistral AI 位于欧洲的基础设施上，使开发人员能够在各种型号的模型上创建应用和服务。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Azure：Mistral Large 可通过 Azure AI Studio 和 Azure Machine Learning 获取，其用户体验与 Mistral AI 的 API 一致。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">安全部署：Mistral AI 的部分模型可以部署在用户自己的环境中，用于对安全性最敏感的用例。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">感兴趣的读者可以前去尝试。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考内容：</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://mistral.ai/news/mistral-large/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://techcrunch.com/2024/02/26/mistral-ai-releases-new-model-to-rival-gpt-4-and-its-own-chat-assistant/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.reuters.com/technology/microsoft-partners-with-openais-french-rival-mistral-2024-02-26/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425061" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>关注大模型的</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[国内公司有望做出Sora吗？这支清华系大模型团队给出了希望]]></title>
        <id>2650908691_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908691&amp;idx=1&amp;sn=1f4eb958d61d40b568bac20fff6cc165&amp;chksm=84e46c6db393e57b69240f690d8e548c04f49feffbb12041a89b22271d26d298e24135b8e348#rd"/>
        <updated>2024-02-26T10:19:24.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心原创<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">作者：张倩</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="32" data-source-title="" style="outline: 0px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 0.578px;visibility: visible;"><div class="js_blockquote_digest" style="outline: 0px;visibility: visible;"><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">在 Sora 代表的视</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">频生成路线上，国内公司其实已有一定的技术储备。</span></p></div></blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;letter-spacing: 0.034em;">2023 年年底，很多人都预测，未来一年将是视频生成快速发展的一年。</span><span style="font-size: 15px;letter-spacing: 0.034em;">但出人意料的是，农历春节刚过，OpenAI 就扔出了一个重磅炸弹 —— 能生成 1 分钟流畅、逼真视频的 Sora。</span><span style="font-size: 15px;letter-spacing: 0.034em;">它的出现让很多研究者担心：</span><span style="font-size: 15px;letter-spacing: 0.034em;">国内外 AI 技术的差距是不是又拉大了？</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3344131265981038597" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8RhQ1NqywibSzHuyE72XN6QXO8Br7CYrxicdynaESd6B7XPCniarXDX3asZFUeHxGw0WjzwGFia7pvBg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3344131265981038597"></iframe></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 0.034em;font-size: 12px;">Sora 生成的新视频</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">根据 OpenAI 披露的技术报告，<strong>Sora 的核心技术点之一是将视觉数据转化为 patch 的统一表示形式，并通过 Transformer 和扩散模型结合，展现了卓越的 scale 特性</strong>。无独有偶，最近发布的 <a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908360&amp;idx=2&amp;sn=7ab6412f5979cb8f1386abb83f30f6d8&amp;chksm=84e462b6b393eba085a27e47431c36e8fa4e61c56a264f085cff56bcdb002f450d64cf41b000&amp;scene=21#wechat_redirect" textvalue="Stable Diffusion 3" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Stable Diffusion 3</a> 也采用了同样的架构。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">其实，这两项工作都是基于 Sora 核心研发成员 William Peebles 和纽约大学计算机科学助理教授谢赛宁合著的一篇论文《Scalable Diffusion Models with Transformers》。这篇论文提出了一种基于 Transformer 架构的新型扩散模型 ——DiT，用对潜在 patch 进行操作的 Transformer 替换常用的 U-Net 主干网络，把大语言模型的可扩展性、涌现性复制到了视觉任务上。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">我们关注到，其实早在 2022 年 9 月，清华团队就提交了一篇名为《All are Worth Words: A ViT Backbone for Diffusion Models》的论文（比 DiT 早两个月）。</span><span style="font-size: 15px;">这篇论文提出了用基于Transformer 的网络架构 U-ViT替代基于CNN的U-Net。对</span><span style="font-size: 15px;">比来看，<strong>两项工作在架构路线上完全一致</strong>：均是提出了将 Transformer 与扩散模型融合的思路；并且在具体的实验路径上也一致，比如采用了相同的 patch embedding、patch size；都得出了同样的结论 ——patch size 为 2*2 是最理想的；在模型参数量上，两者都在 50M-500M 左右的参数量上做了实验，最终都证实了 scale 特性。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">不过 DiT 仅在 ImageNet 上做了实验，U-ViT 在小数据集（CIFAR10、CelebA）、ImageNet、图文数据集 MSCOCO 上均做了实验。此外，相比传统的 Transformer，U-ViT 提出了一项「长连接」的技术，大大提升了训练收敛速度。这篇论文后被 CVPR 2023 收录。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于 U-ViT 架构，2023 年 3 月，该团队再次发布了一项 UniDiffuser 的工作（参见<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650870787&amp;idx=1&amp;sn=af162ab7748c4ab417365b6ca2d613c0&amp;scene=21#wechat_redirect" textvalue="《清华朱军团队开源首个基于 Transformer 的多模态扩散大模型，文图互生、改写全拿下》" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2">《清华朱军团队开源首个基于 Transformer 的多模态扩散大模型，文图互生、改写全拿下》</a>），在开源的大规模图文数据集 LAION-5B 上训练了 10 亿参数量的多模态模型。同一时期，主攻通用多模态大模型赛道的生数科技正式成立（参见</span><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650881171&amp;idx=2&amp;sn=bdf6e9da71206b7dc18bf6f7917e215c&amp;chksm=84e4f8edb39371fba72a955fbee2dd6092f44eaef4206d217fbb5ed5352d7aad883c9b1511b7&amp;scene=21#wechat_redirect" textvalue="《专访生数科技唐家渝：清华系团队拿到上亿融资，用Transformer来做多模态大模型》" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">《</span><span style="font-size: 15px;letter-spacing: 0.034em;">专访生数科技唐家渝：</span><span style="font-size: 15px;letter-spacing: 0.034em;">清华系团队拿到上亿融资，用Transformer来做多模态大模型</span><span style="letter-spacing: 0.034em;font-size: 15px;">》</span></a><span style="letter-spacing: 0.034em;font-size: 15px;">）。区别也在此刻发生，生数科技出于算力资源、技术成熟度等方面的考量，优先尝试将 U-ViT 应用于图文任务，而 OpenAI 则是利用其算力优势跨越式地直接将 DiT 应用于视频任务。</span><span style="letter-spacing: 0.034em;font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">虽然主攻的任务不同，但 U-ViT 同样展示了在视觉任务下的优异能力。与当时同阶段的 SD1.5 比较，UniDiffuser 效果是基本持平的。更重要的是，UniDiffuser 扩展性更强，能基于一个底层模型完成图文之间的任意生成。简单来讲，除了单向的文生图，还能实现图生文、图文联合生成、无条件图文生成、图文改写等多种功能。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425036" data-ratio="0.7611111111111111" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6QXHgl0XqQZBTo5j7diab8d8AApPIumRibX0nl2BXMFhtLE67KxlhJZ3Lg/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;">Unidiffuser开源版效果</span></em><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;"><br></span></em></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425042" data-ratio="0.35555555555555557" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6Qib0cPbymCLS2j8cFWu9vSgZKYnhKiaYEibqwDNRaib6YtnnrrEUVeuCAfA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">Unidiffuser当前效果图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">有了这些对于架构的早期探索，生数科技其实在视频生成上颇具潜力，有望成为最接近 Sora 的中国团队。而且，他们也早已在视频生成方向进行了一些探索。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">那么，未来的路怎么走？在视频生成这个问题上，有哪些棘手的问题需要解决？Sora 又将带来哪些商业机遇？在近期的一次访谈中，<strong>生数科技 CEO 唐家渝、首席科学家朱军</strong>向机器之心透露了自己的看法。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>Sora 的出现比预期早半年</strong></span><span style="font-size: 16px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：首先想请两位回忆一下，第一次看到 Sora 的时候是什么感觉？有没有印象比较深刻的 demo？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我印象最深的是它的流畅性和时间长度。之前 AI 生成的短视频，大家都戏称为 GIF—— 变动小，视频短，只有几秒。Sora 生成的视频长得多，流畅度、自然度又明显好了一个层次，我觉得这是最直观的一个视觉上的冲击。印象比较深刻的 demo 是纸飞机那个场景：一堆纸飞机在森林里面飞，各个纸飞机还会撞在一起，还会跟树叶有一些互动。这本身是一个想象中的场景，但是生成效果逼真度很高，已经具有一定的物理规律的表现能力了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3344086088746778624" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8RhQ1NqywibSzHuyE72XN6QKTibAcYhmpHfydYyeBzk71XTlYXP9Y87zM7ibCLB8kVgNhbOCtLuedfg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3344086088746778624"></iframe></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">如果回头看大家之前对视频生成长度的预判，Sora 的出现其实是超前了。之前能够预测到今年视频生成会快速发展，但当时在技术原理上，大家没有看到特别大的技术突破，所以当时就觉得短视频（几秒钟那种）会是一个主流形式。但 Sora 一下子做到了这么长，还是一个比较 surprise 的事情。原本预计今年年中或年底能做到这个水平，Sora 提前了大概有半年的时间。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>用 Transformer 替代 U-Net 是一个自然想法，</strong></span><strong style="color: rgb(61, 170, 214);font-size: 16px;letter-spacing: 0.034em;">区别在于谁先做出效果</strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：最近关于 Sora 核心创新点的讨论比较多，而且大家提及最多的是它的架构。朱老师能否通俗地解释一下 Sora 的 Diffusion Transformer 架构是怎么一回事，「用 Transformer 替换常用的 U-Net 主干网络」有何必要性？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">以视频数据为例，扩散模型的原理就是在数据上做加噪和去噪。这里很关键的问题，就是能不能准确地预测噪声，设计一个噪声预测网络。过去大家会用传统的 U-Net 去做，但是 Transformer 被证明在可扩展性等方面有很大的优势，所以用 Transformer 去替代 U-Net 是一个很自然的想法，区别就在于谁先做出来效果。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Sora 用到的 DiT 是 2022 年底发布出来的。其实早在 2022 年 9 月份，我们发布了一个叫 U-ViT 的模型。这个模型的主要思想是用 Vision Transformer 去替代 U-Net，和 DiT 核心的想法是一样的，就是用 Transformer 去增强扩散模型。这后来被证明非常有效，特别是在视觉数据的生成上。它一方面保持了扩散模型的优势，另一方面又利用了 Transformer 的可扩展性以及对不同模态的兼容性。相比于传统的 Transformer，我们自己的设计（U-ViT）里面还包括了长连接，它可以让计算效率变得更高，能看到很显著的效果提升。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425041" data-ratio="1.357609710550887" data-s="300,640" data-type="png" data-w="1071" style="width: 379px;height: 515px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6QO4LKyZlDnbFslqtaICwJiaMHfMJtYpq7WcaFxU7D1EBYVaUyJJwDrKw/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;">U-ViT 架构</span></em><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：我们可以从哪些指标上看到这些效果？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">其实在 22 年的时候，大家就已经看到了，用 Vision Transformer 这种架构可以提高生成质量，实现更高的分辨率，也可以更有效地训练更大规模的模型。现在，我们可以看到更多的例子，包括 Sora、Stable Diffusion 3。这些例子一次又一次地证明了，这个架构的潜力是巨大的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：在生数的产品里面，这份工作展现出了什么样的效果？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">我们从一开始就坚持用扩散加 Transformer 的融合架构，也就是多模态原生的架构。之前，很多团队在做多模态的时候，会想说什么模态都对到语言上。但我们认为这种架构不是最优，因为从原理和计算效率上来看，这种方法存在天然的不足，所以从一开始我们就在走扩散加 Transformer 这种路线。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">2022 年我们提出 U-ViT 架构的时候对标的是 Stable Diffusion，当时 Stable Diffusion 刚开源。所以在 U-ViT 架构的基础上，我们又在 2023 年 3 月份开源了一个叫 UniDiffuser 的大模型。这个模型也是基于扩散加 Transformer 的融合架构，可以在文、图两种模态之间进行任意的转换。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">从底层架构的训练到优化到支撑上层的图像、3D、视频的生成，生数一直在坚持这个架构，一直在坚持这种融合的路线。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：您的意思是说，这种融合的路线相比那种单纯地用 Diffusion 或者单纯地用 Transformer 效果都要好，是吗？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">是的。与单纯地用 Diffusion 相比，融合架构的主要优势就是 Transformer 的可扩展性。与单纯地用 Transformer 相比，融合架构在生成视觉数据的效率，包括模型的表示效率和计算效率等方面有很大的优势。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对于 Transformer 这个架构来说，你把所有东西都放到里边，好处就是简单直接。但是，就目前对视觉数据的处理和生成效果来看，扩散还是占优势的。在我们看来，融合模型更符合原生多模态的定位。因为不同类型的数据，它的特点是不一样的，所以应该针对不同模态选择最合适的一种处理方式。从实际的视觉生成效果来看，现在主流的方法也是用扩散模型去做生成，因为用 Transformer 这个架构直接去做生成的话，到目前为止效果还是落后的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：你们的 U-ViT 和 DiT 是同一时期提出的，但是你们选择优先用它去做图文任务，而不是视频生成，是基于什么考量？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">实际上我们也在做视频生成，只是当时基于算力的考虑排了一个优先级。这里面也有我们基于技术成熟度的一个预判。去年，我们是优先从 2D 的图像开始，然后紧接着到 5 月份的时候，我们就做了 3D 生成（从 2D 到 3D），后来我们又做了视频和 4D（ 参见《<a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650904838&amp;idx=3&amp;sn=de12a4c5ab4313d126453fbbf6f2531d&amp;chksm=84e45d78b393d46e0c90c46d9daaab20ac8c66278a1d7729dc205f69af7317d8727442027263&amp;scene=21#wechat_redirect" textvalue="一键实景转动画，清华系初创公司全球首发4D骨骼动画框架" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;letter-spacing: 0.578px;text-decoration: none solid rgba(0, 0, 0, 0.9);">一键实景转动画，清华系初创公司全球首发4D骨骼动画框架</span></a>》）。实际上就是在有了基础的基座之后，我们可以做不同维度的扩增，3D、4D 其实分别是空间、时间上的一个扩展。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">视频实际上是图像的流，它相当于在时间轴上做了一个扩增。所以我们的架构实际上可以很自然地支持短视频的生成，只是当时我们主要聚焦在几秒钟的短视频的生成，没有像 OpenAI 的 Sora 那样一下子做到几十秒、一分钟。这里边有很多原因，但其中一个很重要的原因是，我们手头的资源相对来说确实受限很多。但是，从 2D 图像到视频生成，很多东西是一脉相承的，很多经验（比如大规模训练的经验）是可以复用的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>复现 Sora，还有很多难题需要解决</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：生成几秒的视频和 1 分钟的视频之间的技术差异是巨大的。根据您的经验，除了算力，做到这一点的关键是什么？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">这里面很重要的一块是，针对比较长的视频，怎么有效地表示它的时空信息，怎么有效地去压缩视频数据，学到一个嵌入的表示，然后在上面再去做扩散、生成。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">另外，要让这种架构能够有效训练，数据也很重要。基于之前的 DALL・E 3 等积累的优势，OpenAI 可以对视频数据做到比较有效的语义理解。这在训练数据里是非常关键的。因为在创作的时候，你输入的语言通常是比较有限的、简单的，所以如果想去生成丰富的视频内容，中间需要一个比较强的语义理解过程。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">当然，可能还有很多我们不知道的因素。Sora 的成功不光是一个生成的问题，里面包括语义理解、数据标注、数据清洗、大规模训练以及工程优化等等。这些问题如果没有做过是不知道的，由于 OpenAI 做过很多成功的案例，所以他们做成一个新项目的成功率会更高。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：同样的架构用来做图像任务和视频任务，会有什么不同吗？对生数团队而言，下一步计划如何将该架构从图像任务拓展至视频任务？</span></strong><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">主要的不同在于，视频里面包含很多的时空信息。怎么抓住里面关键的运动、保持住长时间的一致性？这是单张图片不会涉及到的。二者从原理上来说是相通的，我们从去年下半年开始也一直在做视频相关的工作。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">生数底层拥有自主训练的架构，所以在上面我们能够很自然地做各种生成。图像生成是一个基础，图像生成的质量会影响到视频生成的质量。此外，3D 生成我们也持续在做。只是，Sora 比我们预期出现得要早，所以后续我们会加强视频生成这一块。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>打造通用多模态，需要通用架构提供支撑</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：Sora 的发布让我们看到 OpenAI「all in AGI」的野心。他们的技术路线有两个关键点：一是多模态，二是通用化架构。生数科技也是「通用多模态路线」的坚持者，在您看来，通用化架构有何必要性？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">如果想让模型实现更强的通用性，就需要更加通用的模型架构来支撑。以 Sora 为例，在架构上它肯定要融合文字和视觉数据。换句话说，如果你只做视觉或只做文本的话，你在多模态的任务上就不是最优，或者说有些模态不能处理。这是一个很直接的相互支撑的关系。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：做这种通用架构的难点体现在哪几个方面？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">难点就在于，不同模态的数据，特点是不一样的，你是不是直接简单粗暴地用一种方式表示所有数据？这种方式目前来看可能并不是最优，所以需要针对不同数据的特点去分析考虑。另外，不同模态的数据，它的数据量是不一样的，或者说不均衡。在训练过程中，这可能会对你的优化过程产生实际的影响。还有不同模态之间的对齐理解也是问题。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：Sora 出现后，有种声音说，国内外的差距进一步拉大了，您怎么看待这个问题？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">差距是否拉大，这是一个可以辩论的问题。但我觉得，Sora 出来之后，国内外并没有像当初 ChatGPT 出来时那样形成很明显的代差。只是大家现在在工程技术上可能会落后一些。视频生成这个问题，国内也很重视，而且国内做图像、视频相关任务的基础还是比较好的。从当前的结果来看，实际情况可能比想象中要乐观一些。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>来自 OpenAI 的启发：</strong></span></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>技术自信和资源都很重要</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：如果从商业和产品的角度来看，您如何看待 Sora 的成功？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">OpenAI 整体的模式是朝着 AGI 的目标，从底层模型能力提升的层面不断地往前跑，模型本身就可以看作是他们最核心的产品。据说 Sora 这个小组也并没有去考虑太多关于商业和产品的事情，所以可能他们在最开始的时候主要还是聚焦在如何实现真正好的视频生成能力，然后去相信说只要我有这么强的能力，上面一定能搭出更多的商业化产品。对外赋能底层 API 的能力，然后在上层去创建一个繁荣的 AI 生态，是 OpenAI 已经验证成功的一种商业模式了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">从这个维度来讲，我觉得他们成功因素中很重要的一点已经写在了他们公司的价值观里，也就是所谓的 “Scale”，他们整个公司都是相信 scale up 的，官网原话是「如果对此产生了怀疑，就进一步 scale it up」。所以我觉得这也是他们对于自己的技术路线的充分自信和坚持，然后衍生出了现在的成功。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：这对生数科技有什么启发？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">首先是观念上的。我觉得我们在设计了 Diffusion 融合 Transformer 这样一个好的架构，并且已经看到它有巨大的潜力的情况下，应该要更有技术上的自信。这和 OpenAI 去相信 scale up 是类似的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">第二点是，在有自信的同时，如果你要去做 scale up，尤其是基于视频数据，就要去卷入更多的资源。因为像我们或者国内的其他创业公司，其实相比 OpenAI 所拥有的资源还是差很多的。所以我们得敢想敢做地去卷入更多资源，和更多资源方去合作，这样才能把技术自信转变为技术实现，然后变成产品实现。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>视频生成：生数的过去与未来</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：生数之前上线过一些文生视频的能力，可以介绍一下之前的探索工作吗？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我们的技术探索最终是为产品服务的。从产品层面来看，我们之前发布的能力和业界是差不多的，就是几秒的短视频生成和编辑。那个时候主要受限于算力等因素，没有利用已有的架构在视频数据上去完成 scale up。从产品使用角度来看，我们其实看到这种几秒的视频已经能够帮用户去做一些创意的工作，即使要制作长视频，其实也可以通过设计脚本来拼接短视频实现。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">但 Sora 的出现让我们看到，原生长视频生成的能力不仅从内容创作的角度，可以帮助我们去进行长镜头等更加艺术化的表达，也能外显出一定的物理世界理解能力，使得生成的视频更加自然。这也大大增强了我们加大视频生成研发投入的信心和决心。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此外，我们之前的这些探索其实也是为了牵引内部的一些工程基础建设，比如为视频数据的收集、清洗、标注以及模型的高效训练积累经验。这些积累和最接近Sora的架构，使得我们在做长视频生成时，对最终的效果更加抱有期待。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：据您所知，Sora 的开发、应用成本有多高？如果要做类似产品，生数要如何应对随之而来的成本问题？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">就开发成本来说，业界估计资源比较充分的状态需要达到万卡（英伟达 A 系列）的水平。由于我们之前在大规模训练上做了很多加速的工作，所以我们的需求实际评估下来会少一些。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如果估算一下 Sora 的应用成本，目前生成 60 秒的高清视频大概需要几块到几十块人民币。所以 OpenAI 现在还没有完全放出来这个东西，估计也是有算力、成本方面的顾虑。此外，模型生成视频的成功率也是未知数，这可能也是一个顾虑。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">要降低应用成本，肯定要在这个过程中做一些模型压缩的工作，包括一些分布式的操作 —— 比如在手机、笔记本端去做一些推理，也会是大家去做的一个衍生方向。另外，架构层面的一些优化肯定也会持续去做。所以应用成本的问题，我们觉得相对来说还是比较乐观的。</span></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>什么叫「原生多模态模型」？&nbsp;</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：根据您公司的描述，你们走的是「原生多模态大模型」赛道，能否介绍一下这个赛道和其他赛道的区别，以及该赛道国内外玩家的具体情况。</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">其实定位原生多模态这个赛道是说，我们从第一天就坚持做一个完整的通用多模态大模型，而不是训练多个模型，对这些模型的能力做排列组合式的使用。我们的做法是从底层的架构出发，天然地去考虑通过一个模型支撑不同数据的输入输出，它的特点是模型学到的知识会更加充分，而且在使用的时候，不用调用不同的模型去做组合应用，因此推理效率会更高。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">举个具体的例子，GPT-4支持文本-文本，DALL·E 3支持文本-图像，GPT-4V可同时输入文本和图像，但输出仅文本，在应对开放的视觉任务时，是通过调用DALL·E 3或者GPT-4V的接口来实现，而原生的技术路线是基于一个底层架构实现「GPT-4V + DALL·E 3」的统一，能应对广泛开放域的文本和视觉交互类的复杂场景。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这个领域的国外玩家主要是谷歌（Gemini）和 OpenAI（Sora）。国内的话，我们是最早、也可能是唯一坚持做通用性的多模态大模型的公司。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：从产品的角度，您如何定义「原生」？</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">从产品角度来看，其实我们更多的是考虑有了原生多模态模型的加持之后，产品所带来的用户体验有没有指数级的提升，像「所想即所得、所说即所得」就是一种指数级的提升。我们所做的事情，无论是图像、3D 还是视频的生成，其实都是朝着这个目标在努力的。就是让一个即使没有任何专业能力的人，都可以去创作出他想要的画面，或者说在数字世界或物理世界具象化出想象中的某个东西。我个人心中的标准之一就是，自己的亲戚朋友最终会不会喜欢去用这么一个产品。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>Sora 所带来的商业机遇</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：在关于 Sora 是否理解物理世界的争论中，Keras 之父 François Chollet 曾提到，这个问题之所以重要，是因为它决定了生成图像、视频的应用范围 —— 是仅限于媒体生产，还是可以用作现实世界的可靠模拟。如果分两种情况去讨论，Sora 的发布将分别带来哪些新的商业机遇？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我觉得前者主要对应的是数字世界里的内容生产。在数字世界中，我们平时接触到的内容涉及电视电影、广告、教育、社交娱乐等多个行业。因为视频形态在我们日常生活中用得太多了，所以即使只看跟视频相关的场景，它的应用前景就已经非常不可限量了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如果它能理解物理世界，那应用范围就不止局限在数字世界了，而是可以和物理世界产生交互。比如，它可以和机器人结合实现具身智能，也可以用于自动驾驶，用于数字孪生。之前一个一个构建小模型的方法可能有很多 corner case 照顾不到，如果模型真能了解到物理世界的规则，我们就能使用一个通用模型来处理所有的关于物理世界的认知和仿真任务，这可能会极大地推动社会运行方式的进化。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425037" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>张倩</name>
        </author>
    </entry>
</feed>