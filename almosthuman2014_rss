<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>almosthuman2014</id>
    <title>机器之心</title>
    <updated>2024-03-03T07:26:53.669Z</updated>
    <generator>awesome</generator>
    <author>
        <name>机器之心</name>
    </author>
    <subtitle>专业的人工智能媒体和产业服务平台</subtitle>
    <logo>http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Hw3m9nYrAsOLx3ZicPxogLrGibnMYybTBN7EGzEhCVulznVbDob2ib3mwdMMQXtOhO6bqCdSz9kX7w/0?wx_fmt=png</logo>
    <icon>http://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Hw3m9nYrAsOLx3ZicPxogLrGibnMYybTBN7EGzEhCVulznVbDob2ib3mwdMMQXtOhO6bqCdSz9kX7w/0?wx_fmt=png</icon>
    <entry>
        <title type="html"><![CDATA[十年内出现AGI？下一代Gemini能感知环境？DeepMind CEO哈萨比斯畅谈AI]]></title>
        <id>2650909283_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909283&amp;idx=1&amp;sn=f3d4b8a421b98f46bc8d13583dd6cbdc&amp;chksm=84e46e1db393e70b96c2fb267d437999cc1968fdf43bc0d5fbedd1ea5f48f72eb64ce8476f82#rd"/>
        <updated>2024-03-03T04:33:54.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：Panda</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="69" data-source-title=""><div class="js_blockquote_digest"><div><p style="margin-bottom: 0px;margin-top: 0px;line-height: 1.75em;"><span style="font-size: 15px;">智能本质、对齐、Gemini、超人类AI和多模态、AGI……在这场干货满满的访谈中，Demis Hassabis可谓「知无不言、言无不尽」。</span></p></div></div></blockquote><p><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">「如果我们在未来十年内拥有类似 AGI 的系统，我不会感到惊讶。」Google DeepMind 联合创始人和 CEO Demis Hassabis 近日在人工智能播客节目 Dwarkesh Podcast 上如是说。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在长达一个小时的节目中，Hassabis 分享了自己对智能本质、强化学习、规模扩展和对齐、AGI、多模态等主题的看法。机器之心选择性地整理了其中的主要内容并进行了适当编辑以便阅读。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="318" data-imgfileid="503425612" data-ratio="0.5497076023391813" data-s="300,640" data-type="jpeg" data-w="684" style="width: 578px;height: 318px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9prHyicKeAPCJpddplfLTH4W4VEvBFLvuSKibjAKZDSAoPJiakLrTQrUX8LOhfXKTkfMWYZiaaX9CPicw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">智能的本质</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：第一个问题：您有神经科学背景，那么您是怎么看待智能的？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这个问题很有趣。智能非常宽泛，可普遍用于各种用途。我认为这说明对于大脑处理我们周围世界的方式，必然存在某种高层级的共同之处，算法层面的共同之处。当然，大脑中有做特定事情的特定部分，但我认为所有这些事情下面可能有一些基本原则作为支撑。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您怎么看待这一事实：对于现在的 LLM，当你向其提供大量特定领域的数据时，它们往往会在那个领域变得格外地好？难道不能在所有不同领域上实现普遍提升吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，我认为当在某个领域内获得提升时，有时候也会在其它领域获得出人意料的提升。举个例子，当这些大模型的编程能力提升时，它们的一般推理能力实际上也能得到提升。所以现在是有一定的迁移学习的证据。而且这也是人脑学习的方式。如果我们大量经历或练习象棋或写作等事项，我们就会越来越擅长对应的事情，即便我们是使用某种通用学习技术和通用学习系统来学习某个特定的领域。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：以语言和编程为例，在神经网络中，是否存在某种地方存在某种机制让模型的语言和编程能力一起提升？&nbsp;</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们目前的分析技术还不足以确定这一点。实际上，对于这些系统构建的表征的机制分析，还有待大量研究。我有时候把这称为虚拟脑分析（virtual brain analytics）。从某个方面看，这有点像是 fMRI，或者记录真实大脑中单个细胞的活动。对于这类分析技术，可以怎样将其类比到人造心智呢？这方面有很多出色的研究成果。比如 Chris Olah 就在研究这个，我很喜欢他的研究。有很多计算神经科学的技术可以引入过来分析我们目前正在构建的这些系统。事实上，我也在努力鼓励我在计算神经科学领域的朋友思考这个方向，应用他们的所学来理解大型模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：由于您有神经科学背景，您多半了解一些其他 AI 研究者不太了解的有关人类智能的知识。这方面的知识有哪些？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：神经科学的助益很大。看看过去一二十年的研究就能知道。事实上我已经思考这些三十多年了。在这新的一轮 AI 浪潮早期，神经科学提供了大量有趣的引导性线索。于是出现了强化学习以及深度学习等技术。我们在这方面也有一些开创性的研究成果，比如经历重放（experience replay）以及已经变得非常重要的注意力（attention）概念。很多这些成果的初始灵感都是来自对大脑工作方式的理解，当然它们并不完全一样。一种是工程开发出的系统，另一种是自然的系统。它们并不是某种算法的一对一映射，而更像是某种指示方向的灵感——或许是某种架构思想，或者算法思想或表征思想。毕竟大脑本身就是通用智能存在的证据。人类就是这样的，一旦知道某件事是可能的，就更容易朝那个方向努力，因为你知道这就是一个努力进取直到某时取得成功的问题，而不是能否成功的问题。这能让人更快地取得进展。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为在如今成功的背后，神经科学启迪了很多人的思考，至少是间接的。至于未来，我认为在规划方面还有很多有趣的问题有待解决。还有大脑是以何种方式构建出了正确的世界模型？举个例子，我研究过大脑是如何进行想象的，你也可以将这看作是心智模拟。我们就会问：为了执行更好的规划，我们是以怎样的方式创建了对于世界的非常丰富的视觉空间模拟？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">LLM 之上的强化学习</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：LLM 能否具备这种类似树搜索的能力？您对此怎么看？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是一个非常有潜力的研究方向。我们在持续不断地提升大型模型，让它们成为越来越准确的世界预测器。在效果上，就是让它们成为越来越可靠的世界模型。这明显是必要的，但我认为这可能并不是 AGI 系统的充分条件。在这之外，我们还在研究 AlphaZero 这样的规划机制——其可使用模型执行明确的规划，从而在世界中实现特定的目标。另外可能还会搭配某种链式思维或推理路径，也可能使用搜索来探索巨大的可能性空间。我认为这是我们当前的大模型所缺少的能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：对于这些方法所需的巨量算力，您会怎么获得？您认为这方面的效率会怎么得到提升？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，摩尔定律会帮助我们。每一年，计算能力都在提升；但我们更关注样本高效型的方法以及复用已有的数据，比如经历重放。世界模型越好，搜索效率就越高。举个例子，AlphaGo 的搜索效率就远高于使用暴力搜索的深蓝（Deep Blue）。深蓝的每一次决策可能需要查看数百万种可能下法。AlphaGo 则只需要大约数万次就能决定下一步。但人类的大师级棋手可能只需检查几百种下法就能得到一个非常好的下一步决策结果。这明显说明，暴力搜索系统对这些棋并没有真正的模型。AlphaGo 有相当不错的模型，而顶级人类棋手拥有更丰富、更准确的围棋或国际象棋模型。这让他们只需少量搜索就能做出世界级的决策。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：但是 AlphaGo 胜过了人类冠军。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：当然，所以我们做出了开创性的成果，DeepMind 也因此出名。我们使用游戏作为验证平台，因为很显然在游戏中的搜索效率更高。另外，在游戏中也更容易设定奖励函数——不管是获胜还是赢取分数。这些是大多数游戏内置的奖励机制。但对于真实世界系统，这却非常困难——该如何定义正确的目标函数、正确的奖励函数和正确的目标？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：人类智能有很高的样本效率，它与 AlphaGo 这些系统得到解答的方式有何不同？比如爱因斯坦如何想出了相对论？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：它们大不相同，因为我们的大脑并不会执行蒙特卡洛树搜索。这不是我们的有机大脑的工作方式。为了弥补这一点，人类的大脑会用到直觉。人类会使用自己的知识和经历来构建非常准确的模型，比如爱因斯坦构建了非常准确的物理模型。如果你阅读一下爱因斯坦的经历，看看他是如何想出那些理论的，你会发现他习惯视觉化地思考那些物理系统，而不只是通过数学公式。这让他有了对这些物理系统的非常直觉化的感知。这让他产生了在当时显得非常离奇的想法。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为这就是我们构建的世界模型的复杂精妙之处。想象一下，如果你的世界模型能让你抵达你正在搜索的某个树的某个节点，然后你就只需要在这个节点附近搜索即可。这样一来，你的搜索量就少多了。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在还有一个问题有待解决：强化学习能否让模型使用自我博弈合成数据来克服数据瓶颈问题？您似乎对此很乐观。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我对此非常乐观。首先，仍然还有大量数据可以使用，尤其是多模态和视频等数据。而且显然，社会也在一直不断增加更多数据。但我认为创造合成数据方面也有很大的发展空间。这方面有一些不同的方法，比如模拟和自我博弈，模拟方法包括使用非常仿真的游戏环境来生成接近真实的数据。而自我博弈则是让模型互相交互或交谈。这种方法在我们开发 AlphaGo 和 AlphaZero 时效果非常好。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：那么该如何确保合成的数据不是来自模型的数据集，而是新数据？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这需要一门完整的学科来进行研究。在这方面，我们仍处于数据管理和数据分析的初级阶段。比如通过分析数据分布，能找到分布中的漏洞，这对于公平与偏见等议题来说非常重要。要将其移出系统，就需要确保数据集能够代表你想要学习的分布。对此人们有一些可以使用的技巧，比如增大数据中特定部分的权重或重放这部分数据。也可以想象，如果你发现你的数据集中有如此漏洞，你可以使用生成的数据来进行填补。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在人们很关注强化学习，但其实 DeepMind 很多年前就研究过了。是否还有类似这样的研究方向——早已经出现了，但还没有引起人们重视？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：事实上，过去几十年来这种事情一直在发生。新旧思想结合起来就有巨大潜力，比如过去的一些想法与更大规模模型和大型多模态模型结合起来也许就能得到激动人心的结果。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：强化学习、LLM、树搜索，哪种方法有潜力催生出 AGI？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：从理论上看，我认为纯 AlphaZero 式的方法没理由不成功。Google DeepMind 和社区一些人正在研究在假设完全没有先验知识、没有数据的前提下，从头开始构建所有知识。我认为这是有价值的，因为这些想法和算法在有一定知识时也能使用。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">话虽如此，但目前来说我认为最可能最快实现 AGI 的方法是使用目前世界上已有的知识，比如网络上的和我们收集的知识。而且我们还有 Transformer 等有能力消化这些信息的可大规模扩展的算法。你可以将一个模型用作某种形式的先验，基于其上进行构建并执行预测，以此启动 AGI 学习。没理由不这样做。我猜想，在最终的 AGI 系统中，大型多模态模型会成为整体解决方案的一部分，但它们本身并不足以成为 AGI。它们还需要额外的规划搜索能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">扩展与对齐</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在有个规模扩展假设（scaling hypothesis）。有人猜想，只要扩大模型和数据分布的规模，智能终会出现，您认同吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是一个需要实验检验的问题。几乎所有人（包括那些最早开始研究规模扩展假设的人）都很惊讶规模扩展所带来的成就。看看现如今的大模型，它们的效果好得简直不合理！大模型涌现出的一些性质相当出人意料；在我看来，大模型是有某种形式的概念和抽象能力。要是回到五年以前，我会说要做到这一点，我们可能还需要另一种算法方面的突破。也许更类似大脑的工作方式。我认为，如果我们想要明确的、简洁的抽象概念，我们依然需要更加理解大脑，但这些系统似乎可以隐式地学习它们。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">另一个出人意料的有趣结果是这些系统获得了某种形式的现实基础知识（grounding/定基），即便它们并未体验过世界的多模态——至少在近期的多模态模型出现之前没有。只是靠语言就能构建起如此大量的信息和模型，着实让人惊讶。对此的原因，我有一些假设。我认为大型语言模型能通过 RLHF 反馈系统获得一些现实基础知识，因为人类反馈者本身就是生活在现实中的人。我们就立足于现实世界中。所以我们的反馈也是立足于现实的。因此这能让模型获得一些现实基础。另外，也许语言中就包含了更多的现实基础，如果你能完全洞悉语言，也许能发现我们之前可能没考虑到的东西，甚至可能已经有语言学家研究过这些方面。这实际上是一个非常有趣的哲学问题。人们甚至可能都尚未触及其表面。看看过去的进展，畅想未来是非常有趣的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">对于你说的规模扩展问题，我认为我们应当尽可能地扩大规模，我们也正在这么做。至于最后会趋近一条渐近线还是撞上铁墙，这是个实验问题，不同的人会有不同的意见。但我认为我们应该直接去测试。没人能想出答案。但与此同时，我们也应该加倍投资创新和发明。这是谷歌研究院、DeepMind 和谷歌大脑的做法，我们在过去十年中开创性地取得了许多成果。这就是我们的生存之道，</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">可以说，我们一半的努力是在扩展规模，另一半则是在研发未来的架构和算法——它们或许是在模型变得越来越大之后所需的。我大概猜想，未来这两方面都需要。所以我们要两方面都尽可能地发力。我们很幸运，因为我们确实能做到这一点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Dwarkesh Patel：再多聊聊定基（grounding）。可以想象，有两件事会让定基变得更加困难。一是随着模型变得更加聪明，它们就能在我们无法生成足够人类标签的领域工作——因为我们不够聪明。而是关于计算。目前我们做的都是下一 token 预测。这就像是一个护轨，限制模型让其像人类一样谈话，像人类一样思考。现在，如果额外的计算是以强化学习形式出现的呢——我们只知道达成了目标但无法追踪是如何达成的？如果这两者组合起来，定基会出现什么问题？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为如果系统没有适当地定基，系统就无法适当地实现这些目标。我认为在某种程度上系统应该有定基，至少要有一些，这样才能在真实世界中真正实现目标。随着 Gemini 这样的系统变得更加多模态，可以在文本数据之外处理视频、音频和视觉数据，这些系统就会开始将这些东西融合到一起。我认为这其实就是一种形式的定基。这样系统就会开始更好地理解真实世界的物理机制。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：为了对齐比人类更聪明的系统，应该怎么做？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我和 Shane（注：Shane Legg，DeepMind 联合创始人，现担任该公司首席 AGI 科学家）还有其他许多人在我们创立 DeepMind 之前就已经在考虑这个问题了，因为我们计划着取得成功。2010 年时，还没什么人研究 AI，更别说 AGI 了。但我们那时就知道，如果我们能通过这些系统和思想取得成功，创造出的技术将会具有让人难以置信的变革力量。所以我们 20 年前就在思考了，这样会有什么正面和负面的后果。正面的后果就是惊人的科学成果，比如 AlphaFold、科学和数学领域的科学发现。同时我们也需要确保这些系统是可理解的和可控的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为了得到经过更为严格评估的系统，人们提出了很多想法。但我们目前还没有足够好的评估方法和基准可以确定系统是否欺骗了你、系统是否会泄漏自己的代码等不良行为。还有些人提出可以使用 AI 来辅助分析，就是使用应用范围窄的 AI（narrow AI）。它们不具备通用学习能力，而是专门为某个特定领域专门设计的；它们可以帮助人类科学家分析更通用的系统的行为。我认为一个有很大潜力的方向是创造强化型沙盒或模拟环境——它们的网络安全经过增强，可以把 AI 困在其中，也能保证外部攻击者无法进入。这样一来，我们就可以在这个沙盒中自由地做实验了。另外也有些人在研究让人类能够理解这些系统构建的概念和表征。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">时间线和智能爆炸</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您认为 AGI 会在什么时候出现？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我没有具体的时间预测，因为我感觉还有很多未知和不确定，而且人类的聪明才智和努力总是会带来惊喜。这些都可能导致时间线变化。但我要说，在我们 2010 年创立 DeepMind 时，我们认为这个项目需要 20 年时间。实际上，我觉得我们正按预期向目标靠近。这很了不起，因为通常的 20 年计划总是还要另外 20 年。如果我们在未来十年内拥有类似 AGI 的系统，我不会感到惊讶。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：如果有了 AGI，您会使用吗？您可以将其用来进一步加速 AI 研究。</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这是有可能的。这要看我们做出什么决定。我们需要作为一个社会来决定如何使用第一个新生的 AGI 系统或甚至 AGI 原型系统。即便是我们现有的系统，我们也需要考虑其安全方面的影响。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">Gemini 的训练</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：目前 Gemini 的开发遇到了什么瓶颈？既然规模扩展法效果很好，为什么不直接把它增大一个数量级？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：首先，有实践方面的限制。一个数据中心究竟能有多少算力呢？实际上，这会遇到非常有趣的分布式计算难题。幸运的是，我们有最好的研究者在研究这些难题以及如何实现跨数据中心训练等等。还有硬件方面的难题，我们有自己构建和设计的 TPU 等硬件，也会使用 GPU。至于规模扩展的效果，也不是总如魔法般有效。扩大规模时也还需要扩展超参数，每一种规模都需要各种不同的创新。不是每一种规模都能重复一样的配方。我们必须调整配方，而且这在某种程度上就像是搞艺术。另外还需要获得新的数据点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：在 Gemini 的开发过程中，您觉得最出人意料的是什么？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我得说没什么非常出人意料，但是能在那种规模上进行训练并从一种组织化的角度去研究它，是非常有趣的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：很多人认为其它实验室的模型的计算效率可能比 DeepMind 的 Gemini 高。您怎么看？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为情况并非如此。实际上，Gemini 使用的算力差不多，也许就比传闻中 GPT-4 使用的算力稍多一点。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;color: rgb(61, 170, 214);">Dwarkesh Patel：对于 2010 年刚创立 DeepMind 的您来说，现在的 AI 进展中哪一点最让您感到意外？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：你也采访过我的同事 Shane。他总是从计算曲线方面进行思考，也常常将 AI 与大脑进行比较——有多少神经元或突触。但现在我们已经差不多到大脑中神经突触数量的数量级和那样的计算量了。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但我认为，更根本的问题在于，我们关注的重心始终是通用性和学习。这始终是我们使用任何技术的核心。因此我们把强化学习、搜索和深度学习看作是三种可以扩展并且可以非常通用的算法，无需大量人工设计的人类先验知识。这不同于 MIT 等在当时构建的 AI——它们是基于逻辑的专家系统，需要大量人工编码。事实证明这种做法是错误的。我们在早期看出了发展趋势。我们使用游戏作为验证平台，发现结果还不错。最后也取得了巨大的成功。AlphaGo 等成功给其他许多人带去了启发。当然，还有我们谷歌研究院和谷歌大脑的同事发明的 Transformer，这种深度学习方法让模型可以处理海量数据。这些技术就是如今成果的基础。这些都是一以贯之的传承。我们当然不可能预测出每一次技术转变，但我认为我们前进的总体方向是正确的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">治理超人类 AI</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您怎么看待超人类智能的前景？它仍然受私有企业控制吗？具体应该如何治理它？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我认为这种技术将会带来重大影响。大于任何一家公司，甚至大于任何一个行业。我认为这必需来自民间社会、学术界、政府的许多利益相关者的大规模合作。好消息是，随着近期聊天机器人等技术的广泛使用，社会中其它一些部分被唤醒了，他们开始认识到这种系统正在到来并且他们也将与这些系统互动。这很不错。这为良好的对话打开了很多大门。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">其中一个例子是几个月前在英国举办的 AI Safety Summit。我认为这是一次巨大成功。我们需要进行国际间的对话，要让整个社会一起来决定我们要使用这些模型做什么、我们希望怎样使用它们、我们希望它们不被用于什么目的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：现在的 AI 系统已经非常强大，为什么它们的影响没有更大呢？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这说明我们依然还处在这个新时代的起点。目前的这些系统已经有一些有趣的用例，比如使用聊天机器人系统来为你做总结、完成一些简单的写作任务、进行样板式写作；但这些只是我们日常生活的一小部分。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我认为，对于更一般化的用例，我们仍然需要新的能力，比如规划和搜索，另外还需要个性化、记忆、情境记忆等。因此长上下文窗口是不够的，还要记住 100 轮对话之前我们说了什么。一旦这些技术成熟了，我们就会看到新的用例，比如能帮助我们找到更好更丰富材料（书、电影、音乐等）的新推荐系统。那样我就会每天使用这类系统。我认为我们目前只是触及了这些 AI 助理的表面，其实未来它们能为我们的一般日常生活和工作做更多事情。另外用它们做科研也不足够可靠。但我相信未来当我们决定了事实性和定基等问题之后，这些 AI 系统就能变成世界上最好的研究助理。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：说到记忆，您在 2007 年有一篇论文谈到记忆和想象（imagination）有某种程度的相似之处。现在也有人说目前的 AI 就只是记住了些东西。您对此怎么看？只靠记忆就足够了吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：在有限的情况下，也许记住一切就够了，但这样无法泛化到原有的分布之外。但很明显 Gemini 和 GPT-4 等模型确实能够泛化到新的情况。至于我的那篇论文，我实际上表达的是：记忆（至少是人类记忆）是一种重建的过程。记忆不是磁带式的精确记录。我们的大脑是把看起来熟悉的东西组合到一起。这让我思考想象可能也是这么回事。只不过这时候我们组合的是语义组件（semantic component）——你的大脑将它们组合起来并且认为结果是全新的。我认为我们目前的系统依然缺少这种能力——即把世界模型的不同部分拿出来组合到一起来模拟新东西，从而帮助用来执行规划。这就是我所说的想象。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">安全、开源和权重安全</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：你们有计划和其它两家主要的 AI 实验室一样从某种程度上放出 Gemini 的框架吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我们内部已经做了大量的检查和平衡，我们也会开始发布一些东西。未来几个月，我们有很多博客文章和技术论文发出来。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：如何保护模型的权重，使其不被恶意盗用？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：这涉及到两个方面。一是安全，二是开源。安全非常关键，尤其是网络安全。我们 Google DeepMind 非常幸运。因为我们在谷歌的防火墙和云的保护之下，这可以说是世界上最好的安全防护。除此之外，我们 DeepMind 还有特定的措施来保护我们的代码库。所以我们有双重保护。而且我们还在不断提升和改进，比如使用强化沙盒。我们也在考虑特定的安全数据中心或硬件解决方案。所有的前沿实验室都应该这么做。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">开源也很重要。我们是开源和开放科学的大力支持者。我们已经发布了数千篇论文，包括 AlphaFold、Transformer 和 AlphaGo。但对于核心的基础技术，我们会考虑如何阻止恶意组织、个人或流氓国家，防止他们使用这些开源系统去实现他们的有害目的。这是我们必须回答的问题。我不知道这个问题的答案，但我也没能从支持开源一切的人那里听到让人信服的答案。我认为这其中必须要有些平衡。但很显然这是个很复杂的问题。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：在安全方面，其它一些实验室有自己的专攻领域，比如 Anthropic 在研究可解释性。现在你们有了最前沿的模型，你们也会在安全方面做前沿研究吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们已经开创了 RLHF 等技术，这不仅能用于提升性能，也能用于安全。我认为很多自我博弈想法也有潜力用于自动测试新系统的边界条件。部分问题在于，对于这些非常通用的系统，它们的适用范围非常广。我认为我们将需要一些自动测试技术以及之前提到的模拟和游戏、非常拟真的虚拟环境。在这方面我们有很长的研究历史。另外，很幸运谷歌有大量网络安全专家和硬件设计师。这也是我们可以获得的安全保障。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">多模态和进一步的进展</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：对于 Gemini 这样的系统，目前与它们默认的交互方式是通过聊天。随着多模态和新能力的加入，这种情况会如何改变？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：在理解完整的多模态系统方面，我们还处于起步阶段。与其的交互方式将与我们现在的聊天机器人大不相同。我想明年的下一代版本可能会具有一定的环境理解能力，比如通过相机或手机。然后我可以想象下一步。模型在理解方面会变得越来越顺畅。我们可以使用视频、声音甚至触碰。如果再考虑到使用传感器的机器人，世界将会开始变得激动人心。我想未来几年，我们就能看到多模态对机器人学科意味着什么。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：Ilya 曾在播客上跟我说过 OpenAI 放弃研究机器人的原因：在该领域的数据不够，至少在那时候是如此。您认为这对机器人的发展而言依然还是一个瓶颈吗？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我们的 Gato 和 RT-2 Transformer 取得了激动人心的进展。我们一直以来都很喜欢机器人。我们在这一领域也有出色的研究成果。我们仍然在进行机器人研究，因为我们其实喜欢这一事实：这是一个数据稀少的领域。我们认为这会是一个非常有用的研究方向，其中涉及到的课题包括采样效率和数据效率、从模拟环境迁移到现实的迁移学习。我们一直在努力研究。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">实际上 Ilya 说得对，机器人很有挑战性就是因为数据问题。但我想我们会开始看到大模型可以迁移到机器人领域、在非常普适的领域学习，并且可以将 Gato 这样的 token 当作是任意类型的 token 进行处理。这些 token 可以是动作，也可以是词、图块、像素等等。我心中的多模态就是这样。但一开始，训练这样的系统比简单直接的文本语言系统更困难。我们之前聊迁移学习时也谈到了，对于一个真正的多模态系统，一个模态是可以从其它模态获益的。比如如果模型更加理解视频，其语言能力也会有所提升。我们最后会有一个这样的更加通用、更有能力的系统。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：DeepMind 发表了许多有趣的研究成果来加速不同领域的科学研究。为什么要构建这样的特定领域的方案呢？为什么不等到一二十年后让 AGI 来做？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：我想我们并不知道 AGI 将在何时到来。而且我们过去也常常说，我们不必等到 AGI，也能做出些出色的成果来造福这个世界。我个人也对 AI 在科学和医疗领域的应用充满热情。而且你可以看到我们的多篇 Nature 论文关注了多个不同的领域。有很多激动人心的研究方向能影响这个世界。作为拥有数十亿用户的谷歌的一分子，我们很荣幸有这样的巨大机会，可以将我们取得的进步快速提供给数十亿人，帮助改善、丰富和助力他们的日常生活。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从 AGI 的角度看，我们也需要检验我们的想法。我们不能指望闭门造 AI 就能推动发展，因为这样只会让内部指标偏离人们真正会关心的真实事物。真实世界应用能提供大量直接的反馈，可以让我们知道系统是否在进步或者我们是不是需要提高数据或样本效率。因为大多数真实世界难题都需要这样。这能不断推动和引导你的研究方向，以确保它们走在正确的道路上。当然，另一方面是，即便是在 AGI 诞生之前很多年，世界也能从中获益。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">Google DeepMind 内部</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：Gemini 的开发工作涉及到谷歌大脑和 DeepMind 等不同机构的合作。这其中遇到了哪些挑战？产生了哪些协同效应？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：过去的一年是很棒的一年。当然，挑战是有的，和任何大型整合工作一样。但我们是两个世界级的组织，各自都发明了许多重要技术，从深度强化学习到 Transformer。因此，我们的很多工作就是将这些汇集起来，实现更加紧密的合作。其实我们过去常常合作，只不过之前是针对具体项目的合作，现在则是更加深度和广泛的合作。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Gemini 是这一合作的首个成果，其实 Gemini 这个名字就暗含了孪生兄弟姐妹的意思。当然，也有很多事情的效率更高了，像是把计算资源、想法和工程开发工作汇集到一起。我们目前就处于这个阶段，基于世界级的工程开发来构建前沿系统。我认为进一步的合作是有意义的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：您和 Shane 创立 DeepMind 的部分原因是你们担忧 AI 的安全问题。您认为 AGI 的到来有现实的可能性。您感觉来自谷歌大脑的研究者也有类似看法吗？这个问题方面是否存在文化差异？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：没有。总体而言，这就是我们在 2014 年与谷歌携手的原因之一。我认为，谷歌和 Alphabet 整体（不只是谷歌大脑和 DeepMind）都以负责任的态度认真对待这些问题。差不多我们的座右铭就是大胆尝试这些系统，同时要负起责任。我显然是一个技术乐观主义者，但我希望我们对技术保持谨慎，毕竟我们共同为这个世界带来的东西具有变革性的力量。我认为这很重要。我认为这将成为人类发明的最重要的技术。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(61, 170, 214);"><strong><span style="font-size: 15px;">Dwarkesh Patel：最后一个问题。2010 年时，当其他人还觉得 AGI 很荒谬时，您就在思考这个终极目标了。现在随着这类技术的慢慢起飞，您是怎么想的呢？您是否已经在您的世界模型中预想到过？</span></strong></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Demis Hassabis：是的，我确实已经在我的世界模型中预想到过这些，至少是从技术角度。但很显然，我们不一定预料到了公众会在如此早期阶段参与进来。像是 ChatGPT 等一些应用在某些方面还有所欠缺，但人们已经有浓烈的兴趣去使用它们了。这一点挺让人意外的。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">另外还有更加专业化的系统，比如 AlphaFold 和 AlphaGo 以及一些科学方面的成果，但它们在公众关注的主线发展之外，也许几年后公众会关注到它们，那时候我们可能就有了更加普遍适用的助理类型的系统。这会创造出一个和现在不一样的环境。而且情况可能看起来会更混乱，因为会有很多事情发生，也会有很多风险投资，好像所有人都失去理智一样。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我唯一担忧的是我们能否负责任地、深思熟虑地、科学地对待这种情况，使用科学方法来应对。也就是我说的乐观但谨慎的方式。我一直都相信这是我们应对 AI 这类事物的方式。我希望我们不会迷失在这场快速袭来的巨大热潮中。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">&nbsp;</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考链接：</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.dwarkeshpatel.com/p/demis-hassabis</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://twitter.com/dwarkesh_sp/status/1762872471479529522</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425614" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[马斯克起诉OpenAI：他们做出了AGI还授权给微软，这是对创始协议赤裸裸的背叛]]></title>
        <id>2650909259_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909259&amp;idx=1&amp;sn=bfda3ce888d99208aa7cc6aa33844889&amp;chksm=84e46e35b393e723e624968bfc2e1e728ce738c5429e0b24cd6aa580b9fc45d5ad0379763b3b#rd"/>
        <updated>2024-03-02T02:23:10.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="38" data-source-title="" style="outline: 0px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 0.578px;visibility: visible;"><div class="js_blockquote_digest" style="outline: 0px;visibility: visible;"><p style="outline: 0px;visibility: visible;"><span style="outline: 0px;letter-spacing: 0.578px;visibility: visible;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">AGI 做出来了吗？</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">创始协议在哪儿？</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">马斯克起诉 OpenAI 的诉讼文件疑点满满。</span></span></p></div></blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="letter-spacing: 0.034em;font-size: 15px;"></span><span style="font-size: 15px;letter-spacing: 0.034em;">在刚刚过去的一天，「沉湎于戏剧性冲突」的马斯克又做了一件新鲜事：</span><span style="font-size: 15px;letter-spacing: 0.034em;">他起诉了自己参与创立的 OpenAI。</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425587" data-ratio="0.615909090909091" data-type="png" data-w="880" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8aqicvLCbzniasMYPTzWDlLCwPdiaLxyuOt4gLDS8VMQrYYSSd454276tQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在诉讼文件中，他指控 OpenAI 不计后果地开发人类级别的人工智能，并将其移交给微软。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克的诉讼针对的是 OpenAI 及其两名高管 —— 首席执行官 Sam Altman 和总裁 Greg Brockman，他们两人与马斯克合作，于 2015 年创立了这家公司。诉讼称，这两人违反了与马斯克最初达成的「创始协议」，该协议承诺公司将公开开发 AGI（通用人工智能），「造福人类」。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425588" data-ratio="0.7342592592592593" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l85FDR9X2oqibjBYdnhU5o8lr2TvUVC6S40xIrVUjYlpO00EicKhALKCjA/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">诉讼文件：https://www.courthousenews.com/wp-content/uploads/2024/02/musk-v-altman-openai-complaint-sf.pdf</span><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克在诉讼中称，该公司的营利性部门是在他与 OpenAI 分道扬镳后于 2019 年成立的，它在没有适当透明度的情况下创建了 AGI，并将其授权给微软，而微软向该公司投资了数十亿美元。诉讼补充道。「这是对创始协议赤裸裸的背叛。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425589" data-ratio="0.6546296296296297" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8w29CsiaqXCQdkkNhyLCE6lps3Z5zsU6sib9wibibl0LR14C3cczILa8Wgw/640?wx_fmt=png&amp;from=appmsg"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼援引微软 CEO Satya Nadella 最近的一次采访，指控微软与 OpenAI 关系密切。针对去年 OpenAI 发生的「宫斗」事件，Nadella 表示，如果「OpenAI 明天就消失了...... 我们拥有所有的知识产权和能力。我们有人，我们有计算，我们有数据，我们拥有一切。We are below them, above them, around them」。该诉讼将此作为 OpenAI 为微软利益服务的有力证据。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于此，该诉讼要求强迫 OpenAI 公开发布其技术，并禁止 OpenAI 利用该技术为微软、Altman 或 Brockman 谋取经济利益。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该诉讼还要求法院裁定，GPT-4 等人工智能系统和其他正在开发的先进模型构成通用人工智能，超越了微软与 OpenAI 许可协议的范围。除了强制 OpenAI 执行禁令之外，马斯克还要求法院在发现 OpenAI 现在是为了私人利益而运营时，对其用于资助公益研究的捐款进行核算和可能的归还。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">根据法律诉状，马斯克在 2016 年至 2020 年 9 月期间向 OpenAI 捐赠了超过 4400 万美元。诉讼补充道，在最初几年，他是 OpenAI 最大的捐款人。马斯克在 2018 年离开了 OpenAI 的董事会，他早些时候表示，有人向他提供了这家初创公司营利部门的股份，但他出于原则立场拒绝接受。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">不过，马斯克想打赢这场官司可能没有那么容易，因为他所给出的诉讼文件涉及一些尚未理清的事实，比如 OpenAI 真的开发出 AGI 了吗？所谓的「创始协议」到底是否存在？这些问题给诉讼带来了不小的难度。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>OpenAI 开发出 AGI 了吗？</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此案的很大一部分内容都围绕着一个大胆而又令人质疑的技术主张：OpenAI 开发出了所谓的通用人工智能。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼称，「依据所了解的信息和据此形成的推断（on information and belief），GPT-4 是一种 AGI 算法」。诉讼文件引用了一些研究，发现 GPT-4 可以在律师资格统一考试和其他标准测试中获得及格分数，以此证明它已经超越了人类的某些基本能力。「GPT-4 不仅具有推理能力，而且比普通人更善于推理，」该诉讼称。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">微软去年 4 月发布的论文 ——「Sparks of Artificial General Intelligence: Early experiments with GPT-4」就在被引用的研究之列。在这篇论文，微软提出了一个断言 ——「鉴于 GPT-4 能力的广度和深度，我们相信它应该被合理视作一个通用人工智能（AGI）系统的早期（但仍不完整）版本。」如今，这句话被马斯克作为证据写进了诉讼文件。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425590" data-ratio="0.862037037037037" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8xpnj24V0t2TCnAT0U5pOeqRNubkp3elx0cdm6x6e1w5iaudoh19EZ4Q/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">同样被列为证据的还有传闻中提到的 OpenAI 神秘模型 ——Q*（Q star），诉讼文件称，该模型更接近 AGI。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此外，文件还提到，微软只对 OpenAI 某些达到 AGI 之前的技术拥有权利。不过，就微软的许可而言，OpenAI 是否达到 AGI 由 OpenAI 公司的董事会决定，而 OpenAI 现在的董事会没有能力判断 OpenAI 开发的算法是否达到了 AGI。</span></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="190" data-source-title=""><div class="js_blockquote_digest"><div><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">2023 年 11 月 17 日，OpenAI 公司董事会解雇了 Altman 先生，因为『他没有始终如一地对董事会坦诚相待』，董事会对他继续领导 OpenAI 的能力失去了信心。在接下来几天的一系列令人震惊的事态发展中，Altman 先生和 Brockman 先生与微软联手，利用微软对 OpenAI 公司的巨大影响力，迫使 OpenAI 公司董事会大多数成员辞职，其中包括首席科学家 Ilya Sutskever。</span></p></div></div></blockquote><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="128" data-source-title=""><div class="js_blockquote_digest"><p>据了解，新的董事会成员是由 Altman 先生亲自挑选的，并得到了微软的支持。新的董事会成员缺乏大量的人工智能专业知识，据了解，他们没有能力独立判断 OpenAI 是否以及何时达到了 AGI，也就无法判断 OpenAI 开发的算法是否超出了微软的许可范围。</p></div></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对于诉讼中提到的这些信息和推论，人工智能领域的很多专家都表示没有办法认可。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">华盛顿大学名誉教授、人工智能专家 Oren Etzioni 说：「GPT-4 是通用的，但它显然不是人们通常所指的 AGI」。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">斯坦福大学专门研究人工智能和语言的教授 Christopher Manning 在谈到马斯克诉讼中的 AGI 断言时说：「这将被视为一种夸大的说法」。Manning 说，人工智能界对什么是 AGI 存在不同看法。一些专家可能会降低标准，认为 GPT-4 能够执行多种功能，因此有理由将其称为 AGI，而另一些专家则倾向于将这一术语保留给能够在任何事情上胜过大多数或所有人类的算法。他说：「根据这个定义，我认为我们显然还没有 AGI，而且离它还很远。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">加州大学伯克利分校教授 Michael Jordan 说：「我感觉我们中的大多数研究人员都认为，大型语言模型（如 GPT-4）是一个非常重要的工具，可以让人类做更多的事情，但它们的局限性使得它们远非独立的智能体。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Jordan 倾向于完全避免使用 AGI 这个词，因为它太模糊了。他说：「我从未发现马斯克有任何关于人工智能的言论是经过校准或基于研究现实的。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">马斯克的诉讼面临的另一个困难是，OpenAI 长期以来一直使用自己对 AGI 的定义，将其描述为「在大多数有经济价值的工作中胜过人类的高度自主系统」。如今看来，GPT-4 与这一标准相去甚远。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">有趣的是，就连马斯克自己提出的 AGI 定义都能将 GPT-4 移出 AGI 之列。2022 年 12 月，在他宣布 OpenAI 新推出的 ChatGPT「好得吓人」之后不久，这位企业家提出，算法需要「发明惊人的东西或发现更深层次的物理学」，才能配得上这一称号。马斯克写道：「我还没有看到这种潜力。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425591" data-ratio="0.7731481481481481" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8pbADuQmOFIDJfn4rEOSKlCDsvaXpweUh2Czibkndg0e5ic05xPUsQic2g/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">斯坦福大学法学院教授 Mark Lemley 对 AGI 的主张和该诉讼更广泛的法律依据表示怀疑。虽然 OpenAI 看起来确实不那么开放了，而且变得更加以利润为中心，但这给马斯克带来了什么权利还远不清楚。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Lemley 说：「值得注意的是，诉状中并没有包含马斯克与该公司之间的任何合同，也没有包含他执行这些原则或拿回钱的任何权利的文本。」如果存在这些文件，我希望它们能在诉状中占据显著位置。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>「创始协议」在哪里？</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">另一项颇具争议的内容是马斯克在诉状里提到的「创始协议」，而这份协议并没有出现在证据附件里。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">The Verge 网站主编 Nilay Patel 认为，马斯克是在指控 OpenAI 违反了一份并不存在的合同。而且违约索赔中也承认，「创始协议」基本上就是大家在一些电子邮件中捕捉到的蛛丝马迹。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">诉讼文件中写道，「OpenAI, Inc. 的创始公司章程以及原告与被告之间多年来的多次书面沟通等文件中均有关于该创始协议的记载（memorialize）。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Nilay Patel 认为，马斯克的律师故意用了「memorialize」一词来替代「written down」，这是因为难懂的内容更容易赚律师费。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">接着，它又引用了「公司章程」，但这不是合同，马斯克也没有签署，只是简单地写了以下内容：</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="86" data-source-title=""><div class="js_blockquote_digest"><p>该公司的具体目的是为人工智能相关技术的研究、开发和传播提供资金。由此产生的技术将造福于公众，公司将在适用的情况下寻求开源技术，以造福于公众。本公司的成立不为任何人谋取私利。</p></div></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这里没有任何协议 —— 也许 OpenAI 复杂的公司结构（包括非营利性公司拥有营利性公司）确实颠覆了这份文件中阐述的理想，但马斯克不能因此起诉，因为这不是一份合同。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">违约索赔还提到了 Sam Altman 写给 Elon Musk 的一封电子邮件，其中提到 OpenAI 开发的技术将用于「造福世界」，马斯克回复说：「完全同意。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503425592" data-ratio="1.1522222222222223" data-type="png" data-w="900" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicfHjnTsriaWBKNDqwB8f7l8PYgvztIfduAQ0AM0icBSGiaDYC15jo8sozDM4f1NFHyicV6bvicEXjk9sA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Nilay Patel 表示，他问了几个律师朋友这些看起来像不像合同，他们大多一脸茫然。这与马斯克对合同运作方式越来越模糊的理解如出一辙。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">综合来看，Nilay Patel 认为，马斯克对 OpenAI 的批评是有道理的，但他请的律师让人感觉一言难尽。「他的律师们已经发现，让这位世界首富在无厘头的诉讼中耗费大量的计费时间，比让『事实』符合『法律』或其他普通律师所做的事情更有利可图。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">自 OpenAI 走向闭源以来，马斯克一直在各个平台上抨击这家公司，并表示自己担心 AGI 可能逃离人类控制，采取危害地球的行动。Altman 过去也曾谈到马斯克的一些担忧，他评价马斯克说，「我喜欢这家伙。我认为他完全错了，」「他可以说任何他想说的话，但我为我们正在做的事情感到自豪，我认为我们将为世界做出积极贡献，我试图超越这一切。」</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考链接：</span></em></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.wired.com/story/wild-claim-at-the-heart-of-elon-musks-openai-lawsuit/</span></em></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://www.theverge.com/2024/3/1/24087937/elon-musk-suing-openai-nightmare-1l-contracts-exam</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425604" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="margin-bottom: 0px;"><br></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[“国家队”入局，多模态大模型企业联汇科技宣布完成新一轮数亿元战略融资]]></title>
        <id>2650909083_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650909083&amp;idx=1&amp;sn=56b3946f9d97404f5181fab8694f2438&amp;chksm=84e46de5b393e4f3ffcd16b79bd937a36d02272e39332f5bed48cb5b06725e5e16371a1d3c72#rd"/>
        <updated>2024-03-01T03:54:36.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心发布<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;color: rgb(9, 67, 162);">近日，杭州联汇科技股份有限公司（以下简称 “联汇科技”）宣布完成新一轮数亿元战略融资，投资方由中国移动产业链发展基金中移和创投资、前海方舟（前海母基金管理机构）旗下中原前海基金和齐鲁前海基金等多家头部国资与市场化机构组成。领投方中国移动产业链发展基金中移和创投资是贯彻落实中央企业现代产业链链长工作要求，由中国移动与北京市政府、上海市政府发起成立，服务于数字经济、移动信息现代产业链发展、战略新兴产业等国家战略。</span></strong></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">据悉，本轮融资将主要用于多模态大模型及自主智能体的技术研发、产品创新及市场拓展，扩大其在运营商、能源电力、媒体等国家基础行业与重点细分市场的领先优势。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425390" data-ratio="0.6675925925925926" data-type="jpeg" data-w="1080" style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsE8UeiaWJZsA7IoIrE9HiaX3FNJyXgwia9HQk3ibpCNjg4f43bApKN55y2gQ/640?wx_fmt=jpeg&amp;from=appmsg"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">历经千模大战，为何唯有联汇科技能赢得 “国家队” 青睐？这家坐落在杭州钱塘江畔的 AI 大模型准独角兽企业有哪些过人之处？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong><span style="color: rgb(61, 170, 214);">潮起之江・与 OpenAI 同出一门的黑马技术团队</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">脱颖而出，不是偶然，更非一日之功。2019 年，看准智能化大潮拍岸的联汇科技乘势而上，开启了在多模态大模型、向量数据库等技术领域的研究与沉淀，成为了<strong><span style="color: rgb(9, 67, 162);">国内最早自主研发大规模预训练算法模型的公司之一</span></strong>。放眼全球组建核心技术团队，吸引了卡耐基梅隆大学、微软研究院、加州大学、纽约大学等全球顶尖高校与机构的博士、博士后等技术大牛加盟，以极强的技术研发实力成为全球预训练大模型研究的一颗闪亮明星，连续多年在 ACL、ECCV、CVPR、AAAI 等人工智能国际顶会中取得各项竞赛单元的多个冠军。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">一个优秀的公司，背后必定有一个优秀的理念和团队。联汇科技 CEO 兼首席科学家赵天成博士，博士毕业于卡耐基梅隆大学（CMU）计算机系语言技术所（LTI），仅用 4 年半时间拿下了 CMU 六年起步的博士学位，早在 2017 年就提出了学术界最早的生成式对话模型，深耕多模态机器学习与人机交互技术领域的理论与技术研究，主持多项国家、省、市重大科研项目，带领团队在攻克非结构化数据直接使用、跨模态数据融合分析等行业难题上率先取得突破，是国际多模态交互 AI 领域的领军人物。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在谈及多模态大模型技术的价值时，他说：<strong><span style="color: rgb(9, 67, 162);">“在回国之前，我们很早就已经认识到用小模型的方式去服务中长尾场景，投入产出根本不合理，从而更加坚定了走大模型技术方向的决心，我们要做的事情不是 follow 谁，而是 lead 新的技术革新。”</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503425391" data-ratio="0.7416666666666667" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6Qb8AKzFIBxiabY5C0v1d98nQvqr99FvMAZicnIaA8icQFf2NLlN6V86X2w/640?wx_fmt=png&amp;from=appmsg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><span style="font-size: 15px;"><em style="outline: 0px;color: rgb(136, 136, 136);font-family: system-ui, -apple-system, &quot;system-ui&quot;, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);"><span style="outline: 0px;font-size: 12px;">联汇科技 CEO 兼首席科学家赵天成</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>何以联汇・聚焦多模态大模型</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>率先实现规模化商用</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">眼耳鼻舌身意，色声香味触法，人类用不同的感官来感知物理世界的美妙。相较于单一模态，赵天成博士团队认为多模态大模型在应用上的价值优势更加显著，融合处理文本、图像等跨模态数据，可以使得大模型在复杂情境理解和多样化内容生成方面的表现更为出色，在多模态协作生成、跨领域检索等实际应用场景中的适应性更强。不同模态的数据组成更广泛、多元的数据集，反向促进预训练效率提升，更有助于增强模型泛化能力和整体性能。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;color: rgb(9, 67, 162);">自 2020 年起，联汇科技陆续推出多个版本的自研多模态大模型</span></strong><span style="font-size: 15px;">，其中 1.0 版本是业界最早的视觉语言大模型，具备视频、图片、文本等跨模态数据的融合分析、认知理解能力；2.0 版本一路过关斩将，不负众望成为全国第一个高分通过工信部信通院评测认证的预训练大模型；3.0 版本<strong><span style="color: rgb(9, 67, 162);">在开放识别、视觉问答、认知推理和高效微调四大核心能力实现质变飞跃</span></strong>，同期发布了 OmBot 大模型驱动的自主智能体与视频小欧、文档小欧和创作小欧等首批典型场景应用，为不同行业提供定制化的智能助手。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在产品研发和市场服务方面，客户覆盖中国移动、中国电信、全国人大、国家电网、央广总台等头部企业，通过提供以多模态大模型为核心的产品与服务，赋能各行各业智能化转型，助力国家 AI 普惠加速实现。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在核心技术创新方面，联汇科技发表多篇国际顶会论文，发明专利丰硕，坚持 “以用促研、研用结合”，结合行业用户服务经验获中国电力科学技术进步奖、中国电力科技创新奖、中国广播电视科技进步奖、国家科技部颠覆性科技成果创新等科技奖项。入选 IDC 等国际咨询机构 “中国多模态 AI 大模型领域代表厂商”、“全球向量数据库代表企业”、“2023 年度最佳大模型” 等。一路艰辛跋涉、一路鲜花掌声，如今的联汇科技以不俗的业绩表现成长为人工智能领军企业、中国 AI 基础大模型创新企业。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>联动未来・携手 “国家队”</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>锚定大 B 赛道服务科技强国战略</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">加快推动人工智能发展、培育新质生产力，不仅是国家高质量发展的必然要求，也是联汇科技矢志不渝的追求。对于多模态大模型技术服务的市场坐标，赵天成博士的目标非常清晰：“<strong><span style="font-size: 15px;color: rgb(9, 67, 162);">我们希望 AI 技术是能够真正服务国家、社会，创造出真正的价值，这是我们团队中的很多人结束留洋、归国扎根的初心和目标。</span></strong>我们的客户有很多是服务国家战略的央企、国企和头部企业，他们代表着国家经济发展的大方向。帮助不同行业的企业与客户降本增效，带去看得见、摸得着的收益，是我们专注大模型技术商业落地的动力所在。”</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">本次中国移动产业链发展基金中移和创投资领投联汇科技，双方携手共同推进行业级人工智能技术发展、支撑壮大 “战新” 产业，主动把握 “AI+” 时代潮流。中移和创投资表示：“联汇科技在视觉领域具备海量高质量图文对和独有数据积累，在行业级多模态大模型和自主智能体技术的研究和创新方面取得了令人瞩目的成绩单，多领域快速实现了商业化落地，相信未来联汇科技持续攻坚多模态大模型技术在视觉领域的应用，赋能千行百业加速提质增效。”</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">联汇科技与 “国家队” 的强强联合，将推动自身从智能平台服务向提供全套解决方案服务的大模型产业生态转型，降低多模态大模型技术的落地赋能的技术门槛与成本，进一步加速产业焕新、夯实基础底座、加快重点行业赋能，与千行百业一道迎接 AI 技术红利真正爆发。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong><span style="font-size: 16px;color: rgb(61, 170, 214);">同风起 共潮生・欢迎志同道合之士加入！</span></strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">联汇科技本轮融资主要用于扩充人才队伍、组织架构升级，更好的提供多模态大模型相关的产品与服务，推动更多的行业规模化应用。欢迎有识之士选择联汇、加入联汇，一起携手共创、加快 AI 普惠，让所有人都能享受到一流的大模型应用服务，让美好发生。招聘通道持续开放中！</span></p><p style="text-align: center;margin-bottom: 24px;"><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;margin-bottom: 0px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;outline: 0px;max-width: 100%;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;white-space: normal;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;margin-bottom: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;box-sizing: border-box !important;overflow-wrap: break-word !important;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于神经网络的偏微分方程求解器新突破：北大&字节研究成果入选Nature子刊]]></title>
        <id>2650908962_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908962&amp;idx=1&amp;sn=a3d84a59bf5cbfb0ddaf1b4fd6f40213&amp;chksm=84e46d5cb393e44a158cef28845bcba5f26f746c912779e4caab7864cbf1d82dfb45631cc590#rd"/>
        <updated>2024-02-29T03:50:08.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心发布</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span><span style="letter-spacing: 0.578px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: 15px;text-align: justify;"></span></p></div></div></div></div></div><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">近年来，基于神经网络的偏微分方程求解器在各领域均得到了广泛关注。其中，量子变分蒙特卡洛方法（NNVMC）在量子化学领域异军突起，对于一系列问题的解决展现出超越传统方法的精确度 [1, 2, 3, 4]。北京大学与字节跳动研究部门 ByteDance Research 联合开发的计算框架 Forward Laplacian 创新地利用 Laplace 算子前向传播计算，为 NNVMC 领域提供了十倍的加速，从而大幅降低计算成本，达成该领域多项 State of the Art，同时也助力该领域向更多的科学难题发起冲击。该工作以《A computational framework for neural network-based variational Monte Carlo with Forward Laplacian》为题的论文已发表于国际顶级期刊《Nature Machine Intelligence》，相关代码已开源。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425260" data-ratio="0.9300411522633745" data-s="300,640" data-type="png" data-w="729" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5KQnIibq2gV2dZOHFmev9O2QhYA7U8DdCS1uzaic46iaicOBdugfrUNNKdA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文链接：https://www.nature.com/articles/s42256-024-00794-x</span></p></li><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">代码地址：</span></p></li></ul><ul class="list-paddingleft-1" style="list-style-type: circle;"><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">https://github.com/bytedance/LapNet</span></p></li><li><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;color: rgb(123, 12, 0);">https://github.com/YWolfeee/lapjax</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;letter-spacing: 0.034em;">该项工作一提出即受到相关研究人员的密切关注，围绕该工作已有多个开源项目实现，编程框架 JAX 也计划将该项工作吸收其中。</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该项工作由北京大学智能学院王立威课题组、物理学院陈基课题组联合字节跳动研究部门 ByteDance Research 一同开发完成，作者中有多位北京大学博士生在 ByteDance Research 实习。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>背景简介</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于神经网络的量子变分蒙特卡洛方法（NNVMC）已成为量子化学 - 从头计算领域中一项前沿技术。它具备精度高、适用范围广等优点。但它的阿克琉斯之踵在于过高的计算成本，这也限制了该方法在实际化学问题中的应用。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">作者提出了一套全新的计算框架 "Forward Laplacian"，利用 Laplace 算子的前向传播，显著提升了 NNVMC 方法的计算效率，为人工智能在微观量子问题中的应用打开了新的大门。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>方法介绍</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">Forward Laplacian 框架</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在 NNVMC 方法中，神经网络的目标函数是微观体系的能量，包括动能与势能两项。其中动能项涉及对神经网络的拉普拉斯算子的计算，这也是 NNVMC 中耗时最长的计算瓶颈。现有的自动微分框架在计算拉普拉斯算子时，需要先计算黑塞矩阵，再求得拉普拉斯项（即黑塞矩阵的迹）。而作者所提出的计算框架 "Forward Laplacian" 则通过一次前向传播直接求得拉普拉斯项，避免了黑塞矩阵的计算，从而削减了整体计算的规模，实现了显著加速。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425261" data-ratio="0.4675925925925926" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5ib4Dk6zZYzsopmDnjnsYqsArBPj5zSzfYxCzZXicEiaPcVZsqPxRzH7tw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">LapNet 网络</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">除了有效削减计算图规模之外，Forward Laplacian 框架的另一大特点是能有效利用神经网络梯度计算中的稀疏性，提出神经网络结构 LapNet。LapNet 通过增加神经网络中的稀疏性，在精度无损的同时，显著提升了网络计算的效率。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425262" data-ratio="0.6018518518518519" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W59qOzkOJbsibXYMNL3XZM3Ow0HicSc61ajsDyh5eYAVppZHC5Iaq35a3A/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>计算结果</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">绝对能量</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">作者首先就方法的效率及精度同当前 NNVMC 领域有代表性的几项工作进行了比较。从绝对能量的计算结果而言，作者提出的 LapNet 在 Forward Laplacian 框架下的效率高于参考工作数倍，精度上也与 SOTA 保持一致。此外，如果在相同计算资源（即相同 GPU hour）的情况下比较，LapNet 的计算结果可以显著优于之前的 SOTA。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425263" data-ratio="0.9972222222222222" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5y92D6oGiblKPDSKUV0PlM7iaxqqbsAltwEVTiaMSibPJXAaxveeFNa4hMg/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">加速标度</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">为了更明确地研究作者所提出方法相比于之前 SOTA 的加速标度，作者在不同大小的链式聚乙烯体系上进行了测试，结果可以很明显地看到 Forward Laplacian 工作带来的 O (n) 加速。此处 n 为目标分子中的电子数目。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425264" data-ratio="0.5583333333333333" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5PZLRU6AfveAtN4qyErucmicUjwP4fqpLr4pJDj4kicPibMpYJMjgx9jow/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">相对能量</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在物理、化学研究中，相对能量相较于绝对能量具有更明确的物理意义。作者也在一系列的体系上进行了测试，均取得了理想结果。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425265" data-ratio="1" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWico0cNn8CrFgfB6kA4Ll5W5J4ne2g6zxIe3zXibC1a7fliaYr4D6mYSa9YC45ibtvPicdkkaCUrvBUD9Q/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;"><strong>总结</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">为降低基于神经网络的量子变分蒙特卡洛方法（NNVMC）的使用门槛，北京大学与字节跳动研究部门 ByteDance Research 联合开发了计算框架 Forward Laplacian，实现了十倍的加速。该工作已受到相关研究人员的广泛关注，期望能够推动 NNVMC 方法在更多科学问题中发挥重要作用。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">参考文献</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[1] Han, J., Zhang, L., &amp; Weinan, E. (2019). Solving many-electron Schrödinger equation using deep neural networks. Journal of Computational Physics, 399, 108929.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[2] Hermann, J., Schätzle, Z., &amp; Noé, F. (2020). Deep-neural-network solution of the electronic Schrödinger equation. Nature Chemistry, 12 (10), 891-897.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[3] Pfau, D., Spencer, J. S., Matthews, A. G., &amp; Foulkes, W. M. C. (2020). Ab initio solution of the many-electron Schrödinger equation with deep neural networks. Physical Review Research, 2 (3), 033429.</span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 12px;color: rgb(136, 136, 136);">[4] Li, X., Li, Z., &amp; Chen, J. (2022). Ab initio calculation of real solids via neural network ansatz. Nature Communications, 13 (1), 7895.</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;caret-color: rgb(34, 34, 34);text-size-adjust: inherit;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[能看会说的人形机器人，对话的样子吓到我了]]></title>
        <id>2650908860_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908860&amp;idx=1&amp;sn=0ac695768808930827f1ed277654df70&amp;chksm=84e46cc2b393e5d48933bea59bdcbe5efaf9590bc8042a0a30f978b8d2cd31cdda48f5b02c9e#rd"/>
        <updated>2024-02-28T09:21:18.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><p style="margin-bottom: 0px;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">还记得这个表情宛如真人的人形机器人吗？</span></p><p style="margin-bottom: 0px;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425149" data-ratio="0.5625" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEuy0iajornSyKE4MLqaYOWVQkcsia6Iw3BKLtLlaicEWNjTKuDTX5TSNWA/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">ta被取名Ameca，由一家名为「Engineered Arts」的英国公司制造。最近，这个机器人又迎来了新的升级：&nbsp;&nbsp;</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p class="channels_iframe_wrp wxw_wechannel_card_not_horizontal"><mp-common-videosnap class="js_uneditable custom_select_card channels_iframe videosnap_video_iframe" data-pluginname="mpvideosnap" data-url="https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzGiaDia5pfLg7z8wGy668qkwibL18VC2UD9uzcuNdicuL9iavYiau5XWMQuEAYLyGBgsq8aTdFbEoup82qLn3xZY1pp8A&amp;bizid=1023&amp;dotrans=0&amp;hy=SH&amp;idx=1&amp;m=&amp;scene=0&amp;token=AxricY7RBHdUIpNuHuBpHMQUg0etqyNCD2X5HtjcFyoXuCaVBOjrmPj7TxHlbbOHyxdLDjZyHJWI" data-headimgurl="http://wx.qlogo.cn/finderhead/PiajxSqBRaEKs6XzYjCzlSsfrOck5ZdKLHuqicYEiaI62Ty9EQxZmibuCQ/0" data-username="v2_060000231003b20faec8c7e5811fcbd2cc05eb34b077bf43ae33648ee0ea039da9063a594944@finder" data-nickname="机器之心机动组" data-desc="能看会说的人形机器人，对话的样子吓到我了！模仿人类说话，观察描述世界！英国公司Engineered Arts宣布人形机器人「Ameca」拥有了视觉能力。#机器人#人形机器人#科技#前沿科技#AI#具身智能#人工智能" data-nonceid="5764530620137363735" data-type="video" data-mediatype="undefined" data-authiconurl="https://dldir1v6.qq.com/weixin/checkresupdate/icons_filled_channels_authentication_enterprise_a2658032368245639e666fb11533a600.png" data-from="new" data-width="1080" data-height="1920" data-id="export/UzFfAgtgekIEAQAAAAAAMXkHIt1TSQAAAAstQy6ubaLX4KHWvLEZgBPE5oJMFzxpc5-FzNPgMIstAxNl4XvKasvz3AKLRPr3" data-isdisabled="0" data-errortips=""></mp-common-videosnap></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">从视频中可以看到，现在Ameca不仅表情丰富，还拥有了观察周围环境并与人交流的能力，而且音色、语言风格都可以定制。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Ameca说话的能力是通过接入大型语言模型（早先是GPT-3）来实现的，所以交流起来和语音版ChatGPT体验非常接近。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">观察世界的能力则来自安装在眼睛、胸部等处的各个摄像头。这些摄像头可以识别人脸、物品和周围环境，并判断在谈话中谁在注意倾听或是在做眼神交流。有时 ，Ameca 也需要多试一次才能准确看到目标（比如，视频里看到第三个人体头部的解剖模型）。在最近举办的2024年世界移动通信大会（MWC 2024）上，Ameca接受了很多媒体的「采访」。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3347068431761653760" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEeSBKFWW9rrlCrvWEdTBvff2pUQJWKgicOAsrSJOs1X5q9ogwU4jotjQ%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1920" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3347068431761653760"></iframe></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">之前的视频显示，如果给Ameca安上手臂，ta也可以做一些简单的事情，比如画画（在接入文生图AI模型Stable Diffusion之后）以及尬舞。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;"><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3347048282291683332" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEa79d3BMOUNHyaVFjBE0mU4mmOjWYr6qLgB8mFeHgg7UxfsdGv4ocFg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1920" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3347048282291683332"></iframe></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425150" data-ratio="1.775" data-s="300,640" data-type="gif" data-w="320" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEbicr5gudLHdQ8LBIvWMosFE4fVbeqcKZamtyuporNOZTCqx5YWO1MEg/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">当然，Ameca 目前还走不了路，只能固定在地板上。不过，实验室已经在测试实验用腿。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">值得注意的是，Ameca 价格不菲。据媒体报道，特斯拉 Optimus 价格（马斯克估计量产后价格不到２万美元）甚至不及 Ameca 基本款的十分之一。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">研发 Ameca 的英国机器人公司 Engeneered Arts 规模不大，位于英国的法尔茅斯。负责人 Will Jackson 出生在一个艺术家庭，父母都参与过机器人制造，他也耳濡目染地倾向于为一些主题公园、电影娱乐公司、博物馆等机构制作机器人。有的提供向导服务，有的被大学作为研究平台。近几年，他们将所有的资源都投入到了 Ameca 的研发上，它也是该公司迄今为止最先进的机器人。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Will Jackson 坚持认为，建造人形机器人是为了让他们完成与人类互动的任务（而不是为了进工厂和仓库）。例如，经过这几年的研发，Ameca 也许可以成为老人的陪护（提醒＋关注）。为此，他们还教机器人下棋，但下棋水平不能太高。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">为了成功与人类互动，机器人需要有一张脸——Jackson 认为，人脸是我们所拥有的宽带最高的通信工具。面部能表达的东西要比你能说出来的要多。因此，Ameca 的脸是由一张受电子系统控制表情动态的乳胶制皮肤构成，非常富有表现力。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425152" data-ratio="0.56125" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsENGJicvR1hficSupKd1TaxQLvibKcmFhYEJP60kn1OO0THHmCTKTYJQhKg/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">视频前半段，除了一口英式英语，你是否也注意到了 Ameca 的微表情。调侃时会带点笑意；思考时会闭眼，有时也会转动眼珠？</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425151" data-ratio="0.5633333333333334" data-s="300,640" data-type="gif" data-w="600" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsEGCtib246vNpc5br0rX6D9jYUZUiafMyZVpykN7u32zGlGnIaPxz7ZRuw/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Engeneered Arts 最初也为娱乐业制作过动画人物，也有能力构建出极为逼真的面孔，但后来还是刻意按照人们从科幻小说获得的印象设计了 Ameca 的脸，皮肤呈灰色，有明显的接缝，还没有头发。据说，这样设计是为了避免恐怖谷效应。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425154" data-ratio="0.56125" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gW9ZXB4AXtKdtIVR5aO7qibsE38EIS4Gyj0yQr7clLPHyad5s3Gn4JfhPkjiaE7hWHOafQ7wYyabBUyw/640?wx_fmt=gif&amp;from=appmsg"></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">至于人形机器人与人类互动中的安全问题，公司也在通过工程方法加以解决。Jackson 注意到人类的四肢之所以能避免伤害他人，原因之一是他们既结实又松软。不过，现在还没有那种既小巧又强大的执行器能在机器人身上实现这一点。不过，他们也在努力克服这个难题，毕竟，如果 Ameca 会失控撞到人，以社交为生的它们也就失去了意义。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>参考链接：</em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>https://www.youtube.com/watch?time_continue=1&amp;v=VXlpF3DrVP0&amp;embeds_referring_euri=https%3A%2F%2Ftwitter.com%2F&amp;source_ve_path=Mjg2NjY&amp;feature=emb_logo</em></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>https://www.economist.com/science-and-technology/2022/11/07/humanoid-robots-are-getting-close-to-reality?utm_medium=cpc.adword.pd&amp;utm_source=google&amp;ppccampaignID=17210591673&amp;ppcadID=&amp;utm_campaign=a.22brand_pmax&amp;utm_content=conversion.direct-response.anonymous&amp;gad_source=1&amp;gclid=CjwKCAiAivGuBhBEEiwAWiFmYU9-IIvzfA2H0haQ-9meiKTYeebsVZlOgpxwmkxtTMSL80_37JK3QxoChkkQAvD_BwE&amp;gclsrc=aw.ds</em></span><span style="font-size: 15px;"></span></p><p style="margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425153" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><div style="line-height: 1.75em;"><p style="display: none;margin-bottom: 0px;"><br></p></div><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name>关注生成式AI用例</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mistral AI新模型对标GPT-4，不开源且与微软合作，网友：忘了初心]]></title>
        <id>2650908731_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908731&amp;idx=1&amp;sn=ede59d27d5992ca5c5274a76b837da2e&amp;chksm=84e46c45b393e553b2dca187f7e11752b476677101894f7c1feed7ac23908432d8afd9790fcb#rd"/>
        <updated>2024-02-27T03:41:25.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: auto;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;background-color: rgb(117, 117, 118);color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道</span><br mp-original-font-size="17" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">机器之心编辑部</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="29" data-source-title="" mp-original-font-size="15" mp-original-line-height="24" style="color: var(--weui-FG-1);line-height: 24px;letter-spacing: 0.578px;text-wrap: wrap;outline: 0px;font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-size-adjust: auto;visibility: visible;"><div class="js_blockquote_digest" mp-original-font-size="15" mp-original-line-height="24" style="outline: 0px;visibility: visible;line-height: 24px;"><p style="outline: 0px;visibility: visible;line-height: 1.75em;"><span mp-original-font-size="15" mp-original-line-height="26.25" style="outline: 0px;visibility: visible;line-height: 26.25px;letter-spacing: 0.578px;">「欧洲版 OpenAI」的「最强开源大模型」，被微软收编了。</span></p></div></blockquote><p style="letter-spacing: 0.578px;text-wrap: wrap;margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">生成式 AI 领域，又有重量级产品出现。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">周一晚间，Mistral AI 正式发布了「旗舰级」大模型 Mistral Large。与此前的一系列模型不同，这次 Mistral AI 发布的版本性能更强，体量更大，直接对标 OpenAI 的 GPT-4。而新模型的出现，也伴随着公司大方向的一次转型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">随着 Mistral Large 上线，Mistral AI 推出了名为 Le Chat 的聊天助手（对标 ChatGPT），任何人都可以试试效果。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425047" data-ratio="0.5636623748211731" data-s="300,640" data-type="png" data-w="699" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffgbqZBNggCH8pM3WMUW6XBSu6x3TGP1HXdbpawrlbge5JAWatIxVkBg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="font-size: 15px;color: rgb(123, 12, 0);">试用链接：https://chat.mistral.ai/</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">此前，Mistral AI 提出的 Mistral-Medium 因为强大的性能、「意外」的开源而名噪一时，目前很多大模型初创企业都已不再对标 Llama 2，而是将 Mistral AI 旗下模型作为直接竞争对手。此次 Mistral Large 的出现，自然迅速吸引了众人关注。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人们首先关注的是性能，尽管在参数数量上不及 GPT-4，Mistral-Large 在关键性能方面却能与 GPT-4 媲美，可以说是当前业内的前三：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425048" data-ratio="0.9593417231364957" data-s="300,640" data-type="jpeg" data-w="1033" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffKNNhZUCQiaToREJicwWnLpdiaFLBoaRw54PA39ZUHn6icV5eXUVdyDtyNw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的推理准确性优于 Claude 2、Gemini 1.0 Pro、GPT-3.5，支持 32k token 的上下文窗口，支持精确指令，自带函数调用能力。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人们也发现 Mistral Large 的推理速度超过了 GPT-4 和 Gemini Pro。然而优点到此为止。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">模型除了增加体量，也需要有相应的数据。在模型发布后，人们发现它生成的文本有一种 ChatGPT 的既视感。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425049" data-ratio="0.6564814814814814" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffGib82Q5OvjdXPicYF0duUh6qBlf6waf8b129Ld3SfDNicw323n9Q6IJYQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">如果说为了能赶上业内最先进的 GPT-4，使用 AI 生成的内容进行训练或许并不是什么大问题。但 Mistral Large 的出现也给 AI 社区的人们带来了危机感：它并不是一个开源大模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425050" data-ratio="0.48318924111431316" data-s="300,640" data-type="jpeg" data-w="1041" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffaxgVD5Suqdr7tfjugalJvH0LrJHXTpeUjhfLurQq6aOGO1UPKO7Kiaw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这次发布的大模型有跑分，有 API 和应用，就是不像往常一样有 GitHub 或是下载链接。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">有网友发现，新模型发布后，Mistral AI 官网还悄悄把所有有关开源社区义务的内容全部撤掉了：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425051" data-ratio="1.183495145631068" data-s="300,640" data-type="jpeg" data-w="1030" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffbNHZB6HYRlX6ibXozXu6VviafRd33OQQYfdPwteS3gYwspf2p8AFkafA/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">难道以开源起家的 Mistral AI，成立才不足一年，这就要转向了吗？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 目前已经能在 Mistral AI 自有平台 La Plateforme 和微软 Azure 上使用。除了 Mistral Large 之外，Mistral AI 还发布了新模型 Mistral Small，针对延迟和成本进行了优化。Mistral Small 的性能优于 Mixtral 8x7B，并且推理延迟得到了降低，提供了一种开放权重模型和旗舰模型之间的中间方案。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">但模型的定价也引发了一些质疑。比如 Mistral Small 的低延迟相比于 Mixtral 8x7B 的提升微乎其微，但输入贵了 2.8 倍，输出贵了 8.5 倍：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425052" data-ratio="0.3787037037037037" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffy48AuaWgsje5qB3PSzKtsCl1T0sia2M1fwjEoD76dia31icB3dy4cQ9pg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">如果以商业大模型的标准来看待，Mistral Large 的定价和 GPT-4 相比并不具备优势，这又该如何吸引客户呢？</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425053" data-ratio="0.7333333333333333" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffNtbGFYbLmu1Q3Ub1c2ktgGXfB9f2IANt41By9aRf5svHPLMGAYqTtw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这位业内人士表示：「如果它的价格是 GPT-4 Turbo 的一半，我会更理解。」</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425054" data-ratio="0.6027777777777777" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffMGf758vmqdKNsvmTXvUN07EHTKXAjSH1mfQUNBKB4zGryfJRxJBGAg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">新的 Mistral AI「大杯」模型，表现如何？</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在官方博客中，Mistral AI 详细介绍了 Mistral Large 的功能和优势：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 在多个常用基准测试中取得了优异的成绩，使其成为世界上排名第二的可通过 API 普遍使用的模型（仅次于 GPT-4）：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425055" data-ratio="0.5067920585161965" data-s="300,640" data-type="png" data-w="957" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaff8aArzEMWN8DqrgfZ9rsPMXsvdV42h9anquNXAeaoAkonc3I3rc3Qmg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;letter-spacing: 0.034em;">GPT-4、Mistral Large（预训练）、Claude 2、Gemini Pro 1.0、GPT 3.5 和 LLaMA 2 70B 在 MMLU 上的比较（测量大规模多任务语言理解）。<br></span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的优势如下：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的母语是流利的英语、法语、西班牙语、德语和意大利语，对语法和文化背景有细致入微的理解；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 的 32K Token 上下文窗口允许从大型文档中精确调用信息；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">其精确的指令跟随能力使开发人员能够设计自己的审核策略 ——Mistral AI 以此来设置 le Chat 的系统级审核；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 本身就能够进行函数调用。这与在 la Plateforme 上实施的受限输出模式一起，实现了大规模应用程序开发和技术堆栈现代化。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">关于基准测试结果对比，可以参考以下：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">推理和知识</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 展现出了强大的推理能力。下图报告了预训练模型在标准基准上的性能：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425056" data-ratio="0.32685185185185184" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiafficaVQMtjxp9BV9dankUjx6MAiaZib3PibGLaTtvPib5v7Eria6CCbyqwNNnQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">与多个领先 LLM 模型在广泛常识、推理和知识基准上的表现对比，基准包括 MMLU（测量理解中的大规模多任务语言）、HellaSwag（10-shot）、Wino Grande（5-shot）、Arc Challenge（5-shot）、Arc Challenge（25-shot）、TriviaQA（5-shot）和 TruthfulQA。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">多语言能力</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 具有原生的多语言能力。它在法语、德语、西班牙语和意大利语的 HellaSwag、Arc Challenge 和 MMLU 基准测试中明显优于 LLaMA 2 70B。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425057" data-ratio="0.23333333333333334" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffibM5bCJzDe8ZPwhmTL6EgK28fKaTTxUQeibVxAMR2YFNVnEnkKbITflA/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Mistral Large、Mixtral 8x7B 和 LLaMA 2 70B 在 HellaSwag、Arc Challenge 和 MMLU 上法语、德语、西班牙语和意大利语的比较。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><strong><span style="font-size: 15px;">数学和编码</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral Large 在编码和数学任务中表现出顶尖的性能。下表报告了一系列流行基准的性能，以评估一些顶级 LLM 模型的编码和数学性能。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425058" data-ratio="0.46794871794871795" data-s="300,640" data-type="png" data-w="936" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffcNe6qHicDukX0ribGib99nS6kOH6MWLOibiadKx3EnsSE8A17QJzetTm8dg/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">领先 LLM 模型在流行编码和数学基准上的性能：HumanEval pass@1、MBPP pass@1、Math maj@4、GSM8K maj@8（8-shot）和 GSM8K maj@1（5-shot）。</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: center;"><strong><span style="font-size: 16px;">与微软合作，行 OpenAI 故事</span></strong></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">在发布 Mistral Large 等模型的同时，Mistral AI 还宣布了一个消息：将与微软合作，在 Azure 上提供自己的模型。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">此次合作使 Mistral AI 成为第二家在微软 Azure 云计算平台上提供商业语言模型的公司。这有助于 Mistral AI 将自己的模型推向市场，也让 Mistral AI 有机会使用 Azure 的尖端 AI 基础设施，以加速其下一代大型语言模型的开发和部署。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425059" data-ratio="0.32407407407407407" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffrOaXib6q1Jkicfw00FIFN7kI283JtyMu8ZJ1Lr10HNKBicP0BiasNV74wQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这家公司表示，「在 Mistral AI，我们的使命是让前沿人工智能无处不在。这就是我们今天宣布将自己的开放和商业模型引入 Azure 的原因。微软对我们模型的信任让我们前进了一步！」</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">这项为期多年的协议标志着微软正在其最大的赌注 OpenAI 之外，努力提供各种人工智能模型，为其 Azure 云服务吸引更多客户。去年 11 月，OpenAI 经历了 CEO Altman 被解雇（后又重返）的风波。而作为最大的股东，微软在消息公布前 5 到 10 分钟才从 OpenAI 那里得到消息。在这次动荡后，微软设法在控制 OpenAI 的非营利性董事会中获得了一个无投票权的观察员席位。这让他们对 OpenAI 的内部运作有了更多了解，但在重大决策上，微软依然没有投票权。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 对路透社表示，作为交易的一部分，微软将持有该公司少数股权，但未透露细节。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">微软证实了对 Mistral AI 的投资，但表示不持有该公司的股权。这家科技巨头因向 OpenAI 提供巨额资金而受到欧洲和美国监管机构的审查。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">根据公告，微软与 Mistral AI 的合作主要集中在三个核心领域：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">超算基础设施：微软将通过 Azure AI 超级计算基础设施支持 Mistral AI ，为 Mistral AI 旗舰模型的 AI 训练和推理工作负载提供一流的性能和规模；</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">市场推广：微软和 Mistral AI 将通过 Azure AI Studio 和 Azure 机器学习模型目录中的模型即服务（MaaS）向客户提供 Mistral AI 的高级模型。除 OpenAI 模型外，模型目录还提供了多种开源和商业模型。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">人工智能研发：微软和 Mistral AI 将探索为特定客户训练特定目的模型的合作。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">除了微软，MistralAI 还一直在与亚马逊和谷歌合作，分销自己的模型。一位发言人表示，该公司计划在未来几个月内将 Mistral Large 应用于其他云平台。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 成立于 2023 年 5 月，由来自 Meta Platforms 和 Alphabet 的几位前研究人员 ——Arthur Mensch（现任 CEO）、Guillaume Lample 和 Timothee Lacroix 共同创立。成立不到四周，Mistral AI 就获得了 1.13 亿美元 的种子轮融资，估值约为 2.6 亿美元。成立半年后，他们在 A 轮融资中筹集了 4.15 亿美元，估值飙升至 20 亿美元，涨了七倍多。而此时，他们仅有 22 名员工。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425060" data-ratio="0.3175925925925926" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW9vnoUQYTuRK9GwrZlABiaffMCNSfTnABSfgSqibicDmOlNp0Na4pKqiaibZFjgz16mH78jjicyUJZdJjSw/640?wx_fmt=png&amp;from=appmsg"></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">总体来说，Mistral AI 的模型现在有以下几种获取方式：</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><ul class="list-paddingleft-1" style="list-style-type: disc;"><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Mistral AI 自己的 API：该接入点安全地托管在 Mistral AI 位于欧洲的基础设施上，使开发人员能够在各种型号的模型上创建应用和服务。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">Azure：Mistral Large 可通过 Azure AI Studio 和 Azure Machine Learning 获取，其用户体验与 Mistral AI 的 API 一致。</span></p></li><li><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">安全部署：Mistral AI 的部分模型可以部署在用户自己的环境中，用于对安全性最敏感的用例。</span></p></li></ul><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">感兴趣的读者可以前去尝试。</span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">参考内容：</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://mistral.ai/news/mistral-large/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://techcrunch.com/2024/02/26/mistral-ai-releases-new-model-to-rival-gpt-4-and-its-own-chat-assistant/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.reuters.com/technology/microsoft-partners-with-openais-french-rival-mistral-2024-02-26/</span></em></span></p><p style="margin-top: 0px;margin-bottom: 0px;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/</span></em></span></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;line-height: 1.75em;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425061" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>关注大模型的</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[国内公司有望做出Sora吗？这支清华系大模型团队给出了希望]]></title>
        <id>2650908691_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908691&amp;idx=1&amp;sn=1f4eb958d61d40b568bac20fff6cc165&amp;chksm=84e46c6db393e57b69240f690d8e548c04f49feffbb12041a89b22271d26d298e24135b8e348#rd"/>
        <updated>2024-02-26T10:19:24.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心原创<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">作者：张倩</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="32" data-source-title="" style="outline: 0px;color: var(--weui-FG-1);font-family: system-ui, -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-wrap: wrap;background-color: rgb(255, 255, 255);letter-spacing: 0.578px;visibility: visible;"><div class="js_blockquote_digest" style="outline: 0px;visibility: visible;"><p style="outline: 0px;visibility: visible;"><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">在 Sora 代表的视</span><span style="font-size: 15px;letter-spacing: 0.578px;text-wrap: wrap;">频生成路线上，国内公司其实已有一定的技术储备。</span></p></div></blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;letter-spacing: 0.034em;">2023 年年底，很多人都预测，未来一年将是视频生成快速发展的一年。</span><span style="font-size: 15px;letter-spacing: 0.034em;">但出人意料的是，农历春节刚过，OpenAI 就扔出了一个重磅炸弹 —— 能生成 1 分钟流畅、逼真视频的 Sora。</span><span style="font-size: 15px;letter-spacing: 0.034em;">它的出现让很多研究者担心：</span><span style="font-size: 15px;letter-spacing: 0.034em;">国内外 AI 技术的差距是不是又拉大了？</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3344131265981038597" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8RhQ1NqywibSzHuyE72XN6QXO8Br7CYrxicdynaESd6B7XPCniarXDX3asZFUeHxGw0WjzwGFia7pvBg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3344131265981038597"></iframe></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);letter-spacing: 0.034em;font-size: 12px;">Sora 生成的新视频</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">根据 OpenAI 披露的技术报告，<strong>Sora 的核心技术点之一是将视觉数据转化为 patch 的统一表示形式，并通过 Transformer 和扩散模型结合，展现了卓越的 scale 特性</strong>。无独有偶，最近发布的 <a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908360&amp;idx=2&amp;sn=7ab6412f5979cb8f1386abb83f30f6d8&amp;chksm=84e462b6b393eba085a27e47431c36e8fa4e61c56a264f085cff56bcdb002f450d64cf41b000&amp;scene=21#wechat_redirect" textvalue="Stable Diffusion 3" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Stable Diffusion 3</a> 也采用了同样的架构。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">其实，这两项工作都是基于 Sora 核心研发成员 William Peebles 和纽约大学计算机科学助理教授谢赛宁合著的一篇论文《Scalable Diffusion Models with Transformers》。这篇论文提出了一种基于 Transformer 架构的新型扩散模型 ——DiT，用对潜在 patch 进行操作的 Transformer 替换常用的 U-Net 主干网络，把大语言模型的可扩展性、涌现性复制到了视觉任务上。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">我们关注到，其实早在 2022 年 9 月，清华团队就提交了一篇名为《All are Worth Words: A ViT Backbone for Diffusion Models》的论文（比 DiT 早两个月）。</span><span style="font-size: 15px;">这篇论文提出了用基于Transformer 的网络架构 U-ViT替代基于CNN的U-Net。对</span><span style="font-size: 15px;">比来看，<strong>两项工作在架构路线上完全一致</strong>：均是提出了将 Transformer 与扩散模型融合的思路；并且在具体的实验路径上也一致，比如采用了相同的 patch embedding、patch size；都得出了同样的结论 ——patch size 为 2*2 是最理想的；在模型参数量上，两者都在 50M-500M 左右的参数量上做了实验，最终都证实了 scale 特性。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">不过 DiT 仅在 ImageNet 上做了实验，U-ViT 在小数据集（CIFAR10、CelebA）、ImageNet、图文数据集 MSCOCO 上均做了实验。此外，相比传统的 Transformer，U-ViT 提出了一项「长连接」的技术，大大提升了训练收敛速度。这篇论文后被 CVPR 2023 收录。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">基于 U-ViT 架构，2023 年 3 月，该团队再次发布了一项 UniDiffuser 的工作（参见<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650870787&amp;idx=1&amp;sn=af162ab7748c4ab417365b6ca2d613c0&amp;scene=21#wechat_redirect" textvalue="《清华朱军团队开源首个基于 Transformer 的多模态扩散大模型，文图互生、改写全拿下》" linktype="text" imgurl="" imgdata="null" tab="innerlink" data-linktype="2">《清华朱军团队开源首个基于 Transformer 的多模态扩散大模型，文图互生、改写全拿下》</a>），在开源的大规模图文数据集 LAION-5B 上训练了 10 亿参数量的多模态模型。同一时期，主攻通用多模态大模型赛道的生数科技正式成立（参见</span><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650881171&amp;idx=2&amp;sn=bdf6e9da71206b7dc18bf6f7917e215c&amp;chksm=84e4f8edb39371fba72a955fbee2dd6092f44eaef4206d217fbb5ed5352d7aad883c9b1511b7&amp;scene=21#wechat_redirect" textvalue="《专访生数科技唐家渝：清华系团队拿到上亿融资，用Transformer来做多模态大模型》" linktype="text" imgurl="" imgdata="null" data-itemshowtype="11" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">《</span><span style="font-size: 15px;letter-spacing: 0.034em;">专访生数科技唐家渝：</span><span style="font-size: 15px;letter-spacing: 0.034em;">清华系团队拿到上亿融资，用Transformer来做多模态大模型</span><span style="letter-spacing: 0.034em;font-size: 15px;">》</span></a><span style="letter-spacing: 0.034em;font-size: 15px;">）。区别也在此刻发生，生数科技出于算力资源、技术成熟度等方面的考量，优先尝试将 U-ViT 应用于图文任务，而 OpenAI 则是利用其算力优势跨越式地直接将 DiT 应用于视频任务。</span><span style="letter-spacing: 0.034em;font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">虽然主攻的任务不同，但 U-ViT 同样展示了在视觉任务下的优异能力。与当时同阶段的 SD1.5 比较，UniDiffuser 效果是基本持平的。更重要的是，UniDiffuser 扩展性更强，能基于一个底层模型完成图文之间的任意生成。简单来讲，除了单向的文生图，还能实现图生文、图文联合生成、无条件图文生成、图文改写等多种功能。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425036" data-ratio="0.7611111111111111" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6QXHgl0XqQZBTo5j7diab8d8AApPIumRibX0nl2BXMFhtLE67KxlhJZ3Lg/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;">Unidiffuser开源版效果</span></em><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;"><br></span></em></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425042" data-ratio="0.35555555555555557" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6Qib0cPbymCLS2j8cFWu9vSgZKYnhKiaYEibqwDNRaib6YtnnrrEUVeuCAfA/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 0px;"><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">Unidiffuser当前效果图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">有了这些对于架构的早期探索，生数科技其实在视频生成上颇具潜力，有望成为最接近 Sora 的中国团队。而且，他们也早已在视频生成方向进行了一些探索。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">那么，未来的路怎么走？在视频生成这个问题上，有哪些棘手的问题需要解决？Sora 又将带来哪些商业机遇？在近期的一次访谈中，<strong>生数科技 CEO 唐家渝、首席科学家朱军</strong>向机器之心透露了自己的看法。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>Sora 的出现比预期早半年</strong></span><span style="font-size: 16px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：首先想请两位回忆一下，第一次看到 Sora 的时候是什么感觉？有没有印象比较深刻的 demo？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我印象最深的是它的流畅性和时间长度。之前 AI 生成的短视频，大家都戏称为 GIF—— 变动小，视频短，只有几秒。Sora 生成的视频长得多，流畅度、自然度又明显好了一个层次，我觉得这是最直观的一个视觉上的冲击。印象比较深刻的 demo 是纸飞机那个场景：一堆纸飞机在森林里面飞，各个纸飞机还会撞在一起，还会跟树叶有一些互动。这本身是一个想象中的场景，但是生成效果逼真度很高，已经具有一定的物理规律的表现能力了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p><iframe class="video_iframe rich_pages" data-vidtype="2" data-mpvid="wxv_3344086088746778624" data-cover="http%3A%2F%2Fmmbiz.qpic.cn%2Fsz_mmbiz_jpg%2FKmXPKA19gW8RhQ1NqywibSzHuyE72XN6QKTibAcYhmpHfydYyeBzk71XTlYXP9Y87zM7ibCLB8kVgNhbOCtLuedfg%2F0%3Fwx_fmt%3Djpeg" allowfullscreen="" frameborder="0" data-ratio="1.7777777777777777" data-w="1280" style="border-radius: 4px;" data-src="https://mp.weixin.qq.com/mp/readtemplate?t=pages/video_player_tmpl&amp;action=mpvideo&amp;auto=0&amp;vid=wxv_3344086088746778624"></iframe></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">如果回头看大家之前对视频生成长度的预判，Sora 的出现其实是超前了。之前能够预测到今年视频生成会快速发展，但当时在技术原理上，大家没有看到特别大的技术突破，所以当时就觉得短视频（几秒钟那种）会是一个主流形式。但 Sora 一下子做到了这么长，还是一个比较 surprise 的事情。原本预计今年年中或年底能做到这个水平，Sora 提前了大概有半年的时间。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>用 Transformer 替代 U-Net 是一个自然想法，</strong></span><strong style="color: rgb(61, 170, 214);font-size: 16px;letter-spacing: 0.034em;">区别在于谁先做出效果</strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：最近关于 Sora 核心创新点的讨论比较多，而且大家提及最多的是它的架构。朱老师能否通俗地解释一下 Sora 的 Diffusion Transformer 架构是怎么一回事，「用 Transformer 替换常用的 U-Net 主干网络」有何必要性？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">以视频数据为例，扩散模型的原理就是在数据上做加噪和去噪。这里很关键的问题，就是能不能准确地预测噪声，设计一个噪声预测网络。过去大家会用传统的 U-Net 去做，但是 Transformer 被证明在可扩展性等方面有很大的优势，所以用 Transformer 去替代 U-Net 是一个很自然的想法，区别就在于谁先做出来效果。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Sora 用到的 DiT 是 2022 年底发布出来的。其实早在 2022 年 9 月份，我们发布了一个叫 U-ViT 的模型。这个模型的主要思想是用 Vision Transformer 去替代 U-Net，和 DiT 核心的想法是一样的，就是用 Transformer 去增强扩散模型。这后来被证明非常有效，特别是在视觉数据的生成上。它一方面保持了扩散模型的优势，另一方面又利用了 Transformer 的可扩展性以及对不同模态的兼容性。相比于传统的 Transformer，我们自己的设计（U-ViT）里面还包括了长连接，它可以让计算效率变得更高，能看到很显著的效果提升。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503425041" data-ratio="1.357609710550887" data-s="300,640" data-type="png" data-w="1071" style="width: 379px;height: 515px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gW8RhQ1NqywibSzHuyE72XN6QO4LKyZlDnbFslqtaICwJiaMHfMJtYpq7WcaFxU7D1EBYVaUyJJwDrKw/640?wx_fmt=png&amp;from=appmsg"></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><em style="color: rgb(136, 136, 136);text-align: left;font-size: var(--articleFontsize);letter-spacing: 0.034em;"><span style="font-size: 12px;">U-ViT 架构</span></em><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：我们可以从哪些指标上看到这些效果？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">其实在 22 年的时候，大家就已经看到了，用 Vision Transformer 这种架构可以提高生成质量，实现更高的分辨率，也可以更有效地训练更大规模的模型。现在，我们可以看到更多的例子，包括 Sora、Stable Diffusion 3。这些例子一次又一次地证明了，这个架构的潜力是巨大的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：在生数的产品里面，这份工作展现出了什么样的效果？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">我们从一开始就坚持用扩散加 Transformer 的融合架构，也就是多模态原生的架构。之前，很多团队在做多模态的时候，会想说什么模态都对到语言上。但我们认为这种架构不是最优，因为从原理和计算效率上来看，这种方法存在天然的不足，所以从一开始我们就在走扩散加 Transformer 这种路线。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">2022 年我们提出 U-ViT 架构的时候对标的是 Stable Diffusion，当时 Stable Diffusion 刚开源。所以在 U-ViT 架构的基础上，我们又在 2023 年 3 月份开源了一个叫 UniDiffuser 的大模型。这个模型也是基于扩散加 Transformer 的融合架构，可以在文、图两种模态之间进行任意的转换。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">从底层架构的训练到优化到支撑上层的图像、3D、视频的生成，生数一直在坚持这个架构，一直在坚持这种融合的路线。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：您的意思是说，这种融合的路线相比那种单纯地用 Diffusion 或者单纯地用 Transformer 效果都要好，是吗？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">是的。与单纯地用 Diffusion 相比，融合架构的主要优势就是 Transformer 的可扩展性。与单纯地用 Transformer 相比，融合架构在生成视觉数据的效率，包括模型的表示效率和计算效率等方面有很大的优势。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对于 Transformer 这个架构来说，你把所有东西都放到里边，好处就是简单直接。但是，就目前对视觉数据的处理和生成效果来看，扩散还是占优势的。在我们看来，融合模型更符合原生多模态的定位。因为不同类型的数据，它的特点是不一样的，所以应该针对不同模态选择最合适的一种处理方式。从实际的视觉生成效果来看，现在主流的方法也是用扩散模型去做生成，因为用 Transformer 这个架构直接去做生成的话，到目前为止效果还是落后的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：你们的 U-ViT 和 DiT 是同一时期提出的，但是你们选择优先用它去做图文任务，而不是视频生成，是基于什么考量？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">实际上我们也在做视频生成，只是当时基于算力的考虑排了一个优先级。这里面也有我们基于技术成熟度的一个预判。去年，我们是优先从 2D 的图像开始，然后紧接着到 5 月份的时候，我们就做了 3D 生成（从 2D 到 3D），后来我们又做了视频和 4D（ 参见《<a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650904838&amp;idx=3&amp;sn=de12a4c5ab4313d126453fbbf6f2531d&amp;chksm=84e45d78b393d46e0c90c46d9daaab20ac8c66278a1d7729dc205f69af7317d8727442027263&amp;scene=21#wechat_redirect" textvalue="一键实景转动画，清华系初创公司全球首发4D骨骼动画框架" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;letter-spacing: 0.578px;text-decoration: none solid rgba(0, 0, 0, 0.9);">一键实景转动画，清华系初创公司全球首发4D骨骼动画框架</span></a>》）。实际上就是在有了基础的基座之后，我们可以做不同维度的扩增，3D、4D 其实分别是空间、时间上的一个扩展。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">视频实际上是图像的流，它相当于在时间轴上做了一个扩增。所以我们的架构实际上可以很自然地支持短视频的生成，只是当时我们主要聚焦在几秒钟的短视频的生成，没有像 OpenAI 的 Sora 那样一下子做到几十秒、一分钟。这里边有很多原因，但其中一个很重要的原因是，我们手头的资源相对来说确实受限很多。但是，从 2D 图像到视频生成，很多东西是一脉相承的，很多经验（比如大规模训练的经验）是可以复用的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>复现 Sora，还有很多难题需要解决</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：生成几秒的视频和 1 分钟的视频之间的技术差异是巨大的。根据您的经验，除了算力，做到这一点的关键是什么？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">这里面很重要的一块是，针对比较长的视频，怎么有效地表示它的时空信息，怎么有效地去压缩视频数据，学到一个嵌入的表示，然后在上面再去做扩散、生成。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">另外，要让这种架构能够有效训练，数据也很重要。基于之前的 DALL・E 3 等积累的优势，OpenAI 可以对视频数据做到比较有效的语义理解。这在训练数据里是非常关键的。因为在创作的时候，你输入的语言通常是比较有限的、简单的，所以如果想去生成丰富的视频内容，中间需要一个比较强的语义理解过程。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">当然，可能还有很多我们不知道的因素。Sora 的成功不光是一个生成的问题，里面包括语义理解、数据标注、数据清洗、大规模训练以及工程优化等等。这些问题如果没有做过是不知道的，由于 OpenAI 做过很多成功的案例，所以他们做成一个新项目的成功率会更高。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：同样的架构用来做图像任务和视频任务，会有什么不同吗？对生数团队而言，下一步计划如何将该架构从图像任务拓展至视频任务？</span></strong><span style="font-size: 15px;">&nbsp;</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">主要的不同在于，视频里面包含很多的时空信息。怎么抓住里面关键的运动、保持住长时间的一致性？这是单张图片不会涉及到的。二者从原理上来说是相通的，我们从去年下半年开始也一直在做视频相关的工作。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">生数底层拥有自主训练的架构，所以在上面我们能够很自然地做各种生成。图像生成是一个基础，图像生成的质量会影响到视频生成的质量。此外，3D 生成我们也持续在做。只是，Sora 比我们预期出现得要早，所以后续我们会加强视频生成这一块。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>打造通用多模态，需要通用架构提供支撑</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：Sora 的发布让我们看到 OpenAI「all in AGI」的野心。他们的技术路线有两个关键点：一是多模态，二是通用化架构。生数科技也是「通用多模态路线」的坚持者，在您看来，通用化架构有何必要性？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">如果想让模型实现更强的通用性，就需要更加通用的模型架构来支撑。以 Sora 为例，在架构上它肯定要融合文字和视觉数据。换句话说，如果你只做视觉或只做文本的话，你在多模态的任务上就不是最优，或者说有些模态不能处理。这是一个很直接的相互支撑的关系。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：做这种通用架构的难点体现在哪几个方面？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">难点就在于，不同模态的数据，特点是不一样的，你是不是直接简单粗暴地用一种方式表示所有数据？这种方式目前来看可能并不是最优，所以需要针对不同数据的特点去分析考虑。另外，不同模态的数据，它的数据量是不一样的，或者说不均衡。在训练过程中，这可能会对你的优化过程产生实际的影响。还有不同模态之间的对齐理解也是问题。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：Sora 出现后，有种声音说，国内外的差距进一步拉大了，您怎么看待这个问题？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">朱军：</span></strong><span style="font-size: 15px;">差距是否拉大，这是一个可以辩论的问题。但我觉得，Sora 出来之后，国内外并没有像当初 ChatGPT 出来时那样形成很明显的代差。只是大家现在在工程技术上可能会落后一些。视频生成这个问题，国内也很重视，而且国内做图像、视频相关任务的基础还是比较好的。从当前的结果来看，实际情况可能比想象中要乐观一些。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>来自 OpenAI 的启发：</strong></span></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>技术自信和资源都很重要</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：如果从商业和产品的角度来看，您如何看待 Sora 的成功？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">OpenAI 整体的模式是朝着 AGI 的目标，从底层模型能力提升的层面不断地往前跑，模型本身就可以看作是他们最核心的产品。据说 Sora 这个小组也并没有去考虑太多关于商业和产品的事情，所以可能他们在最开始的时候主要还是聚焦在如何实现真正好的视频生成能力，然后去相信说只要我有这么强的能力，上面一定能搭出更多的商业化产品。对外赋能底层 API 的能力，然后在上层去创建一个繁荣的 AI 生态，是 OpenAI 已经验证成功的一种商业模式了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">从这个维度来讲，我觉得他们成功因素中很重要的一点已经写在了他们公司的价值观里，也就是所谓的 “Scale”，他们整个公司都是相信 scale up 的，官网原话是「如果对此产生了怀疑，就进一步 scale it up」。所以我觉得这也是他们对于自己的技术路线的充分自信和坚持，然后衍生出了现在的成功。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：这对生数科技有什么启发？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">首先是观念上的。我觉得我们在设计了 Diffusion 融合 Transformer 这样一个好的架构，并且已经看到它有巨大的潜力的情况下，应该要更有技术上的自信。这和 OpenAI 去相信 scale up 是类似的。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">第二点是，在有自信的同时，如果你要去做 scale up，尤其是基于视频数据，就要去卷入更多的资源。因为像我们或者国内的其他创业公司，其实相比 OpenAI 所拥有的资源还是差很多的。所以我们得敢想敢做地去卷入更多资源，和更多资源方去合作，这样才能把技术自信转变为技术实现，然后变成产品实现。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>视频生成：生数的过去与未来</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：生数之前上线过一些文生视频的能力，可以介绍一下之前的探索工作吗？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我们的技术探索最终是为产品服务的。从产品层面来看，我们之前发布的能力和业界是差不多的，就是几秒的短视频生成和编辑。那个时候主要受限于算力等因素，没有利用已有的架构在视频数据上去完成 scale up。从产品使用角度来看，我们其实看到这种几秒的视频已经能够帮用户去做一些创意的工作，即使要制作长视频，其实也可以通过设计脚本来拼接短视频实现。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">但 Sora 的出现让我们看到，原生长视频生成的能力不仅从内容创作的角度，可以帮助我们去进行长镜头等更加艺术化的表达，也能外显出一定的物理世界理解能力，使得生成的视频更加自然。这也大大增强了我们加大视频生成研发投入的信心和决心。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此外，我们之前的这些探索其实也是为了牵引内部的一些工程基础建设，比如为视频数据的收集、清洗、标注以及模型的高效训练积累经验。这些积累和最接近Sora的架构，使得我们在做长视频生成时，对最终的效果更加抱有期待。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：据您所知，Sora 的开发、应用成本有多高？如果要做类似产品，生数要如何应对随之而来的成本问题？</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">就开发成本来说，业界估计资源比较充分的状态需要达到万卡（英伟达 A 系列）的水平。由于我们之前在大规模训练上做了很多加速的工作，所以我们的需求实际评估下来会少一些。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如果估算一下 Sora 的应用成本，目前生成 60 秒的高清视频大概需要几块到几十块人民币。所以 OpenAI 现在还没有完全放出来这个东西，估计也是有算力、成本方面的顾虑。此外，模型生成视频的成功率也是未知数，这可能也是一个顾虑。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">要降低应用成本，肯定要在这个过程中做一些模型压缩的工作，包括一些分布式的操作 —— 比如在手机、笔记本端去做一些推理，也会是大家去做的一个衍生方向。另外，架构层面的一些优化肯定也会持续去做。所以应用成本的问题，我们觉得相对来说还是比较乐观的。</span></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>什么叫「原生多模态模型」？&nbsp;</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：根据您公司的描述，你们走的是「原生多模态大模型」赛道，能否介绍一下这个赛道和其他赛道的区别，以及该赛道国内外玩家的具体情况。</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">其实定位原生多模态这个赛道是说，我们从第一天就坚持做一个完整的通用多模态大模型，而不是训练多个模型，对这些模型的能力做排列组合式的使用。我们的做法是从底层的架构出发，天然地去考虑通过一个模型支撑不同数据的输入输出，它的特点是模型学到的知识会更加充分，而且在使用的时候，不用调用不同的模型去做组合应用，因此推理效率会更高。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">举个具体的例子，GPT-4支持文本-文本，DALL·E 3支持文本-图像，GPT-4V可同时输入文本和图像，但输出仅文本，在应对开放的视觉任务时，是通过调用DALL·E 3或者GPT-4V的接口来实现，而原生的技术路线是基于一个底层架构实现「GPT-4V + DALL·E 3」的统一，能应对广泛开放域的文本和视觉交互类的复杂场景。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这个领域的国外玩家主要是谷歌（Gemini）和 OpenAI（Sora）。国内的话，我们是最早、也可能是唯一坚持做通用性的多模态大模型的公司。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：从产品的角度，您如何定义「原生」？</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">从产品角度来看，其实我们更多的是考虑有了原生多模态模型的加持之后，产品所带来的用户体验有没有指数级的提升，像「所想即所得、所说即所得」就是一种指数级的提升。我们所做的事情，无论是图像、3D 还是视频的生成，其实都是朝着这个目标在努力的。就是让一个即使没有任何专业能力的人，都可以去创作出他想要的画面，或者说在数字世界或物理世界具象化出想象中的某个东西。我个人心中的标准之一就是，自己的亲戚朋友最终会不会喜欢去用这么一个产品。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 16px;color: rgb(61, 170, 214);"><strong>Sora 所带来的商业机遇</strong></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">机器之心：在关于 Sora 是否理解物理世界的争论中，Keras 之父 François Chollet 曾提到，这个问题之所以重要，是因为它决定了生成图像、视频的应用范围 —— 是仅限于媒体生产，还是可以用作现实世界的可靠模拟。如果分两种情况去讨论，Sora 的发布将分别带来哪些新的商业机遇？&nbsp;</span></strong><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><strong><span style="font-size: 15px;">唐家渝：</span></strong><span style="font-size: 15px;">我觉得前者主要对应的是数字世界里的内容生产。在数字世界中，我们平时接触到的内容涉及电视电影、广告、教育、社交娱乐等多个行业。因为视频形态在我们日常生活中用得太多了，所以即使只看跟视频相关的场景，它的应用前景就已经非常不可限量了。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如果它能理解物理世界，那应用范围就不止局限在数字世界了，而是可以和物理世界产生交互。比如，它可以和机器人结合实现具身智能，也可以用于自动驾驶，用于数字孪生。之前一个一个构建小模型的方法可能有很多 corner case 照顾不到，如果模型真能了解到物理世界的规则，我们就能使用一个通用模型来处理所有的关于物理世界的认知和仿真任务，这可能会极大地推动社会运行方式的进化。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503425037" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>张倩</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[8/8/6/3的Mamba论文，最终还是被ICLR 2024拒了，网友：悬着的心终于死了]]></title>
        <id>2650908519_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908519&amp;idx=1&amp;sn=7090725444cde58d629f43c24568a30d&amp;chksm=84e46319b393ea0f129f9a06d572747b99bd09ff12ca59c35450de93c7b9f5bbf1382e9d2cc6#rd"/>
        <updated>2024-02-25T04:40:50.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;outline: 0px;letter-spacing: 0.544px;text-wrap: wrap;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：蛋酱</strong></span></p></div></div></div></div></div><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">几天前，ICLR 2024 的最终接收结果出来了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">大家应该还记得，Mamba 被 ICLR 2024 大会 Decision Pending（待定）的消息在 1 月份引发过一波社区热议。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">当时，多位领域内的研究者分析，Decision Pending 的意思是延迟决定，虽然也可能会被拒，但这篇论文得到了 8/8/6/3 的打分，按理说不至于真被拒。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424850" data-ratio="1.212962962962963" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSomzysbSXZpbaAbgoBJ3Yr2mlLEAzqJPnpgKqLgqicFVSzyOPLK2jicug/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 15px;">论文审稿页面：https://openreview.net/forum?id=AL1fq05o7H</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如今，Decision 已出，Mamba 彻底被拒，悬着的心终于死了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424851" data-ratio="0.14351851851851852" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSf4TXl5epNe0WZBicuthfS4cvsOQHZRicscKVT0AOhPv1xeNWdViahansg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「Mamba」发布之初即被视为「Transformer 的强劲竞争者」，它是一种选择性状态空间模型（selective state space model），在语言建模方面可以媲美甚至击败 Transformer。而且，它可以随上下文长度的增加实现线性扩展，其性能在实际数据中可提高到百万 token 长度序列，并实现 5 倍的推理吞吐量提升。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">但对于 ICLR 审稿人来说，这篇论文还存在重大缺陷（至少针对当前版本）。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong>手握 8/8/6/3 得分，究竟为什么被拒？</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;font-size: var(--articleFontsize);letter-spacing: 0.034em;"></span><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">重新查看 OpenReview 页面之后，我们发现了新的审稿意见。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">ICLR 区域主席给出的最终说法是：论文使用的评估方法有争议。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424852" data-ratio="0.43425925925925923" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSBCJhiaq1mFlrkDIOcxuC8EsTialibL0zQWEcGAcMdiaK3OTM92U7FCxv8Q/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">审稿意见整理如下：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">本文介绍了一种为远距离语言建模而设计的新型状态空间模型变体。实验表明，在语言建模任务的困惑度指标下，该模型与现有模型相比有显著进步。值得注意的是，两位审稿人给出了非常积极的评价（尽管其中一位审稿人在语言模型方面经验有限）。然而，第三位审稿人，一位在语言模型方面更有经验的专家，提出了两个与基准和评估指标有关的重大问题：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">1. 缺少 LRA（Long Range Arena）的结果：审稿人强调缺少 LRA 的结果，而 LRA 是公认的长序列建模基准。在之前的状态空间模型研究中，LRA 已成为惯例，因此必须对其进行全面评估。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">2. 使用困惑度进行评估：审稿人质疑将困惑度作为主要评价指标的做法。论文引用了 Sun et al. (2021)（《Do Long-Range Language Models Actually Use Long-Range Context?》）的观点，他们认为较低的困惑度并不一定意味着最终 NLP 应用的建模能力有所提高。Zhang et al. (2023)（《Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer》）进一步加强了他们的观点，他们强调了一些 transformer 模型的局限性，这些模型虽然实现了较低的困惑度，但在生成任务（如摘要和问题解答）中却举步维艰。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此外，还有人对长序列语言模型在短文本序列中的潜在性能差距表示担忧。我建议加入补充实验结果来解决这方面的问题。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">为了调和这些不同的观点，我们与审稿人 du8a 进行了讨论，随后又与高级区域主席进行了讨论。在对论文进行细致审查并考虑到所提出的合理关切后，最终决定建议拒绝该论文。这些问题，尤其是与实验方法和所选评价指标有关的问题，被认为是实质性的，在所提供的 rebuttal 中没有得到充分解决。我们认为，通过增加额外的实验来解决这些问题，对论文将大有裨益。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong>同样被 ICLR 拒绝的神作：「 Word2vec」</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Mamba 的经历，让人们想起了十年前的一篇论文。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424853" data-ratio="1.0675925925925926" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSEBRVYwOeEW6kMCeob3IR1fyHxCCc3eT7RJzYlad8dqZc5LZyYeiaMIg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">图中提到的是关于的 Word2vec 首篇论文《Efficient Estimation of Word Representations in Vector Space》，由 Tomas Mikolov 等四位谷歌研究者共同完成。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424854" data-ratio="0.525" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSibAg0I0ANsnbl2PJuU6rrJYibNzkDdTjiaBL2hicdAg6ec36F9oQ2M36Bg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">论文链接：https://arxiv.org/pdf/1301.3781.pdf</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这篇论文在 2013 年首届 ICLR 会议被拒了，尽管当年的接收率比较高。去年， Tomas Mikolov 在梳理 Word2vec 发展历程的时候还遗憾提到：「这让我想到审稿人预测论文的未来影响是多么困难。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">但细看之下，Word2vec 被拒的原因倒是和一般论文不同。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在 OpenReview 的页面，我们看到当时几位审稿人针对提交版本给到了一波意见，比如补充定义模型的方程等等。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 15px;">审稿页面：https://openreview.net/forum?id=idpCdOWtqXd60</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">而 Tomas Mikolov 的回复态度偏强硬，显然也没有充分完善对应每条审稿意见的材料，导致几位审稿人看完了 rebuttal，更生气了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">一位审稿人最终给出「Strong Reject」：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424855" data-ratio="0.18425925925925926" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExS11oO1qlnfbeLzAvc9n7DMX1s901mhUSWRvrPoicGicJtoqgcLWG7OqGw/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">另一位审稿人曾给出「大部分内容清晰良好」的评论，但后来也修改为「Weak Reject」：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424856" data-ratio="0.12685185185185185" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSzmfQSBhdMGpxiceMmUywFU24FIXD7sibpic1L8eiaOgb9cgb99Jdlel11Q/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">还有一位审稿人直白地指出：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「令人遗憾的是，答辩作者似乎只关心他的模型和模型组合的每一个可能的调整，却对合理的科学对比表现出强烈的漠视。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「作者写道，有许多显而易见的实际任务，他们的词向量应该有所帮助，但却没有展示或提及任何任务。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「除了他自己的模型、数据集和任务之外，作者似乎更愿意忽略所有其他的东西。我仍然不清楚是模型的哪个部分带来了性能提升。是顶层任务还是词向量的平均化？」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「链接到作者在维基百科上发表的一篇文章并不能作为有力的论据，还不如显示出指出实际差异的方程式。经过审稿人之间的讨论，我们一致认为论文的修订版和随附的 rebuttal 并没有解决审稿人提出的许多问题，审稿人的许多问题（如哪些模型包含非线性）仍未得到回答。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><img class="rich_pages wxw-img" data-imgfileid="503424857" data-ratio="0.43333333333333335" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSfbTDf5E3fK8BiabCcV4fnCxlKrE5tqMys5icFiaFvwGU9f8SibicASlyq9Q/640?wx_fmt=png&amp;from=appmsg"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">总之，这次审稿闹得不太愉快。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">后来，四位作者 Tomas Mikolov、Kai Chen、Greg Corrado、Jeffrey Dean 和当时在谷歌任职的 Ilya Sutskever 又写了一篇关于 Word2vec 的论文《Distributed Representations of Words and Phrases and their Compositionality》，转投 NeurIPS 且被顺利接收了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">去年，这篇论文还获得了 NeurIPS 2023 的时间检验奖，获奖理由是「这项工作引入了开创性的词嵌入技术 word2vec，展示了从大量非结构化文本中学习的能力，推动了自然语言处理新时代的到来」。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">可惜的是，后续几位作者的关系陷入僵局，Tomas Mikolov 透露的版本是：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="229" data-source-title=""><div class="js_blockquote_digest"><p>我在谷歌 Brain 内部多次讨论过这个项目，主要是与 Quoc 和 Ilya，在我转到 Facebook AI 后他们接手了这个项目。我感到非常意外的是，他们最终以「从序列到序列（sequence to sequence）」为名发表了我的想法，不仅没有提到我是共同作者，而且在长长的致谢部分提及了谷歌 Brain 中几乎所有的人，唯独没有我。那时是资金大量涌入人工智能领域的时期，每一个想法都价值连城。看到深度学习社区迅速变成某种权力的游戏，我感到很悲哀。</p></div></blockquote><p><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong>神作的影响力，时间自会证明</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">从 Mamba 的 OpenReview 页面来看，本次审稿过程中并没有「不够冷静」的成员。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">汇总所有审稿人的意见之后，作者团队及时对论文内容进行了修改和完善，补充了详尽的实验结果和分析。但正如审稿人所说，仍然「缺少 LRA（Long Range Arena）的结果」，导致最终被拒。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">与此同时，一位细心的网友发现，热门的开源多模态大模型 CogVLM 也被这次 ICLR 拒了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424858" data-ratio="0.3731481481481482" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSUow8MVItmeia2gIXVbJQQniciaE0rXkia9g1mxbwsbx2tjlmC50vAvDodg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424859" data-ratio="0.8296296296296296" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSLnMIiaXbcqYUMfPum5GtSiaxHMPLH1x2drs1iacbeEpiaD7qk6lQulOXVQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对于 Mamba、CogVLM 的作者团队来说，拒稿是一种令人遗憾的结果，但换个角度想，研究的真正价值不会仅由某一个学术会议而界定，也不会因此被埋没。伴随着理论研究的不断突破，Mamba 和 CogVLM 或许将衍生出更多有意义的成果，同样有机会开启一个新的时代。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-imgfileid="503424860" data-ratio="0.4537037037037037" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWicbZB8cZQul3aG8kCrH8ExSTEJVzXevzVzVAsroT8aibCK1nzLwxwAuJyjVGiagEDA5Ebic85bp35cpQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">推荐阅读：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650900669&amp;idx=1&amp;sn=8b74a72f2887fb00d4ad36b6482d8cb4&amp;chksm=84e44cc3b393c5d5e561f62de20edba1d4cefdc9b0b3983ca4701d65371bba51ca74976b8dde&amp;scene=21#wechat_redirect" textvalue="《论文遭首届 ICLR 拒稿、代码被过度优化，word2vec 作者 Tomas Mikolov 分享背后的故事》" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">《论文遭首届 ICLR 拒稿、代码被过度优化，word2vec 作者 Tomas Mikolov 分享背后的故事》</span></a></p><p style="line-height: 1.75em;margin-bottom: 0px;"><a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650905694&amp;idx=2&amp;sn=d2862bd65612846b702db0be71bbbb04&amp;chksm=84e45820b393d1363390e09f1dd83ad194ca02b09cf42ef328bdd82f7ee0a136a4a283bb38e8&amp;scene=21#wechat_redirect" textvalue="《Mamba 论文为什么没被 ICLR 接收？AI 社区沸腾了》" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span style="font-size: 15px;">《Mamba 论文为什么没被 ICLR 接收？AI 社区沸腾了》</span></a><span style="font-size: 15px;"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503424861" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name/>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[谷歌Gemini生图功能紧急关闭，口碑一夜塌房，Yann LeCun：我早就知道]]></title>
        <id>2650908456_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908456&amp;idx=1&amp;sn=2af47dde9f5caa786ff422f0f9cf3b69&amp;chksm=84e46356b393ea40f6496e7cc33bc845634a3b7fdf4d2ca986ec5eb57b617891f93ca7eb303f#rd"/>
        <updated>2024-02-24T05:10:44.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：小舟、泽南</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="15" data-source-title="" style="letter-spacing: 0.578px;text-wrap: wrap;"><div class="js_blockquote_digest"><p><span style="display: none;line-height: 0px;">‍</span>Gemini 好像终于被玩坏了。</p></div></blockquote><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">去年年底，谷歌 Gemini 震撼了业界，它是谷歌「最大、最有能力和最通用」的 AI 系统，号称第一个原生多模态大模型，能力超越 GPT-4，也被认为是谷歌反击微软和 OpenAI 的强大工具。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">对此，在 2 月 8 日，谷歌还把自家对标 ChatGPT 的服务 Bard 更名为 Gemini，以着重体现新使命 —— 旨在提供对「最强模型系列」的访问。上周谷歌还<a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650907658&amp;idx=2&amp;sn=e6dad13b58a1ea9298c81e537f022041&amp;chksm=84e46074b393e962eb67f32e0f56357678a211d9cdad63ac28174cdbffc896662c35ffcf22a7&amp;scene=21#wechat_redirect" textvalue="火速更新了 Gemini Pro 1.5 版" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">火速更新了 Gemini Pro 1.5 版</a>。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">结果，推出不到一个月，这个 Gemini 就翻车了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">多离谱呢，作为一个多模态的生成大模型，Gemini 生成的伊隆・马斯克是这样的：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424772" data-ratio="1.0465116279069768" data-s="300,640" data-type="png" data-w="946" style="width: 475px;height: 497px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CDs1T4Ieib3AoCXvMdDmIia0bkHuK9odnRGuorMPk0UEG6OkxhHQibcJkA/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">脸型神态都很传神，只是有个大问题：怎么成了黑人？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">又有人尝试让 Gemini 画一幅<span style="letter-spacing: 0.578px;text-wrap: wrap;">「</span>1940 年代德国领导人<span style="letter-spacing: 0.578px;text-wrap: wrap;">」</span>的图，结果 AI 给出了这么一张：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424774" data-ratio="1.0708661417322836" data-s="300,640" data-type="png" data-w="889" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9C99z9R9vrQB2ibZElDGgQL6Py5p7k1KSTvKF9cFYgSCb3uiblOZhfJHuA/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">社交网络上的众多网友们还提供了一些 Gemini 生成维京人、教皇的图片样本。我们可以看到有一名身着教皇服装的亚洲女性，但历史上所有教皇都是男性担任的。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424775" data-ratio="0.5597826086956522" data-s="300,640" data-type="png" data-w="920" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CyypTjKBQiaichft0oP7ZyS6PQvz7S5wkNC4fcBraaoVnVNKf34fJqlEQ/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">总之，众多用户在使用人像生成服务时发现，Gemini 似乎拒绝在图像中描绘白人，以至于生成了不少违背基本事实（性别、种族、宗教等）的图片。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">以往的图像生成模型大多被诟病生成人物图像以「白人」为主，而 Gemini 矫枉过正了？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在 reddit 的斗图区，网友们也开始玩起了梗，比如让 Gemini 生成个「钢铁侠」小罗伯特唐尼：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424776" data-ratio="1" data-s="300,640" data-type="png" data-w="640" style="width: 440px;height: 440px;" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CEkGHic1Ef8GDXdo7mFLtiacRc2mtuxPtjNR5HoDic7z9lHzsQUjqcNhhA/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">你就说是不是一视同仁吧。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">然而，Gemini 也不是一直都这么偏心，有时它生成的图像中的人物就成了白人。例如克拉伦斯・托马斯（Clarence Thomas），美国最高法院大法官，Gemini 生成的结果是这样的：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424778" data-ratio="0.5657407407407408" data-s="300,640" data-type="png" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9Ct7fOQBD4eNKaE3Fm0ABS1m9T8eWYUiaM2gPWxmib14IYUibdHlYrxm6sg/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">然而，他实际上是个非裔。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424779" data-ratio="0.6648148148148149" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CiaWibAnGBIJGDFjj5E95m0C8bT8OQGFFKuHdDXbRsnzPFqJzChJ4oicIA/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">Clarence Thomas 本人的照片。</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">怎么一到法官这种特殊职业，Gemini 的偏见就调转了 180 度呢？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这些图片有真有假，像病毒一样在社交媒体上迅速传播，马斯克本人的关注进一步扩大了事件影响。他措辞严厉表示，谷歌在文生图上「玩过头了」。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424780" data-ratio="0.9298969072164949" data-s="300,640" data-type="jpeg" data-w="970" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CojSllCKkN3bT5R7mtOWK9Idc6HT0b6HaX4hqBnLoRBp3QpeP2SFDRQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">随着节奏越来越大，很多 AI 专家也纷纷开始发表自己的看法。图灵奖获得者 Yann LeCun 今天就表示他早有预料。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">他表示，早在四年前，自己对 GAN 肖像超分辨率的评论就受到了众人的激烈反对。但一个明显的事实是，图像重建任务会受到训练数据集统计的严重偏差影响。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424781" data-ratio="1.3935483870967742" data-s="300,640" data-type="png" data-w="930" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CW18fibD9PKdN5yfsE8md8TO4ZrVJiczxwseILkIEcdy4OSzMJzwQ75ow/640?wx_fmt=png&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 15px;">LeCun 还援引 AI 顶会 ECCV 2022 的一篇研究《Studying Bias in GANs through the Lens of Race》，其指出生成图像模型的性能会受到训练数据集中种族组成的影响。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该研究表明，生成图像的种族成分成功继承了训练数据的种族成分，而且生成图像的种族和质量也有所不同——注释者始终更喜欢 AI 生成的白人图像。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">LeCun 转推的帖子来自 Perplexity AI 首席执行官 Aravind Srinivas。后者表示，数据偏差让模型的输出出现了问题，谷歌在相反的方向上走得太远了，以至于他们在 Gemini 中酿成大错。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: center;"><span style="font-size: 16px;"><strong>谷歌：我们错了，承诺改进</strong></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在重压之下，谷歌在本周四承认了 Gemini 图像生成的问题。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424782" data-ratio="0.3675925925925926" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWibou2tiacxwoiaxMjic330EL9CkRd2lMnFQZfdEDYibw78qGIFjQZVyOPVOICpicQWCGSJxthXGNX3zkOw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">以下是谷歌知识与信息高级副总裁 Prabhakar Raghavan 针对 Gemini 图像生成「翻车」给出的最新回应：</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="158" data-source-title=""><div class="js_blockquote_digest"><div><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">三周前，我们为 Gemini 对话应用程序（以前称为 Bard）推出了新的图像生成功能，其中包括创建人物图像的功能。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">很明显，这个功能没有达到预期。生成的一些图像不准确甚至具有攻击性。我们感谢用户的反馈，并对功能未能正常运行感到抱歉。</span></p><p style="margin-bottom: 0px;line-height: 1.75em;"><br></p><p style="margin-bottom: 0px;line-height: 1.75em;"><span style="font-size: 15px;">我们已经承认了这个错误，<strong><span style="color: rgb(61, 170, 214);">并暂停了 Gemini 的人物图像生成功能</span></strong>，同时我们正在开发改进版本。</span></p></div></div></blockquote><p><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">谷歌表示，Gemini 对话应用程序是一款独立于谷歌的搜索、底层人工智能模型和其他产品的特定产品。其图像生成功能建立在人工智能模型 Imagen 2 的基础上。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在为 Gemini 构建图像生成功能时，谷歌对其进行了调整，以确保它不会落入我们过去在图像生成技术中看到的一些陷阱，例如创建暴力或露骨的图像，或对现实生活中存在的真人的描绘。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">由于 Google 用户来自世界各地，公司希望 Gemini 能为每个人提供良好的服务。在生成人物图像时，用户可能不仅仅只想生成一种种族（或任何其他特征）的人物图像。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">如果你提示 Gemini 特定类型的人物图像 - 例如「教室里的黑人老师」、「带着狗的白人兽医」或特定文化、历史背景下的人，用户绝对应该得到一个准确反映人类要求的答复。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">那么 Gemini 到底出了什么问题呢？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">简而言之，有两件事。首先，谷歌为确保 Gemini 显示一系列人物而进行的调整未能考虑到显然不应该显示的范围。其次，随着时间的推移，该模型变得比开发者预期的更加谨慎，拒绝回答某些提示——会错误地将一些提示解释为敏感提示。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这两件事导致模型在某些情况下过度输出，而在另一些情况下过度保守，从而导致 Gemini 的图像生成功能出现了一些错误。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">谷歌表示，<span style="letter-spacing: 0.578px;text-wrap: wrap;">「</span>这不是我们的初衷。我们不希望 Gemini 拒绝创造任何特定群体的形象。我们不希望它创造出不准确的历史图像或任何其他图像。因此，我们关闭了人物图像生成功能，并将在重新打开它之前努力改进，这个过程将包括广泛的测试。<span style="letter-spacing: 0.578px;text-wrap: wrap;">」</span></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">需要记住的一件事是，Gemini 是一种创造力和生产力工具，它或许并不总是可靠的，特别是在生成有关时事、不断发展的新闻或热门话题的图像或文本时，它可能会犯错。众做周知，幻觉是所有大语言模型（LLM）都会面临的挑战，这需要不断的努力改进。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="113" data-source-title=""><div class="js_blockquote_digest"><p style="line-height: 1.75em;">我们不能保证 Gemini 不会偶尔产生令人尴尬、不准确或令人反感的结果，但我们可以保证，只要发现问题，我们就将采取行动。人工智能是一项新兴技术，在很多方面都有帮助，具有巨大的潜力，我们正在尽最大努力安全、负责任地推动它发展。</p></div></blockquote><p><br></p><p><span style="font-size: 15px;letter-spacing: 0.034em;">虽然伴随着「Demo 加特技」、训练数据抄百度文心一言等各种诟病指责，Gemini 仍然一直被谷歌寄予厚望，不过此次生成内容上的问题让人们产生了非常不好的观感，不知如何才能补救。</span></p><p><span style="font-size: 15px;letter-spacing: 0.034em;"><br></span></p><p><span style="font-size: 15px;letter-spacing: 0.034em;">另一方面，这或许也体现了 OpenAI 一直强调安全性，及其建立 Red Teaming Network 的先见之明。</span><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">Gemini 这样的大体量模型，能否很快弥补此种缺陷？</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 12px;"><span style="color: rgb(136, 136, 136);">参考内容：</span><em><span style="color: rgb(136, 136, 136);"></span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">https://blog.google/products/gemini/gemini-image-generation-issue/</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">https://twitter.com/ylecun/status/1761161335004598677</span></em></span><span style="font-size: 15px;color: rgb(136, 136, 136);"></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503424784" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="10000"></mp-style-type></p>]]></summary>
        <author>
            <name>关注大模型的</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2770亿美元，英伟达创史上最大单日涨幅，黄仁勋：生成式AI已到临界点]]></title>
        <id>2650908360_1</id>
        <link href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650908360&amp;idx=1&amp;sn=c6dc497719c85e201315917f87cee66a&amp;chksm=84e462b6b393eba01804820febc569fbfe17b12e480124f5318819d4a0b99076426eda83823e#rd"/>
        <updated>2024-02-23T02:45:05.000Z</updated>
        <summary type="html"><![CDATA[<div data-mpa-powered-by="yiban.io" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-bottom: 0px;text-wrap: wrap;outline: 0px;letter-spacing: 0.544px;text-size-adjust: inherit;caret-color: rgb(34, 34, 34);background-color: rgb(255, 255, 255);font-family: &quot;Helvetica Neue&quot;, Helvetica, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="outline: 0px;border-width: 0px;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><div data-darkmode-bgcolor-16095509242984="rgb(25, 25, 25)" data-darkmode-original-bgcolor-16095509242984="rgb(255, 255, 255)" data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;" mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;outline: 0px;border-bottom: 1px solid rgb(204, 204, 204);border-top: 1px solid rgb(204, 204, 204);border-right-style: none;border-left-style: none;text-decoration: inherit;visibility: visible;line-height: 27.2px;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-top: -1.2em;margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;font-family: inherit;border-width: initial;border-style: initial;border-color: currentcolor;visibility: visible;line-height: 29.75px;color: rgb(163, 163, 163) !important;text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px !important;"><span mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;color: rgb(255, 255, 255);font-family: inherit;font-size: 15px;letter-spacing: 0.544px;background-color: rgb(117, 117, 118);text-decoration: inherit;visibility: visible;line-height: 29.75px;">机器之心报道<strong mp-original-font-size="15" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;"></strong></span></p><p mp-original-font-size="17" mp-original-line-height="29.75" style="margin-right: 8px;margin-left: 8px;outline: 0px;text-align: center;visibility: visible;line-height: 29.75px;"><span mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;visibility: visible;line-height: 29.75px;"><strong mp-original-font-size="12" mp-original-line-height="29.75" style="outline: 0px;visibility: visible;line-height: 29.75px;">编辑：泽南</strong></span></p></div></div></div></div></div><blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="16" data-source-title="" style="letter-spacing: 0.578px;text-wrap: wrap;"><div class="js_blockquote_digest"><p>老黄即将跻身全球前 20 富豪行列。</p></div></blockquote><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">英伟达，现在已是「地球上最重要的一支股票」了。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">本周四，英伟达市值单日暴涨 2770 亿美元。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">这是华尔街历史上最大的股票单日涨幅，这家重量级芯片公司的最新季度报告超出了预期，点燃了人们对于人工智能的乐观情绪。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424668" data-ratio="1.0575673166202415" data-s="300,640" data-type="jpeg" data-w="1077" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicYNZJv7F6FBHPp3DmQZsk6cvWmDma8xgrAGhLSavR3NMKPTz2rKIMFpzeluOdEwYovJSz98Alg4A/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);letter-spacing: 0.034em;">单日成交金额 659 亿美元，约合 4700 亿人民币。</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">该公司股价飙升了 16.4% 收于 785.38 美元，创历史新高。其总市值升至 1.96 万亿美元，再次超越谷歌（Alphabet）成为全球第三大市值公司，位列微软和苹果之后。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">此前，英伟达于周三晚间发布的一月季度报告显示，用于人工智能计算的专用芯片的需求继续超过分析师的预期，其中单季度营收 221 亿美元，同比 +265%，环比 +22%。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">英伟达的业绩加速反映了全球科技公司对于 AI 算力需求的激增。随着 <a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650907658&amp;idx=1&amp;sn=fb3a71b37ebe12815b936d67fe99c16c&amp;chksm=84e46074b393e962fbd121e16a1ef37d897c6ac3b3113bf0a0f1b2feb605d3e0740310f44f0c&amp;scene=21#wechat_redirect" textvalue="Sora" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Sora</a>、<a target="_blank" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650907658&amp;idx=2&amp;sn=e6dad13b58a1ea9298c81e537f022041&amp;chksm=84e46074b393e962eb67f32e0f56357678a211d9cdad63ac28174cdbffc896662c35ffcf22a7&amp;scene=21#wechat_redirect" textvalue="Gemini1.5" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">Gemini1.5</a> 等大模型的相继推出，基于大模型的诸多应用逐渐落地，AI 芯片供不应求的状况有望在 2024 年后持续。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">与此同时，英伟达的涨幅也联动了一系列科技股，推动了标准普尔 500 指数、欧洲 STOXX 600 和日经指数均创历史新高。周四成交的 650 亿美元英伟达股票，几乎占标准普尔 500 指数股票交易总额的五分之一。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">英伟达的股价创下了华尔街历史上最大单日涨幅，轻松超过了 Meta Platforms 刚刚达成的 1960 亿美元。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">英伟达市值的单日上涨幅度也超过了可口可乐的总市值，后者市值为 2637 亿美元。英伟达的股价在 2024 年内已上涨 58%，占标准普尔 500 指数今年内涨幅的四分之一以上。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">AJ Bell 投资总监 Russ Mould 表示：「在十九世纪中期的淘金热中赚到最多钱的人是那些提供工具的人，而不是那些寻找金矿的人。今天，英伟达在这场技术革命中实际上扮演着同样的角色。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">正在生成式 AI 军备竞赛中疯狂价码的科技公司对英伟达芯片的需求持续提升，是英伟达股价上涨的直接原因。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">据估算，英伟达 AI 芯片占据全球该领域销售额的 70% 左右。尽管 Meta、亚马逊、IBM 和微软都已经开始生产自己的 AI 芯片，但英伟达的盈利增长展示了自身不可替代的地位。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">于此同时，其他涉足人工智能领域的芯片制造商也纷纷上涨，AMD 涨约 11%，博通上涨了 6.3%。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424669" data-ratio="0.4775" data-s="300,640" data-type="gif" data-w="800" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_gif/KmXPKA19gWicYNZJv7F6FBHPp3DmQZsk6AIsEBmib8rlv9qTBvjg0HR71Sh1e3d2caLagtGWpIOhh4WObzenYAmA/640?wx_fmt=gif&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">在机遇出现时，英伟达也面临挑战，一些分析师担心美国对中国芯片销售的限制可能会损害其收入增长。中国的销售额约占英伟达第四季度销售额的 9%，低于上一季度的 22%。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">分析师财务预期的快速上升意味着英伟达的预期盈利估值已经下降，即使其股价去年上涨了两倍多。根据 LSEG 的数据，在英伟达发布报告之前，该公司的估值约为预期收益的 30 倍，低于一年前的 49 倍。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">至少有 17 家券商在业绩公布后上调了目标价。Rosenblatt Securities 是最看涨的公司之一，将目标价从 1100 美元上调至 1400 美元，这意味着市值 3.5 万亿美元。瑞银则将目标价从 850 美元下调至 800 美元，认为「收入增长可能会放缓」。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">当然，英伟达 CEO 黄仁勋的财富也在大幅增长。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img js_insertlocalimg" data-imgfileid="503424670" data-ratio="0.6583333333333333" data-s="300,640" data-type="jpeg" data-w="1080" style="" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gWicYNZJv7F6FBHPp3DmQZsk6bIXSKmDMbXnDUfEjppwYCvQuSjX2dfgkWPWuG20qEgso1UuyXrbudw/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">现年 61 岁的黄仁勋目前在彭博社的全球富豪排行榜上名列第 21 位，而仅在这个周四，他的财富就增加了 85 亿美元。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">老黄现在的身家估计约为 681 亿美元，超过了科氏集团董事长查尔斯・科赫（Charles Koch），并迅速追上了拥有沃尔玛的沃尔顿家族成员 (Walton family）。这是一个显著的提升：在去年初，黄仁勋的身家还是 135 亿美元，净资产排名第 128 位。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">黄仁勋自英伟达成立以来一直掌管公司，担任联合创始人、首席执行官、总裁和董事会成员，他拥有公司约 3% 的股份。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">本周三黄仁勋表示，生成式人工智能现在已经「达到了临界点」，全球的公司、各行业和国家的需求都在激增。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">他强调，数据中心从通用计算向「加速计算」的持续转变是英伟达成功的关键之一，并认为这是一种全新的计算方式，甚至是「一个全新的行业」。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「现在，数据中心第一次不仅仅用于计算数据、存储数据以及为公司员工提供服务。」黄仁勋表示，「我们现在已拥有了关于人工智能生成的新型数据中心，一个人工智能生成工厂。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">老黄解释说，这些工厂的工作是通过大量数据的训练生成 token，而 token 最终构成了人们在 ChatGPT、Midjourney 和智能化搜索引擎上的全新体验。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">AI 生成工厂的诞生导致了科技公司对英伟达芯片的强烈需求，以至于英伟达不得不在财报电话会议上解决「如何决定谁可以购买其产品」的问题，并承诺这一过程是「公平的」。</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;"><span style="font-size: 15px;">「我的猜测是，世界上的每个企业、每个软件公司…… 都将在 Nvidia AI Enterprise 上运行，」黄仁勋说道。「因此，随着时间的推移，这可能会成为一项非常重要的业务。我们有了一个良好的开端。」</span></p><p style="line-height: 1.75em;margin-bottom: 0px;"><br></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="color: rgb(136, 136, 136);"><span style="font-size: 12px;">参考内容：</span><em><span style="font-size: 12px;"></span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.reuters.com/technology/ai-leader-nvidia-rises-forecast-tops-wall-streets-lofty-goals-2024-02-22/</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://www.cnn.com/2024/02/22/tech/nvidia-ceo-jensen-huang-20-richest-billionaire/index.html</span></em></span></p><p style="line-height: 1.75em;margin-bottom: 0px;text-align: left;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">https://fortune.com/2024/02/22/billionaire-jensen-huang-nvidia-ai-tipping-point-whole-new-industry/</span></em></span></p><p><br></p><p style="letter-spacing: 0.578px;text-wrap: wrap;text-align: center;margin-bottom: 0px;"><img class="rich_pages wxw-img" data-cropselx1="0" data-cropselx2="578" data-cropsely1="0" data-cropsely2="645" data-galleryid="" data-imgfileid="503424667" data-ratio="0.8305555555555556" data-s="300,640" data-type="png" data-w="1080" style="height: 480px;width: 578px;" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/KmXPKA19gW9BcwDFz901ZX0iaIEk07W0Q6SZr9pu0tfoIelKhoSSymoOjB3PbKtjqiaiarOibX8GTCnRWwfO2ehVibQ/640?wx_fmt=jpeg&amp;from=appmsg"></p><p style="margin-bottom: 0px;letter-spacing: 0.578px;text-wrap: wrap;"><br></p><p class="mp_profile_iframe_wrp"><mp-common-profile class="js_uneditable custom_select_card mp_profile_iframe" data-pluginname="mpprofile" data-id="MzkwODI4NjY2Mw==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/bTicW6huibprLhW8WYM5M1CENXBd7Xn3bIjaTia6BX9cRhZ4ic6YHCDrv4ec9ao4tbtd6YEy7E9zCiascIEZzsEWibAA/0?wx_fmt=png" data-nickname="机器之心PRO会员" data-alias="almosthuman2014pro" data-signature="一份让您从此不再担心因业务繁忙而错失AI &amp; Robotics 赛道良机的业内通讯" data-from="0" data-is_biz_ban="0"></mp-common-profile></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;"><br></span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;color: rgb(136, 136, 136);font-size: 12px;font-family: mp-quote, -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;line-height: 19.2px;">©&nbsp;THE END&nbsp;</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" style="margin-top: 5px;margin-bottom: 0px;text-wrap: wrap;outline: 0px;color: rgb(34, 34, 34);font-family: -apple-system, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;caret-color: rgb(34, 34, 34);text-size-adjust: auto;background-color: rgb(255, 255, 255);text-align: center;line-height: 27.2px;"><span mp-original-font-size="12" mp-original-line-height="19.200000762939453" style="outline: 0px;font-size: 12px;color: rgb(136, 136, 136);line-height: 19.2px;">投稿或寻求报道：content@jiqizhixin.com</span></p><p style="display: none;"><mp-style-type data-value="3"></mp-style-type></p>]]></summary>
        <author>
            <name>关注生成式AI的</name>
        </author>
    </entry>
</feed>